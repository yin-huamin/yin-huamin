<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="YHM">




<!-- 解决语雀图片防盗链 -->
<meta name="referrer" content="no-referrer" />

<title>图解计算机系统 | Hexo</title>



    <link rel="icon" href="/luffy.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        
    


<meta name="generator" content="Hexo 6.3.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Huamin&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Huamin&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">图解计算机系统</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">YHM</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">October 9, 2023&nbsp;&nbsp;15:07:05</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/">计算机</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>2023.10.08~2023.10.09<br>本人是生物学在读研究生，本科为生物信息学，一种结合生物学，计算机和数学统计的学科。<br>学习动机：Deep Learning在生物学上的应用收到关注。DL的学习需要掌握基本计算机概念，在学习计算机组成原理之前，看到了《码农的荒岛求生》公众号作者的这本书《图解计算机系统》，非常有趣，像我这样的外行也能搭建一些简单的基本概念框架。<br>收获：（简单提几点）</p>
<pre><code>  - 明白了CPU、程序、进程、内存、寄存器、栈帧、线程、操作系统、内核、缓存、编译、I/O，汇编等计算机基础概念。
  - 明白了高级语言速度慢原因之一是因为需要编译，以及汇编语言的存在。
  - 内存分配的过程、寄存器的结构。
  - 明白了CPU是怎么懂得人们写的代码（指令集），以及CPU有不同的指令集框架。
  - 大型服务器需要排队的原因之一是因为线程安全。
  - 缓存catch是CPU和内存之间的桥梁，CPU核数与线程之间的关系。。。
</code></pre>
<p>联系方式：QQ：1132250853，V：yinhm1999，欢迎大家交流与指正。欢迎大佬们继续补充未看完的部分。</p>
<h1 id="一、CPU是如何理解01二进制的？"><a href="#一、CPU是如何理解01二进制的？" class="headerlink" title="一、CPU是如何理解01二进制的？"></a>一、CPU是如何理解01二进制的？</h1><p>准确的来说，<strong>CPU不认识也不理解任何东西</strong>。<br>CPU就像一个单细胞一样，本身不具备任何思考能力，没什么自己的想法，只是简单的你给它一个刺激，它会有一个反应。<img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696636845076-f23b7f0b-2a6b-4132-92ed-f0a1f6af6d04.png#averageHue=%235c8092&clientId=u72175fe2-58d5-4&from=paste&height=1000&id=u970abd5f&originHeight=1000&originWidth=1333&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1360230&status=done&style=none&taskId=u68598b09-c6cd-42af-8154-982bd05d65a&title=&width=1333" alt="image.png"><br>那这个刺激是什么呢？是电压，硬件感知到的仅仅就是电压。 电压有两种，高电压和低电压。<br>你马上就能反应过来，这就是01二进制，高电压代表1低电压代表0，<strong>0和1仅仅是人类可以理解的东西，硬件电路可不理解这玩意</strong>，它仅仅就是靠电流驱动来工作。<br>让我们来看看这个简单的电路，这个就是与门<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696636868833-f2e72fa4-4d5d-46ad-bca9-1b485cb8af7d.png#averageHue=%23f0f0f0&clientId=u72175fe2-58d5-4&from=paste&height=531&id=u5d2c785f&originHeight=531&originWidth=365&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27048&status=done&style=none&taskId=u888e3623-da36-4d60-822a-9f8fee4ab92&title=&width=365" alt="image.png"><br>你能说这个电路理解它自己该做什么吗？它有自我意识吗？当然没有。 所以说这个问题的答案非常简单：<strong>CPU根本就不能理解任何东西，之所以CPU能正常工作，仅仅是因为你(制作CPU的人)让它这么工作</strong>。<br>这个问题就好比你问一辆自行车是如何理解自己怎么跑起来的？还不是因为你设计了车轮、车链然后用脚一蹬跑起来的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696636898289-be938c8f-5619-4a41-bc8b-c0c364b82b9d.png#averageHue=%23d6d5d0&clientId=u72175fe2-58d5-4&from=paste&height=685&id=uc90579fd&originHeight=685&originWidth=820&originalType=binary&ratio=1&rotation=0&showTitle=false&size=236030&status=done&style=none&taskId=u54488c8e-4620-4400-b910-ec82015706e&title=&width=820" alt="image.png"><br>你希望两个开关都打开灯才亮，因此你这样设计电路，这就是与门；你希望任意一个开关打开灯就亮，因此你那样设计电路，这就是或门；你希望关闭开关灯才亮，这就是非门，有了与或非你可以搭建出任意复杂的逻辑电路，比如下面这个能执行加操作的加法器。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696636923976-78d6db39-a3cb-4305-9dec-5b76c7b5c3aa.png#averageHue=%23fdfdfd&clientId=u72175fe2-58d5-4&from=paste&height=702&id=u7cffd41d&originHeight=702&originWidth=1120&originalType=binary&ratio=1&rotation=0&showTitle=false&size=49395&status=done&style=none&taskId=u471fe1cc-4b74-4919-a7a5-892480ab416&title=&width=1120" alt="image.png"><br>看看这个电路，你能说它知道自己是在执行加法操作吗，这当然是人类认为这个电路的输出等价于加法操作的结果。 尽管这个电路看上去很不错，给定两个输入得到的输出和我们人类认为的加法是一样一样的，但这有点简单。 除了加法是不是还应该有其它操作，如果有多种类型的操作那么就必须告诉电路该操作的类型是上面 (操作码)，操作的数字是什么(操作数)。 这样我们给它一个输入就能按照我的想法来控制电路该怎么工作了，BOOM！！！宇宙大爆炸！<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637014054-7f0b0451-72f3-456f-b598-846535a2101a.png#averageHue=%233a485f&clientId=u72175fe2-58d5-4&from=paste&height=721&id=u15cb843b&originHeight=721&originWidth=1280&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1752670&status=done&style=none&taskId=u8e7a6aaa-fc5f-4a6b-a03c-d6a5e36f9a4&title=&width=1280" alt="image.png"><br>哦不对，CPU诞生了！<br>人类编写的代码必须首先转为01二进制，之后才能驱动CPU工作。 当然，怎么把一坨代码<strong>高效等价</strong>的转为1001011100。。。这项工作可不简单，人类探索了几十年， 一干人等还获得了图灵奖，可见这个问题的重要程度以及难度。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637038569-4d24f343-dac6-4424-a096-716b4cc0b3f8.png#averageHue=%237c7655&clientId=u72175fe2-58d5-4&from=paste&height=499&id=u0d63ef13&originHeight=499&originWidth=330&originalType=binary&ratio=1&rotation=0&showTitle=false&size=400044&status=done&style=none&taskId=u58f8cff7-2639-4e2d-9025-1e623f9c8f0&title=&width=330" alt="image.png"><br>你今天能简单点一下build按钮或简单运行一个命令就能把你写的代码转为01串，要知道这简单的背后是靠无数天才榨干天量的脑细胞才实现的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637053491-cbb93a5a-89c5-45d6-bd3f-5f7d8df21356.png#averageHue=%23fffffe&clientId=u72175fe2-58d5-4&from=paste&height=652&id=ua90e854d&originHeight=652&originWidth=221&originalType=binary&ratio=1&rotation=0&showTitle=false&size=28786&status=done&style=none&taskId=u11dbe0d5-23e4-4b84-af43-3f8568fb14d&title=&width=221" alt="image.png"><br>从这里应该应该能看出来，<strong>CPU根本也不会认识任何语言</strong>。<br>现在我们能给CPU输入了，那么输出怎么办呢？<br><strong>剩下的仅仅就是解释了</strong>，比如给你一个01串，01001101，你可以认为这是一个数字，也可以认为这<br>是一个字符，也可以是表示RGB颜色，一切都看你怎么解释，这就是软件的工作了。<br>最终的目的只有一个：<strong>让人类能看懂</strong>。<br>整个流程就是这样的：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637075015-0014dac6-c66d-4a3e-8221-afddf5652531.png#averageHue=%23fffefd&clientId=u72175fe2-58d5-4&from=paste&height=716&id=u9084e107&originHeight=716&originWidth=733&originalType=binary&ratio=1&rotation=0&showTitle=false&size=71454&status=done&style=none&taskId=ub2a4cf68-927b-4348-9e90-e85910fa3d8&title=&width=733" alt="image.png"><br>计算机真实一个非常神奇的机器，如此简单，却又能完成复杂无比的工作。 现在你应该明白了吧，计算机所谓能理解二进制就好比你的台灯能理解开关一样。 <strong>它们真的对此一无所知</strong></p>
<h1 id="二、CPU空闲时在干嘛？"><a href="#二、CPU空闲时在干嘛？" class="headerlink" title="二、CPU空闲时在干嘛？"></a>二、CPU空闲时在干嘛？</h1><p>人空闲时会发呆会无聊，计算机呢？ 假设你正在用计算机浏览网页，当网页加载完成后你开始阅读，此时你没有移动鼠标，没有敲击键 盘，也没有网络通信，那么你的计算机此时在干嘛？有的同学可能会觉得这个问题很简单，但实际上，这个问题涉及从硬件到软件、从 CPU 到操作系统 等一系列环节，理解了这个问题你就能明白操作系统是如何工作的了。<br><strong>你的计算机 CPU 使用率是多少？ <strong>如果此时你正在计算机旁，并且安装有 Windows 或者 Linux ，你可以立刻看到自己的计算机 CPU 使用率是多少。<br>这是博主的一台安装有 Win10 的笔记本：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637357877-456476a4-9ec5-4ee9-93ec-abcff861d4cc.png#averageHue=%23f4f9f8&clientId=u72175fe2-58d5-4&from=paste&height=628&id=ub5d4d30b&originHeight=628&originWidth=844&originalType=binary&ratio=1&rotation=0&showTitle=false&size=265716&status=done&style=none&taskId=u032eca8d-ba16-41d2-aaf2-4cabcf01c06&title=&width=844" alt="image.png"><br>可以看到大部分情况下 CPU 利用率很低，也就在 8% 左右，而且开启了 283 个进程，</strong>这么多进程基本上无所事事</strong>，<strong>都在等待某个特定事件来唤醒自己</strong>，就好比你写了一个打印用户输入的程序，如果用户一直不按键盘，那么你的进程就处于这种状态。<br>有的同学可能会想也就你的比较空闲吧，实际上大部分个人计算机 CPU 使用率都差不多这样(排除掉看电影、玩游戏等场景)，如果你的使用率<strong>总是</strong>很高，风扇一直在嗡嗡的转，那么不是软件 bug 就有可能是病毒。。。<br>那么有的同学可能会问，<strong>剩下的 CPU 时间都去哪里了？</strong></p>
<h2 id="剩下的-CPU-时间都去哪里了？"><a href="#剩下的-CPU-时间都去哪里了？" class="headerlink" title="剩下的 CPU 时间都去哪里了？"></a>剩下的 CPU 时间都去哪里了？</h2><p>这个问题也很简单，还是以 Win10 为例，打开任务管理器，找到 “详细信息” 这一栏，你会发现有一个 “系统空闲进程”，其 CPU 使用率达到了 99%，正是这个进程消耗了几乎所有的 CPU 时间。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637410117-7bfd29a0-0441-4f96-ac15-5fff220ab6e2.png#averageHue=%23eaeeea&clientId=u72175fe2-58d5-4&from=paste&height=457&id=u25762cd4&originHeight=457&originWidth=844&originalType=binary&ratio=1&rotation=0&showTitle=false&size=275842&status=done&style=none&taskId=ub297a27f-39d5-4cef-ad0d-2c4bf2f0db8&title=&width=844" alt="image.png"><br>那么为什么存在这样一个进程呢？以及这个进程什么时候开始运行呢？ 这就要从操作系统说起了。 </p>
<h2 id="程序、进程与操作系统"><a href="#程序、进程与操作系统" class="headerlink" title="程序、进程与操作系统"></a>程序、进程与操作系统</h2><p>当你用最喜欢的<strong>代码编辑器</strong>编写代码时，这时的代码不过就是磁盘上的普通文件，此时的程序和操作系统没有半毛钱关系，操作系统也不认知这种文本文件。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637461674-a56bc1e6-e35c-44e7-a155-cc44975ca9c6.png#averageHue=%23b9d4c2&clientId=u72175fe2-58d5-4&from=paste&height=385&id=u1965757a&originHeight=385&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=172184&status=done&style=none&taskId=uccd00c11-7da9-462f-8c76-4632a9704a7&title=&width=1080" alt="image.png"><br>程序员写完代码后开始编译，这时<strong>编译器</strong>将普通的文本文件翻译成二进制可执行文件，此时的程序依然是保存在磁盘上的文件，和普通没有本质区别。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637473535-c7b0df6d-e3e6-4827-950b-871c42635fe0.png#averageHue=%23fafdfa&clientId=u72175fe2-58d5-4&from=paste&height=359&id=u6b0592b4&originHeight=359&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=172838&status=done&style=none&taskId=u91222be4-6f9d-4bf5-905c-e1356c44a77&title=&width=1080" alt="image.png"><br>但此时不一样的是，该文件是可执行文件，也就是说操作系统开始 “懂得” 这种文件，所谓 “懂得” 是 指操作系统可以识别、解析、加载，因此必定有某种类似协议的规范，这样编译器按照这种协议生成 可执行文件，操作系统就能加载了。<br>在 Linux 下可执行文件格式为 ELF ，在 Windows 下是 EXE 。<br>此时虽然操作系统可以识别可执行程序，**但如果你不去双击一下(或者在Linux下运行相应命令)的依 **<br><strong>然和操作系统没有半毛钱关系。 <strong>但是当你运行可执行程序时魔法就出现了。 此时操作系统开始将可执行文件加载到内存，解析出代码段、数据段等，并为这个程序创建运行时需 要的堆区栈区等内存区域，此时这个程序在内存中就是这样了：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637565329-cc2ea244-02c7-4b64-93c5-f59015c401bb.png#averageHue=%238eb1e5&clientId=u72175fe2-58d5-4&from=paste&height=693&id=u2b2b98f9&originHeight=693&originWidth=1057&originalType=binary&ratio=1&rotation=0&showTitle=false&size=233268&status=done&style=none&taskId=uf84ea16c-a003-4f96-90e4-871670f7811&title=&width=1057" alt="image.png"><br>最后，根据可执行文件的内容，操作系统知道该程序应该执行的第一条机器指令是什么，并将其告诉CPU ，CPU 从该程序的第一条指令开始执行，程序就这样运行起来了。<br>一个在内存中运行起来的程序显然和保存在磁盘上的二进制文件是不一样的，总的有个名字吧，根据“<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485705&idx=1&sn=1845875575601b23ed5cea0579c1f77e&source=41#wechat_redirect">弄不懂原则</a>”，这个名字就叫</strong>进程</strong>，英文名叫做Process。 <strong>我们把一个运行起来的程序叫做进程，这就是进程的由来</strong>。<br>此时操作系统开始掌管进程，现在进程已经有了，那么操作系统是怎么管理进程的呢？</p>
<h2 id="调度器与进程管理"><a href="#调度器与进程管理" class="headerlink" title="调度器与进程管理"></a><strong>调度器与进程管理</strong></h2><p>银行想必大家都去过，实际上如果你仔细观察的话银行的办事大厅就能体现出操作系统最核心的进程管理与调度。<br>首先大家去银行都要排队，类似的，进程在操作系统中也是通过队列来管理的。 同时银行还按照客户的重要程度<strong>划分了优先级</strong>，大部分都是普通客户；但当你在这家银行存上几个亿 时就能升级为 VIP 客户，优先级最高，每次去银行都不用排队，优先办理你的业务。<br>类似的，操作系统也会为进程划分优先级，操作系统会根据进程优先级将其放到相应的队列中供调度器调度。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637735631-ef1eea95-1873-4767-aca4-24a279aea68d.png#averageHue=%23e2e9ed&clientId=u72175fe2-58d5-4&from=paste&height=382&id=u9db1931d&originHeight=382&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=198019&status=done&style=none&taskId=ue888e0d4-1335-4562-a957-205890ce1db&title=&width=1080" alt="image.png"><br>这就是操作系统需要实现的最核心功能。<br>现在准备工作已经就绪。<br>接下来的问题就是操作系统如何确定是否还有进程需要运行。</p>
<h2 id="队列判空：一个更好的设计"><a href="#队列判空：一个更好的设计" class="headerlink" title="队列判空：一个更好的设计"></a><strong>队列判空：一个更好的设计</strong></h2><p>从上一节我们知道，实际上操作系统是用队列来管理进程的，那么很显然，如果队列已经为空，那么<br>说明此时操作系统内部没有进程需要运行，这是 CPU 就空闲下来了，此时，我们需要做点什么，就<br>像这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (<span class="built_in">queue</span>.empty()) &#123;</span><br><span class="line">    do_someting();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这些编写内核代码虽然简单，但内核中到处充斥着 if 这种异常处理的语句，这会让代码看起来一团<br>糟，<strong>因此更好的设计是没有异常</strong>，那么怎样才能没有异常呢？<br>很简单，<strong>那就是让队列永远不会空</strong>，这样调度器永远能从队列中找到一个可供运行的进程。<br>而这也是为什么链表中通常会有哨兵节点的原因，就是为了避免各种判空，这样既容易出错也会让代<br>码一团糟。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637882800-93c90565-da78-4a08-8b94-b33f816a9877.png#averageHue=%23f8fcfd&clientId=u72175fe2-58d5-4&from=paste&height=572&id=uc80862d8&originHeight=572&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=247416&status=done&style=none&taskId=u52f3d6b6-f67f-4712-85cc-32db5ec385a&title=&width=1080" alt="image.png"><br>就这样，<strong>内核设计者创建了一个叫做空闲任务的进程</strong>，这个进程就是Windows 下的我们最开始看到<br>的“系统空闲进程”，在 Linux 下就是第0号进程。<br>当其它进程都处于不可运行状态时，调度器就从队列中取出空闲进程运行，显然，**空闲进程永远处于 **<br><strong>就绪状态，且优先级最低</strong>。<br>既然我们已经知道了，当系统无所事事后开始运行空闲进程，那么这个空闲进程到底在干嘛呢？<br>这就需要硬件来帮忙了。</p>
<h2 id="一切都要归结到硬件"><a href="#一切都要归结到硬件" class="headerlink" title="一切都要归结到硬件"></a>一切都要归结到硬件</h2><p>在计算机系统中，<strong>一切最终都要靠 CPU 来驱动</strong>，CPU 才是那个真正干活的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696637931378-89d7d767-61ff-489b-9d68-a43d82ca26c0.png#averageHue=%234f5961&clientId=u72175fe2-58d5-4&from=paste&height=720&id=u5ba4fba0&originHeight=720&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1447429&status=done&style=none&taskId=ude33e9a5-7633-4957-a87d-4921aa19233&title=&width=1080" alt="image.png"><br>原来，CPU 设计者早就考虑到系统会存在空闲的可能，因此设计了一条机器指令，这个机器指令就是<br>halt 指令，停止的意思。<br>这条指令会让部分CPU进入休眠状态，从而<strong>极大减少对电力的消耗</strong>，通常这条指令也被放到循环中执<br>行，原因也很简单，就是要维持这种休眠状态。<br>值得注意的是，halt 指令是特权指令，也就是说只有在内核态下 CPU 才可以执行这条指令，程序员<br>写的应用都运行在用户态，因此你没有办法在用户态让 CPU 去执行这条指令。<br>此外，不要把进程挂起和 halt 指令混淆，当我们调用 sleep 之类函数时，暂停运行的只是进程，此时<br>如果还有其它进程可以运行那么 CPU 是不会空闲下来的，当 CPU 开始执行halt指令时就意味着系统<br>中所有进程都已经暂停运行。</p>
<h2 id="软件硬件结合"><a href="#软件硬件结合" class="headerlink" title="软件硬件结合"></a>软件硬件结合</h2><p>现在我们有了 halt 机器指令，同时有一个循环来不停的执行 halt 指令，这样空闲任务进程的实际上<br>就已经实现了，其本质上就是这个不断执行 halt 指令的循环，大功告成。<br>这样，当调度器在没有其它进程可供调度时就开始运行空间进程，也就是在循环中不断的执行 halt 指<br>令，此时 CPU 开始进入低功耗状态。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696638005069-2684dd65-47ba-4a0f-aaf6-2550df3f44de.png#averageHue=%23f5f6f3&clientId=u72175fe2-58d5-4&from=paste&height=461&id=u5569e0e0&originHeight=461&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=164893&status=done&style=none&taskId=ufcf0bec4-8875-44dc-95ff-10950395114&title=&width=1080" alt="image.png"><br>在 Linux 内核中，这段代码是这样写的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">while</span>(!need_resched()) &#123;</span><br><span class="line">        cpuidle_idle_call();  </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中 cpuidle_idle_call函数最终会执行 halt 指令，注意，<strong>这里删掉了很多细节，只保留最核心代码， **<br>实际上 Linux 内核在实现空闲进程时还要考虑很多很多，不同类型的 CPU 可能会有深睡眠浅睡眠之<br>类，操作系统必须要预测出系统可能的空闲时长并以此判断要进入哪种休眠等等，但这并不是我们关<br>注的重点。<br>总的来说，这就是计算机系统空闲时 CPU 在干嘛，就是在执行这一段代码，本质上就是 CPU 在执行<br>halt 指令。<br>实际上，对于个人计算机来说，halt 可能是 CPU 执行最多的一条指令，</strong>全世界的 CPU 大部分时间都 **<br><strong>用在这条指令上了</strong>，是不是很奇怪。<br>更奇怪的来了，有的同学可能已经注意到了，上面的循环可以是一个while(1) 死循环，而且这个循环<br>里没有break语句，也没有return，那么<strong>操作系统是怎样跳出这个循环的呢</strong>？<br>关于这个问题，我们将会在后续文章中讲解。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>CPU 空闲时执行特定的 halt 指令，这看上去是一个很简单的问题，但实际上由于 halt 是特权指令，<br>只有操作系统才可以去执行，因此 CPU 空闲时执行 halt 指令就变成了软件和硬件相结合的问题。<br>操作系统必须判断什么情况下系统是空闲的，这涉及到进程管理和进程调度，同时，halt 指令其实是<br>放到了一个 while死循环中，操作系统必须有办法能跳出循环，所以，CPU 空闲时执行 halt 指令并<br>没有看上去那么简单。</p>
<h1 id="三、编译器是如何工作的？"><a href="#三、编译器是如何工作的？" class="headerlink" title="三、编译器是如何工作的？"></a>三、编译器是如何工作的？</h1><p>对于程序员来说编译器是非常熟悉的，每天都在用，但是当你在点击“Run”这个按钮或者执行编译命令时你知道编译器是怎样工作的吗？<br>这篇文章就为你解答这个问题。</p>
<h2 id="编译器就是一个普通程序，没什么大不了的"><a href="#编译器就是一个普通程序，没什么大不了的" class="headerlink" title="编译器就是一个普通程序，没什么大不了的"></a>编译器就是一个普通程序，没什么大不了的</h2><p>什么是编译器？ </p>
<blockquote>
<p><strong>编译器是一个将高级语言翻译为低级语言的程序。</strong></p>
</blockquote>
<p>首先我们一定要意识到编译器就是一个普通程序，没什么大不了的。 在没有弄明白编译器如何工作之前你可以简单的把编译器当做一个黑盒子，其作用就是输入一个文本文件输出一个二进制文件。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666048284-c8eaeaa0-ee2f-45ad-915e-2f2a74a28f57.png#averageHue=%2392afdc&clientId=ua93502a5-3344-4&from=paste&height=334&id=u367601c0&originHeight=334&originWidth=1045&originalType=binary&ratio=1&rotation=0&showTitle=false&size=145668&status=done&style=none&taskId=uaeb2d02d-a381-4e0d-b9d1-c6168c54cd8&title=&width=1045" alt="image.png"><br>基本上编译器经过了以下几个阶段，等等，这句话教科书上也有，但是我相信很多同学其实并没有真正理解这几个步骤到底在说些什么，为了让你彻底理解这几个步骤，我们用一个简单的例子来讲解。<br>假定我们有一段程序：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">while</span> (y &lt; z) &#123;</span><br><span class="line">   <span class="type">int</span> x = a + b;</span><br><span class="line">   y += x;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么编译器是怎样把这一段程序人类认识的程序转换为CPU认识的二进制机器指令呢？</p>
<h2 id="提取出每一个单词：词法分析"><a href="#提取出每一个单词：词法分析" class="headerlink" title="提取出每一个单词：词法分析"></a>提取出每一个单词：词法分析</h2><p>首先编译器要把源代码中的每个“单词”提取出来，在编译技术中“单词”被称为<strong>token</strong>。其实不只是每个单词被称为一个token，除去单词之外的比如左括号、右括号、赋值操作符等都被称为token。<br>从源代码中提取出token的过程就被称为词法分析，Lexical Analysis。 经过一遍词法分析，编译器得到了以下token：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">T_While     <span class="keyword">while</span></span><br><span class="line">T_LeftParen   （</span><br><span class="line">T_Identifier   y</span><br><span class="line">T_Less         &lt;</span><br><span class="line">T_Identifier   z</span><br><span class="line">T_RightParen   )</span><br><span class="line">T_OpenBrace   &#123;</span><br><span class="line">T_Int         <span class="type">int</span></span><br><span class="line">T_Identifier   x</span><br><span class="line">T_Assign       =</span><br><span class="line">T_Identifier   a</span><br><span class="line">T_Plus         +</span><br><span class="line">T_Identifier   b</span><br><span class="line">T_Semicolon   ;</span><br><span class="line">T_Identifier   y</span><br><span class="line">T_PlusAssign   +=</span><br><span class="line">T_Identifier   x</span><br><span class="line">T_Semicolon   ;</span><br><span class="line">T_CloseBrace   &#125;</span><br></pre></td></tr></table></figure>
<p>就这样一个磁盘中保存的字符串源代码文件就转换为了一个个的token。</p>
<h2 id="这些token想表达什么意思：语法分析"><a href="#这些token想表达什么意思：语法分析" class="headerlink" title="这些token想表达什么意思：语法分析"></a>这些token想表达什么意思：语法分析</h2><p>有了这些token之后编译器就可以根据语言定义的语法恢复其原本的结构，怎么恢复呢？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666185720-4e84c01e-c5eb-4391-8f46-e710ab4302fe.png#averageHue=%23f4f7f5&clientId=ua93502a5-3344-4&from=paste&height=670&id=u3a4ffddf&originHeight=670&originWidth=1021&originalType=binary&ratio=1&rotation=0&showTitle=false&size=291562&status=done&style=none&taskId=ua854ac78-74cf-4686-8023-656dadca2f0&title=&width=1021" alt="image.png"><br>原来，编译器在扫描出各个token后根据规则将其用树的形式表示出来，这颗树就被称为<strong>语法树</strong>。</p>
<h2 id="语法树是不是合理的：语义分析"><a href="#语法树是不是合理的：语义分析" class="headerlink" title="语法树是不是合理的：语义分析"></a>语法树是不是合理的：语义分析</h2><p>有了语法树后我们还要检查这棵树是不是合法的，比如我们不能把一个整数和一个字符串相加、比较符左右两边的数据类型要相同，等等。<br>这一步通过后就证明了程序合法，不会有编译错误。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666223855-0ea52bbd-1290-4c85-a0f4-ed18e2649d42.png#averageHue=%23eef1ef&clientId=ua93502a5-3344-4&from=paste&height=746&id=u2315c3c5&originHeight=746&originWidth=1028&originalType=binary&ratio=1&rotation=0&showTitle=false&size=304305&status=done&style=none&taskId=u47fadf91-ead9-48b8-ab93-3669e91f40d&title=&width=1028" alt="image.png"></p>
<h2 id="根据语法树生成中间代码：代码生成"><a href="#根据语法树生成中间代码：代码生成" class="headerlink" title="根据语法树生成中间代码：代码生成"></a>根据语法树生成中间代码：代码生成</h2><p>语义分析之后接下来编译器遍历语法树并用另一种形式来表示，用什么来表示呢？那就是中间代码，intermediate representation code，简称<strong>IR code</strong>。<br>上述语法树可能就会表示为这样的中间代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Loop: x   = a + b</span><br><span class="line">      y   = x + y</span><br><span class="line">      _t1 = y &lt; z</span><br><span class="line">      <span class="keyword">if</span> _t1 <span class="keyword">goto</span> Loop</span><br></pre></td></tr></table></figure>
<p>怎么样，这实际上已经比较接近最后的机器指令了。 只不过这还不是最终形态。</p>
<h2 id="中间代码优化"><a href="#中间代码优化" class="headerlink" title="中间代码优化"></a>中间代码优化</h2><p>在生成中间代码后要对其进行优化，我们可以看到，实际上可以把x &#x3D; a + b这行代码放到循环外，因为每次循环都不会改变x的值，因此优化后就是这样了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">      x   = a + b</span><br><span class="line">Loop: y   = x + y</span><br><span class="line">      _t1 = y &lt; z</span><br><span class="line">      <span class="keyword">if</span> _t1 <span class="keyword">goto</span> Loop</span><br></pre></td></tr></table></figure>
<p>中间代码优化后就可以生成机器指令了。</p>
<h2 id="代码生成"><a href="#代码生成" class="headerlink" title="代码生成"></a>代码生成</h2><p>将上述优化后的中间代码转换为机器指令：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">      add $<span class="number">1</span>, $<span class="number">2</span>, $<span class="number">3</span></span><br><span class="line">Loop: add $<span class="number">4</span>, $<span class="number">1</span>, $<span class="number">4</span></span><br><span class="line">      slt $<span class="number">6</span>, $<span class="number">1</span>, $<span class="number">5</span></span><br><span class="line">      beq $<span class="number">6</span>, loop</span><br></pre></td></tr></table></figure>
<p>最终，编译器将程序员认识的代码转换为了CPU认识的机器指令。</p>
<h2 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h2><p>注意这篇简短的讲解不希望给大家留下这样的印象，那就是编译器是很简单的，恰恰相反，现代编译 器是非常智能并且极其复杂的，绝不是短短一篇文章就能讲清楚的，能实现一个编译器是困难的，实现一个好的编译器更是难上加难。<br>本文的目的旨在以极简的方式描述编译器的工作原理，这样你就不用把编译器当做一个黑盒了，希望这篇文章能对你有所帮助。</p>
<h1 id="四、函数运行时在内存中是什么样子？"><a href="#四、函数运行时在内存中是什么样子？" class="headerlink" title="四、函数运行时在内存中是什么样子？"></a>四、函数运行时在内存中是什么样子？</h1><p>在开始本篇的内容前，我们先来思考几个问题。 </p>
<ol>
<li>我们先来看一段简单的代码：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span> a)</span> &#123;</span><br><span class="line"> <span class="keyword">if</span> (a &gt; <span class="number">100000000</span>) <span class="keyword">return</span>;</span><br><span class="line"> <span class="type">int</span> arr[<span class="number">100</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"> func(a + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
你能看出这段代码会有什么问题吗？ </li>
<li>我们在上一篇文章《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485713&idx=1&sn=369203957fb922371535df891920dbc1&source=41#wechat_redirect"><strong>高性能高并发服务器是如何实现的</strong></a>》中提到了一项关键技术——协程，你知道协程的本质是什么吗？有的同学可能会说是用户态线程，那么什么是用户态线程，这是怎么实现的？ </li>
<li>函数运行起来后在内存中是什么样子？<br>这几个问题看似没什么关联，但这背后都指向一样东西，这就是所谓的函数<strong>运行时栈</strong>，<strong>run time stack</strong>。 接下来我们就好好看看到底什么是函数运行时栈，为什么彻底理解函数运行时栈对程序员来说非常重<br>要。</li>
</ol>
<h2 id="从进程、线程到函数调用"><a href="#从进程、线程到函数调用" class="headerlink" title="从进程、线程到函数调用"></a>从进程、线程到函数调用</h2><p>汽车在高速上行驶时有很多信息，像速度、位置等等，通过这些信息我们可以直观的感受汽车的运行时状态。<img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666536587-acf72db5-347f-4813-bd64-46ab3869b990.png#averageHue=%23313e56&clientId=ua93502a5-3344-4&from=paste&height=678&id=udd5bd30f&originHeight=678&originWidth=987&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1237807&status=done&style=none&taskId=u21e3cab9-5a5d-4f62-9db5-703b4aede23&title=&width=987" alt="image.png"><br>同样的，程序在运行时也有很多信息，像有哪些程序正在运行、这些程序执行到了哪里等等，通过这些信息我们可以直观的感受系统中程序运行的状态。<br>其中，我们创造了进程、线程这样的概念来记录有哪些程序正在运行，关于进程和线程的概念请参见《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485705&idx=1&sn=1845875575601b23ed5cea0579c1f77e&source=41#wechat_redirect"><strong>看完这篇还不懂进程、线程与线程池你来打我</strong></a>》。<br><strong>进程和线程的运行体现在函数执行上</strong>，函数的执行除了函数内部执行的顺序执行还有子函数调用的控制转移以及子函数执行完毕的返回。其中函数内部的顺序执行乏善可陈，重点是函数的调用。<br>因此接下来我们的视角将从宏观的进程和线程拉近到微观下的函数调用，重点来讨论一下函数调用是怎样实现的。</p>
<h2 id="函数执行的活动轨迹：栈"><a href="#函数执行的活动轨迹：栈" class="headerlink" title="函数执行的活动轨迹：栈"></a>函数执行的活动轨迹：栈</h2><p>玩过游戏的同学应该知道，有时你为了完成一项主线任务不得不去打一些支线的任务，支线任务中可能还有支线任务，当一个支线任务完成后退回到前一个支线任务，这是什么意思呢，举个例子你就明白了。<br>假设主线任务西天取经A依赖支线任务收服孙悟空B和收服猪八戒C，也就是说收服孙悟空B和收服猪八戒C完成后才能继续主线任务西天取经A；支线任务收服孙悟空B依赖任务拿到紧箍咒D，只有当任务D完成后才能回到任务B；整个任务的依赖关系如图所示：<img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666633469-1111e5a4-6b2a-4c62-9f06-94f2a36d4481.png#averageHue=%23f8fdfc&clientId=ua93502a5-3344-4&from=paste&height=390&id=u13ba548b&originHeight=390&originWidth=451&originalType=binary&ratio=1&rotation=0&showTitle=false&size=51642&status=done&style=none&taskId=u64e0fab9-165c-45e6-8006-4ebf69afa71&title=&width=451" alt="image.png"><br>现在我们来模拟一下任务完成过程。<br>首先我们来到任务A，执行主线任务：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666648454-e99710dc-191d-4e94-a695-7ddbf9c29936.png#averageHue=%23eff6f6&clientId=ua93502a5-3344-4&from=paste&height=98&id=u1aac2420&originHeight=98&originWidth=257&originalType=binary&ratio=1&rotation=0&showTitle=false&size=14978&status=done&style=none&taskId=uf430d8fb-498b-4d94-a5cf-63bc7d40dfb&title=&width=257" alt="image.png"><br>执行任务A的过程中我们发现任务A依赖任务B，这时我们暂停任务A去执行任务B：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666658514-78ced0a1-a0dc-453f-85bb-3109b6e0bde2.png#averageHue=%236aa0f1&clientId=ua93502a5-3344-4&from=paste&height=142&id=u338c850a&originHeight=142&originWidth=263&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27265&status=done&style=none&taskId=u850902b3-0e22-4206-b8f8-583110a3dee&title=&width=263" alt="image.png"><br>执行任务B的时候，我们又发现依赖任务D：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666664651-3ba4f7c4-a67b-4e82-8aca-000286c66c64.png#averageHue=%23699ff0&clientId=ua93502a5-3344-4&from=paste&height=202&id=u89861ff2&originHeight=202&originWidth=255&originalType=binary&ratio=1&rotation=0&showTitle=false&size=34922&status=done&style=none&taskId=ub7c2f9fe-68bd-4666-9a01-b318ae0fcf1&title=&width=255" alt="image.png"><br>执行任务D的时候我们发现该任务不再依赖任何其它任务，因此D完成后我们可以会退到前一个任<br>务，也就是B：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666678540-5328ea13-e105-44e1-a956-d47cdaae599d.png#averageHue=%236aa0f0&clientId=ua93502a5-3344-4&from=paste&height=147&id=u6c2c319e&originHeight=147&originWidth=261&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27515&status=done&style=none&taskId=u723beb43-6272-408a-bc1d-ef793ff5050&title=&width=261" alt="image.png"><br>任务B除了依赖任务D外不再依赖其它任务，这样任务B完成后就可以回到任务A：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666694520-f6dc7c0e-b0b3-426c-b03c-030f0df9527f.png#averageHue=%23669ef2&clientId=ua93502a5-3344-4&from=paste&height=86&id=u5d85005b&originHeight=86&originWidth=243&originalType=binary&ratio=1&rotation=0&showTitle=false&size=13122&status=done&style=none&taskId=u0945f757-d18f-4706-accb-4afcd4f5d40&title=&width=243" alt="image.png"><br>和任务D一样，C不依赖任何其它其它任务，任务C完成后就可以再次回到任务A，再之后任务A执行完毕，整个任务执行完成。<br>让我们来看一下整个任务的活动轨迹：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666714173-7532f483-5923-4f11-bd43-5b5601ed48dd.png#averageHue=%23f8fbf8&clientId=ua93502a5-3344-4&from=paste&height=111&id=u03ff94b6&originHeight=111&originWidth=849&originalType=binary&ratio=1&rotation=0&showTitle=false&size=61489&status=done&style=none&taskId=ub665efca-5528-49fc-a000-3a381e639fa&title=&width=849" alt="image.png"><br>仔细观察，实际上你会发现这是一个First In Last Out 的顺序，天然适用于栈这种数据结构来处理。再仔细看一下栈顶的轨迹，也就是A、B、D、B、A、C、A，<strong>实际上你会发现这里的轨迹就是任务依赖树的遍历过程</strong>，是不是很神奇，这也是为什么树这种数据结构的遍历除了可以用递归也可以用栈来实现的原因。</p>
<h2 id="A-Box"><a href="#A-Box" class="headerlink" title="A Box"></a>A Box</h2><p>函数调用也是同样的道理，你把上面的ABCD换成函数ABCD，本质不变。<br>因此，现在我们知道了，使用栈这种结构就可以用来保存函数调用信息。<br>和游戏中的每个任务一样，当函数在运行时每个函数也要有自己的一个“小盒子”，<strong>这个小盒子中保存了函数运行时的各种信息</strong>，这些小盒子通过栈这种结构组织起来，这个小盒子就被称为栈帧，stack frames，也有的称之为call stack，不管用什么命名方式，总之，就是这里所说的小盒子，这个小盒子就是函数运行起来后占用的内存，<strong>这些小盒子构成了我们通常所说的栈区</strong>。关于栈区详细的讲解你可以参考《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485654&idx=1&sn=78f9b5ab2de0bcafac16d377914ce32a&source=41#wechat_redirect"><strong>深入理解操作系统：程序员应如何理解内存</strong></a>》一文。<br>那么函数调用时都有哪些信息呢？</p>
<h2 id="控制转移"><a href="#控制转移" class="headerlink" title="控制转移"></a><strong>控制转移</strong></h2><p>我们知道当函数A调用函数B的时候，控制从A转移到了B，所谓控制其实就是指CPU执行属于哪个函数的机器指令，CPU从开始执行属于函数A的指令切换到执行属于函数B的指令，我们就说控制从函数A转移到了函数B。<br>控制从函数A转移到函数B，那么我们需要有这样两个信息：<br>我从哪里来 (返回)<br>要到去哪里 (跳转)<br>是不是很简单，就好比你出去旅游，你需要知道去哪里，还需要记住回家的路。<br>函数调用也是同样的道理。当函数A调用函数B时，我们只要知道：<br>函数A对于的机器指令执行到了哪里 (我从哪里来，返回)<br>函数B第一条机器指令所在的地址 (要到哪里去，跳转)<br>有这两条信息就足以让CPU开始执行函数B对应的机器指令，当函数B执行完毕后跳转回函数A。<br>那么这些信息是怎么获取并保持的呢？<br>现在我们就可以打开这个小盒子，看看是怎么使用的了。<br>假设函数A调用函数B，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666893744-1914c904-9997-4456-b238-563d78c80993.png#averageHue=%23fefefc&clientId=ua93502a5-3344-4&from=paste&height=543&id=u654a6adc&originHeight=543&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=134960&status=done&style=none&taskId=u9be44d2f-09ba-4b5a-9b31-6f34e4964c1&title=&width=1080" alt="image.png">	当前，CPU执行函数A的机器指令，该指令的地址为0x400564，接下来CPU将执行下一条机器指令也<br>就是:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">call <span class="number">0x400540</span></span><br></pre></td></tr></table></figure>
<p>这条机器指令是什么意思呢？<br>这条机器指令对应的就是我们在代码中所写的函数调用，注意call后有一条机器指令地址，注意观察上图你会看到，<strong>该地址就是函数B的第一条机器指令</strong>，从这条机器指令后CPU将跳转到函数B。<br>现在我们已经解决了控制跳转的“要到哪里去”问题，当函数B执行完毕后怎么跳转回来呢？<br>原来，call指令除了给出跳转地址之外还有这样一个作用，也就是<strong>把call指令的下一条指令的地址，也就是0x40056a push到函数A的栈帧中</strong>，如图所示：<img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666990250-8585a363-9f59-4d80-93b3-5950a3628acf.png#averageHue=%23fefefb&clientId=ua93502a5-3344-4&from=paste&height=499&id=u2f9ec6f7&originHeight=499&originWidth=1001&originalType=binary&ratio=1&rotation=0&showTitle=false&size=143973&status=done&style=none&taskId=ua9d787b2-2b6c-4995-8e9b-b9ccb7360ce&title=&width=1001" alt="image.png"><br>现在，函数A的小盒子变大了一些，因为装入了返回地址：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696666997680-57c10ae4-3f3b-4151-871f-4ba06eec1610.png#averageHue=%23eef3f5&clientId=ua93502a5-3344-4&from=paste&height=279&id=ud76c850c&originHeight=279&originWidth=647&originalType=binary&ratio=1&rotation=0&showTitle=false&size=35027&status=done&style=none&taskId=ua29086b9-9020-455e-942c-daa7e405512&title=&width=647" alt="image.png"><br>现在CPU开始执行函数B对应的机器指令，注意观察，函数B也有一个属于自己的小盒子(栈帧)，可以<br>往里面扔一些必要的信息。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696667024783-88b69ef5-f520-407a-8a07-3a102a67c90f.png#averageHue=%23fefefc&clientId=ua93502a5-3344-4&from=paste&height=558&id=u59751beb&originHeight=558&originWidth=1071&originalType=binary&ratio=1&rotation=0&showTitle=false&size=138413&status=done&style=none&taskId=u7500e0cf-e009-432f-9676-3ea47bcdcb5&title=&width=1071" alt="image.png"><br>如果函数B中又调用了其它函数呢？<br>道理和函数A调用函数B是一样的。<br>让我们来看一下函数B最后一条机器指令ret，这条机器指令的作用是告诉CPU跳转到函数A保存在栈帧上的返回地址，这样当函数B执行完毕后就可以跳转到函数A继续执行了。<br>至此，我们解决了控制转移中“我从哪里来”的问题。</p>
<h2 id="传递参数与获取返回值"><a href="#传递参数与获取返回值" class="headerlink" title="传递参数与获取返回值"></a><strong>传递参数与获取返回值</strong></h2><p>函数调用与返回使得我们可以编写函数，进行函数调用。但调用函数除了提供函数名称之外还需要传递参数以及获取返回值，那么这又是怎样实现的呢？<br>在x86-64中，多数情况下参数的传递与获取返回值是通过<strong>寄存器</strong>来实现的。<br>假设函数A调用了函数B，函数A将一些参数写入相应的寄存器，当CPU执行函数B时就可以从这些寄存器中获取参数了。<br>同样的，函数B也可以将返回值写入寄存器，当函数B执行结束后函数A从该寄存器中就可以读取到返回值了。<br>我们知道寄存器的数量是有限的，当传递的参数个数多于寄存器的数量该怎么办呢？<br>这时那个属于函数的小盒子也就是栈帧又能发挥作用了。<br>原来，当参数个数多于寄存器数量时剩下的参数直接放到栈帧中，这样被调函数就可以<strong>从前一个函数的栈帧中获取到参数了</strong>。<br>现在栈帧的样子又可以进一步丰富了，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696667181718-7df794a6-137e-4e31-8c25-4fb5d8f60824.png#averageHue=%23fdfefb&clientId=ua93502a5-3344-4&from=paste&height=616&id=uac520ab4&originHeight=616&originWidth=492&originalType=binary&ratio=1&rotation=0&showTitle=false&size=66618&status=done&style=none&taskId=uf2fd60c0-8886-4347-806c-59cede51c25&title=&width=492" alt="image.png"><br>从图中我们可以看到，调用函数B时有部分参数放到了函数A的栈帧中，同时函数A栈帧的顶部依然保<br>存的是返回地址。</p>
<h2 id="局部变量"><a href="#局部变量" class="headerlink" title="局部变量"></a>局部变量</h2><p>我们知道在函数内部定义的变量被称为局部变量，这些变量在函数运行时被放在了哪里呢？<br>原来，这些变量同样可以放在寄存器中，但是当局部变量的数量超过寄存器的时候这些变量就必须放到栈帧中了。<br>因此，我们的栈帧内容又一步丰富了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696667225139-a8e39986-2b72-43a9-a43d-5394f607ec2c.png#averageHue=%23fcfefc&clientId=ua93502a5-3344-4&from=paste&height=669&id=uaf0e85a1&originHeight=669&originWidth=506&originalType=binary&ratio=1&rotation=0&showTitle=false&size=79075&status=done&style=none&taskId=u9380421a-cc9b-485f-9905-8912ac219ea&title=&width=506" alt="image.png"><br>细心的同学可能会有这样的疑问，我们知道寄存器是共享资源可以被所有函数使用，既然可以将函数A的局部变量写入寄存器，那么当函数A调用函数B时，函数B的局部变量也可以写到寄存器，这样的话当函数B执行完毕回到函数A时寄存器的值已经被函数B修改过了，这样会有问题吧。<br>这样的确会有问题，因此我们在向寄存器中写入局部变量之前，<strong>一定要先将寄存器中开始的值保存起来</strong>，当寄存器使用完毕后再恢复原值就可以了。<br>那么我们要将寄存器中的原始值保存在哪里呢？<br>有的同学可能已经猜到了，没错，依然是函数的栈帧中。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696667259062-354d6fbd-e22c-4fc5-8c88-586120811f40.png#averageHue=%23faf9ed&clientId=ua93502a5-3344-4&from=paste&height=660&id=ufb006092&originHeight=660&originWidth=494&originalType=binary&ratio=1&rotation=0&showTitle=false&size=86283&status=done&style=none&taskId=u1a6bc421-4ec2-42c3-9d31-5693d1820b4&title=&width=494" alt="image.png"><br>最终，我们的小盒子就变成了如图所示的样子，当寄存器使用完毕后根据栈帧中保存的初始值恢复其内容就可以了。<br>现在你应该知道函数在运行时到底是什么样子了吧，以上就是问题3的答案。</p>
<h2 id="Big-Picture"><a href="#Big-Picture" class="headerlink" title="Big Picture"></a>Big Picture</h2><p>需要再次强调的一点就是，上述讨论的栈帧就位于我们常说的栈区。<br>栈区，属于进程地址空间的一部分，如图所示，我们将栈区放大就是图左边的样子<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696667288875-ef53eb98-1666-46dc-a9ee-ecefae558902.png#averageHue=%23fafaf8&clientId=ua93502a5-3344-4&from=paste&height=677&id=u8ccd3f81&originHeight=677&originWidth=922&originalType=binary&ratio=1&rotation=0&showTitle=false&size=144530&status=done&style=none&taskId=u724691ac-0e5a-407f-924c-7c108d21475&title=&width=922" alt="image.png"><br>关于栈区详细的讲解你可以参考《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485653&idx=1&sn=24a27455af32fdf97f6787e4a29e856a&source=41#wechat_redirect"><strong>深入理解操作系统：程序员应如何理解内存</strong></a>》这篇。<br>最后，让我们回到文章开始的这段简单代码</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span> a)</span> &#123;</span><br><span class="line"> <span class="keyword">if</span> (a &gt; <span class="number">100000000</span>) <span class="keyword">return</span>;</span><br><span class="line"> <span class="type">int</span> arr[<span class="number">100</span>] = &#123;<span class="number">0</span>&#125;;</span><br><span class="line"> func(a + <span class="number">1</span>);</span><br><span class="line">&#125;</span><br><span class="line"><span class="type">void</span> <span class="title function_">main</span><span class="params">()</span>&#123;</span><br><span class="line"> func(<span class="number">0</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>想一想这段代码会有什么问题？<br>原来，<strong>栈区是有大小限制的</strong>，当超过限制后就会出现著名的<strong>栈溢出</strong>问题，显然上述代码会导致这一问题的出现。<br>因此：</p>
<ol>
<li>不要创建过大的局部变量 </li>
<li>函数栈帧，也就是调用层次不能太多</li>
</ol>
<h2 id="总结-2"><a href="#总结-2" class="headerlink" title="总结"></a>总结</h2><p>本章我们从几个看似没什么关联的问题出发，详细讲解了函数运行时栈是怎么一回事，为什么我们不能创建过多的局部变量。细心的同学会发现第2个问题我们没有解答，这个问题的讲解放到下一篇，也就是协程中讲解。 </p>
<h1 id="五、彻底理解回调函数"><a href="#五、彻底理解回调函数" class="headerlink" title="五、彻底理解回调函数"></a>五、彻底理解回调函数</h1><p>不知你是不是也有这样的疑惑，我们为什么需要回调函数这个概念呢？直接调用函数不就可以了？回调函数到底有什么作用？为什么回调函数正在变得越来越重要？<br>这篇文章就来为你解答这些问题，<strong>读完这篇文章后你的武器库将新增一件功能强大的利器</strong>。 </p>
<h2 id="一切要从这样的需求说起"><a href="#一切要从这样的需求说起" class="headerlink" title="一切要从这样的需求说起"></a>一切要从这样的需求说起</h2><p>假设你们公司要开发下一代国民App“明日油条”，一款主打解决国民早餐问题的App，为了加快开发进度，这款应用由A小组和B小组协同开发。<br>其中有一个核心模块由A小组开发然后供B小组调用，这个核心模块被封装成了一个函数，这个函数就叫make_youtiao()。<br>如果make_youtiao()这个函数执行的很快并可以立即返回，那么B小组的同学只需要： </p>
<ol>
<li>调用make_youtiao() </li>
<li>等待该函数执行完成 </li>
<li>该函数执行完后继续后续流程<br>从程序执行的角度看这个过程是这样的： </li>
<li>保存当前被执行函数的上下文 </li>
<li>开始执行make_youtiao()这个函数 </li>
<li>make_youtiao()执行完后，控制转回到调用函数中<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696743584171-1cc6f77c-b3d5-4e36-b6ed-dba7539bd868.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=513&id=u60a00881&originHeight=513&originWidth=602&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27024&status=done&style=none&taskId=u6cc7e4b1-f894-44ec-a8d6-c5286a3e7c8&title=&width=602" alt="image.png"><br>如果世界上所有的函数都像make_youtiao()这么简单，那么程序员大概率就要失业了，还好程序的世界是复杂的，这样程序员才有了存在的价值。</li>
</ol>
<h2 id="现实情况并不容易（同步、异步）"><a href="#现实情况并不容易（同步、异步）" class="headerlink" title="现实情况并不容易（同步、异步）"></a>现实情况并不容易（同步、异步）</h2><p>现实中make_youtiao()这个函数需要处理的数据非常庞大，假设有10000个，<strong>那么make_youtiao(10000)不会立刻返回</strong>，而是可能需要10分钟才执行完成并返回。<br>这时你该怎么办呢？想一想这个问题。<br>可能有的同学就像把头埋在沙子里的鸵鸟一样：和刚才一样直接调用不可以吗，这样多简单。<br>是的，这样做没有问题，但就像爱因斯坦说的那样“一切都应该尽可能简单，但是不能过于简单”。<br>想一想直接调用会有什么问题？<br>显然直接调用的话，那么调用线程会被阻塞暂停，在等待10分钟后才能继续运行。在这10分钟内该线程不会被操作系统分配CPU，也就是说该线程得不到任何推进。<br>这并不是一种高效的做法。<br>没有一个程序员想死盯着屏幕10分钟后才能得到结果。<br>那么有没有一种更加高效的做法呢？<br>想一想我们上一篇中那个一直盯着你写代码的老板(见《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485709&idx=1&sn=86738d509091e7ff0e0c16d4b9aa354f&source=41#wechat_redirect">从小白到高手，你需要理解同步与异步</a>》)，我们已经知道了这种<strong>一直等待直到另一个任务完成的</strong>模式叫做同步。<br>如果你是老板的话你会什么都不干一直盯着员工写代码吗？因此一种更好的做法是程序员在代码的时候老板该干啥干啥，程序员写完后自然会通知老板，这样老板和程序员都不需要相互等待，这种模式被称为<strong>异步</strong>。<br>回到我们的主题，这里一种更好的方式是<strong>调用make_youtiao()这个函数后不再等待这个函数执行完成</strong>，而是直接返回继续后续流程，这样A小组的程序就可以和make_youtiao()这个函数同时进行了，<br>就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696743726153-e54a8a68-190a-47e9-a905-2580ddc7973d.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=502&id=u7128d6a3&originHeight=502&originWidth=604&originalType=binary&ratio=1&rotation=0&showTitle=false&size=25487&status=done&style=none&taskId=u66d7a6b7-7adf-4cf8-a990-f0ee22db204&title=&width=604" alt="image.png"><br>在这种情况下，回调(callback)就必须出场了</p>
<h2 id="为什么我们需要回调callback"><a href="#为什么我们需要回调callback" class="headerlink" title="为什么我们需要回调callback"></a>为什么我们需要回调callback</h2><p>有的同学可能还没有明白为什么在这种情况下需要回调，别着急，我们慢慢讲。<br>假设我们“明日油条”App代码第一版是这样写的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make_youtiao(<span class="number">10000</span>);</span><br><span class="line">sell();</span><br></pre></td></tr></table></figure>
<p>可以看到这是最简单的写法，意思很简单，制作好油条后卖出去<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696743785562-c2af4492-1a6d-4783-881a-e1fee4e4d90a.png#averageHue=%23ffffff&clientId=u918eaff0-5d89-4&from=paste&height=509&id=ub0e04d1c&originHeight=509&originWidth=697&originalType=binary&ratio=1&rotation=0&showTitle=false&size=30091&status=done&style=none&taskId=u63dc9f17-82cd-4c12-8b29-c1cb5fc96fb&title=&width=697" alt="image.png"><br>我们已经知道了由于make_youtiao(10000)这个函数10分钟才能返回，你不想一直死盯着屏幕10分钟等待结果，那么一种更好的方法是让make_youtiao()这个函数知道制作完油条后该干什么，即，更好的调用make_youtiao的方式是这样的：“制作10000个油条，<strong>炸好后卖出去</strong>”，因此调用make_youtiao就变成这样了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make_youtiao(<span class="number">10000</span>, sell);</span><br></pre></td></tr></table></figure>
<p>看到了吧，现在make_youtiao这个函数多了一个参数，除了指定制作油条的数量外<strong>还可以指定制作好后该干什么</strong>，第二个被make_youtiao这个函数调用的函数就叫回调，callback。<br>现在你应该看出来了吧，虽然sell函数是你定义的，但是这个函数却是被其它模块调用执行的，就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696743862217-b9dd7327-6910-4f07-8e36-e781d869115a.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=631&id=u7db61944&originHeight=631&originWidth=490&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27263&status=done&style=none&taskId=u73aa2a9a-e3ab-459e-b909-580def0b013&title=&width=490" alt="image.png"><br>make_youtiao这个函数是怎么实现的呢，很简单：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">make_youtiao</span><span class="params">(<span class="type">int</span> num, func call_back)</span> &#123;</span><br><span class="line"> <span class="comment">// 制作油条</span></span><br><span class="line"> call_back(); <span class="comment">//执行回调</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样你就不用死盯着屏幕了，因为你把make_youtiao这个函数执行完后该做的任务交代给make_youtiao这个函数了，该函数制作完油条后知道该干些什么，这样就解放了你的程序。<br>有的同学可能还是有疑问，为什么编写make_youtiao这个小组不直接定义sell函数然后调用呢？<br>不要忘了明日油条这个App是由A小组和B小组同时开发的，A小组在编写make_youtiao时怎么知道B小组要怎么用这个模块，假设A小组真的自己定义sell函数就会这样写：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">make_youtiao</span><span class="params">(<span class="type">int</span> num)</span> &#123;</span><br><span class="line"> real_make_youtiao(num);</span><br><span class="line"> sell(); <span class="comment">//执行回调</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>同时A小组设计的模块非常好用，这时C小组也想用这个模块，然而C小组的需求是制作完油条后放到仓库而不是不是直接卖掉，要满足这一需求那么A小组该怎么写呢？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">make_youtiao</span><span class="params">(<span class="type">int</span> num)</span> &#123;</span><br><span class="line"> real_make_youtiao(num);</span><br><span class="line"> </span><br><span class="line"> <span class="keyword">if</span> (Team_B) &#123;</span><br><span class="line"> sell(); <span class="comment">// 执行回调</span></span><br><span class="line"> &#125; <span class="keyword">else</span> <span class="keyword">if</span> (Team_D) &#123;</span><br><span class="line"> store(); <span class="comment">// 放到仓库</span></span><br><span class="line"> &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>故事还没完，假设这时D小组又想使用呢，难道还要接着添加if else吗？这样的话A小组的同学只需要维护make_youtiao这个函数就能做到工作量饱满了，显然这是一种非常糟糕的设计。<br>_TODO bad_图<br>所以你会看到，制作完油条后接下来该做什么不是实现make_youtiao的A小组该关心的事情，很明显只有调用make_youtiao这个函数的使用方才知道。<br>因此make_youtiao的A小组完全可以通过回调函数将接下来该干什么交给调用方实现，A小组的同学只需要针对回调函数这一抽象概念进行编程就好了，这样调用方在制作完油条后不管是卖掉、放到库存还是自己吃掉等等想做什么都可以，<strong>A小组的make_youtiao函数根本不用做任何改动</strong>，因为A小组是针对回调函数这一抽象概念来编程的。<br>以上就是回调函数的作用，当然这也是针对抽象而不是具体实现进行编程这一思想的威力所在。面向对象中的多态本质上就是让你用来针对抽象而不是针对实现来编程的。</p>
<h2 id="异步回调"><a href="#异步回调" class="headerlink" title="异步回调"></a>异步回调</h2><p>故事到这里还没有结束。<br>在上面的示例中，虽然我们使用了回调这一概念，也就是调用方实现回调函数然后再将该函数当做参数传递给其它模块调用。<br>但是，这里依然有一个问题，那就是make_youtiao函数的调用方式依然是同步的，关于同步异步请参考《从小白到高手，你需要理解同步与异步》，也就是说调用方是这样实现的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">make_youtiao(<span class="number">10000</span>, sell);</span><br><span class="line"><span class="comment">// make_youtiao函数返回前什么都做不了</span></span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696744344479-ba5cf427-3a73-4f57-94ce-d6b55aebdc3e.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=631&id=ue7b6f2ce&originHeight=631&originWidth=490&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27263&status=done&style=none&taskId=u79a1b747-3473-4468-bc01-2bb930758e9&title=&width=490" alt="image.png"><br>我们可以看到，调用方必须等待make_youtiao函数返回后才可以继续后续流程，我们再来看下make_youtiao函数的实现：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">make_youtiao</span><span class="params">(<span class="type">int</span> num, func call_back)</span> &#123;</span><br><span class="line"> real_make_youtiao(num);</span><br><span class="line"> call_back(); <span class="comment">//执行回调</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>看到了吧，由于我们要制作10000个油条，make_youtiao函数执行完需要10分钟，也就是说即便我们使用了回调，调用方完全不需要关心制作完油条后的后续流程，但是调用方依然会被阻塞10分钟，<br>这就是同步调用的问题所在。<br>如果你真的理解了上一节的话应该能想到一种更好的方法了。没错，那就是异步调用。<br>反正制作完油条后的后续流程并不是调用方该关心的，也就是说调用方并不关心make_youtiao这一函数的返回值，那么一种更好的方式是：把制作油条的这一任务放到另一个线程(进程)、甚至另一台机器上。<br>如果用线程实现的话，那么make_youtiao就是这样实现了:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">make_youtiao</span><span class="params">(<span class="type">int</span> num, func call_back)</span> &#123;</span><br><span class="line"> <span class="comment">// 在新的线程中执行处理逻辑</span></span><br><span class="line"> create_thread(real_make_youtiao,</span><br><span class="line"> num,</span><br><span class="line"> call_back);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696744449974-283aead4-fb6f-4cdd-8a4d-9d51986175db.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=606&id=u21d3e2af&originHeight=606&originWidth=564&originalType=binary&ratio=1&rotation=0&showTitle=false&size=29573&status=done&style=none&taskId=u42eff883-676d-4daf-8911-579f8889284&title=&width=564" alt="image.png"><br>看到了吧，这时当我们调用make_youtiao时就会<strong>立刻返回</strong>，即使油条还没有真正开始制作，而调用方也完全无需等待制作油条的过程，可以立刻执行后流程：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">make_youtiao(<span class="number">10000</span>, sell);</span><br><span class="line"><span class="comment">// 立刻返回</span></span><br><span class="line"><span class="comment">// 执行后续流程</span></span><br></pre></td></tr></table></figure>
<p>这时调用方的后续流程可以和制作油条<strong>同时</strong>进行，这就是函数的<strong>异步调用</strong>，当然这也是异步的高效之处。</p>
<h2 id="新的编程思维模式"><a href="#新的编程思维模式" class="headerlink" title="新的编程思维模式"></a>新的编程思维模式</h2><p>让我们再来仔细的看一下这个过程。<br>程序员最熟悉的思维模式是这样的： </p>
<ol>
<li>调用某个函数，获取结果 </li>
<li>处理获取到的结果<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">res = request();</span><br><span class="line">handle(res);</span><br></pre></td></tr></table></figure>
这就是函数的同步调用，只有request()函数返回拿到结果后，才能调用handle函数进行处理，request函数返回前我们必须<strong>等待</strong>，这就是同步调用，其控制流是这样的：<img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696744522173-c1d1a3da-e2dc-4f50-a994-d64971890760.png#averageHue=%23f9f1f3&clientId=u918eaff0-5d89-4&from=paste&height=640&id=ucf18e92a&originHeight=640&originWidth=428&originalType=binary&ratio=1&rotation=0&showTitle=false&size=27238&status=done&style=none&taskId=ud1f0684c-a9eb-4f21-9d78-9f7d6bcc6e7&title=&width=428" alt="image.png"><br>但是如果我们想更加高效的话，那么就需要异步调用了，我们不去直接调用handle函数，而是作为参数传递给request：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">request(handle);</span><br></pre></td></tr></table></figure>
我们根本就不关心request什么时候真正的获取的结果，这是request该关心的事情，我们只需要把获取到结果后该怎么处理告诉request就可以了，因此request函数可以立刻返回，真的获取结果的处理可能是在另一个线程、进程、甚至另一台机器上完成。<br>这就是异步调用，其控制流是这样的：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696744564409-72e3ab0b-7379-4740-80fe-cb60471c6199.png#averageHue=%23faf2f4&clientId=u918eaff0-5d89-4&from=paste&height=646&id=u9e9df68c&originHeight=646&originWidth=527&originalType=binary&ratio=1&rotation=0&showTitle=false&size=28112&status=done&style=none&taskId=u1c74855b-5f93-46f5-8b12-7f34bb74adb&title=&width=527" alt="image.png"><br>从编程思维上看，异步调用和同步有很大的差别，如果我们把处理流程当做一个任务来的话，那么同步下整个任务都是我们来实现的，但是异步情况下任务的处理流程被分为了两部分： </li>
<li>第一部分是我们来处理的，也就是调用request之前的部分 </li>
<li>第二部分不是我们处理的，而是在其它线程、进程、甚至另一个机器上处理的<br>我们可以看到由于任务被分成了两部分，第二部分的调用不在我们的掌控范围内，同时只有调用方才知道该做什么，因此在这种情况下回调函数就是一种必要的机制了。<br>也就是说回调函数的本质就是“只有我们才知道做些什么，但是我们并不清楚什么时候去做这些，只有其它模块才知道，因此我们必须把我们知道的封装成回调函数告诉其它模块”。<br>现在你应该能看出异步回调这种编程思维模式和同步的差异了吧。<br>接下来我们给回调一个较为学术的定义<br>**正式定义 **<blockquote>
<p>在计算机科学中，回调函数是指一段以参数的形式传递给其它代码的可执行代码。</p>
</blockquote>
</li>
</ol>
<p>这就是回调函数的定义了。<br>回调函数就是一个函数，和其它函数没有任何区别。<br>注意，回调函数是一种软件设计上的概念，和某个编程语言没有关系，几乎所有的编程语言都能实现回调函数。<br>对于一般的函数来说，我们自己编写的函数会在自己的程序内部调用，也就是说函数的编写方是我们自己，调用方也是我们自己。<br>但回调函数不是这样的，虽然函数编写方是我们自己，但是函数调用方不是我们，而是我们引用的其它模块，也就是第三方库，我们调用第三方库中的函数，并把回调函数传递给第三方库，第三方库中的函数调用我们编写的回调函数，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696746762438-03494125-eb1c-4ed7-9f31-fc9123e33ca5.png#averageHue=%23dedede&clientId=u918eaff0-5d89-4&from=paste&height=530&id=ud1fac485&originHeight=530&originWidth=873&originalType=binary&ratio=1&rotation=0&showTitle=false&size=33226&status=done&style=none&taskId=ub722c859-4b73-40e4-bf7d-4c89fe8f6e0&title=&width=873" alt="image.png"><br>而之所以需要给第三方库指定回调函数，是因为第三方库的编写者并不清楚在某些特定节点，比如我们举的例子油条制作完成、接收到网络数据、文件读取完成等之后该做什么，这些只有库的使用方才知道，因此第三方库的编写者无法针对具体的实现来写代码，而只能对外提供一个回调函数，库的使用方来实现该函数，第三方库在特定的节点调用该回调函数就可以了。<br>另一点值得注意的是，从图中我们可以看出回调函数和我们的主程序位于<strong>同一层</strong>中，我们只负责编写该回调函数，但并不是我们来调用的。<br>最后值得注意的一点就是回调函数被调用的时间节点，回调函数只在某些特定的节点被调用，就像上面说的油条制作完成、接收到网络数据、文件读取完成等，这些都是事件，也就是event，本质上我们编写的回调函数就是用来处理event的，因此从这个角度看回调函数不过就是event handler，因此回调函数天然适用于事件驱动编程event-driven，我们将会在后续文章中再次回到这一主题。</p>
<h2 id="回调的类型"><a href="#回调的类型" class="headerlink" title="回调的类型"></a>回调的类型</h2><p>我们已经知道有两种类型的回调，这两种类型的回调区别在于回调函数被调用的时机。</p>
<h3 id="同步回调"><a href="#同步回调" class="headerlink" title="同步回调"></a>同步回调</h3><p>这种回调就是通常所说的同步回调synchronous callbacks、也有的将其称为<strong>阻塞式回调</strong>blocking callbacks，或者什么修饰都没有，就是回调，callback，这是我们最为熟悉的回调方式。<br>当我们调用某个函数A并以参数的形式传入回调函数后，在A返回之前回调函数会被执行，也就是说我们的主程序会等待回调函数执行完成，这就是所谓的同步回调。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696746881834-82b69a51-f1ca-40cb-ac7e-0e83c12df092.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=749&id=u77f8af56&originHeight=749&originWidth=759&originalType=binary&ratio=1&rotation=0&showTitle=false&size=44704&status=done&style=none&taskId=uaaeda5ac-cc7b-4d64-b036-ca72a69bb29&title=&width=759" alt="image.png"></p>
<h3 id="异步回调-1"><a href="#异步回调-1" class="headerlink" title="异步回调"></a>异步回调</h3><p>不同于同步回调， 当我们调用某个函数A并以参数的形式传入回调函数后，A函数会立刻返回，也就是说函数A并不会阻塞我们的主程序，一段时间后回调函数开始被执行，此时我们的主程序可能在忙其它任务，回调函数的执行和我们主程序的运行同时进行。<br>既然我们的主程序和回调函数的执行可以同时发生，因此一般情况下，主程序和回调函数的执行位于不同的线程或者进程中。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696746922243-1bac39ae-280b-4506-919e-9d868b61ce7c.png#averageHue=%23fefefe&clientId=u918eaff0-5d89-4&from=paste&height=764&id=ua6619fc5&originHeight=764&originWidth=759&originalType=binary&ratio=1&rotation=0&showTitle=false&size=42693&status=done&style=none&taskId=ub9fade09-c9fc-4e78-858d-db248bd244d&title=&width=759" alt="image.png"><br>这就是所谓的异步回调，asynchronous callbacks，也有的资料将其称为deferred callbacks ，名字很形象，延迟回调。<br>从上面这两张图中我们也可以看到，异步回调要比同步回调更能充分的利用机器资源，原因就在于在同步模式下主程序会“偷懒”，因为调用其它函数被阻塞而暂停运行，但是异步调用不存在这个问题，主程序会一直运行下去。<br>因此，异步回调更常见于I&#x2F;O操作，天然适用于Web服务这种高并发场景。</p>
<h2 id="为什么异步回调这种思维模式正变得的越来越重要"><a href="#为什么异步回调这种思维模式正变得的越来越重要" class="headerlink" title="为什么异步回调这种思维模式正变得的越来越重要"></a>为什么异步回调这种思维模式正变得的越来越重要</h2><p>在同步模式下，服务调用方会因服务执行而被阻塞暂停执行，这会导致整个线程被阻塞，因此这种编程方式天然不适用于高并发动辄几万几十万的并发连接场景，<br>针对高并发这一场景，异步其实是更加高效的，原因很简单，你不需要在原地等待，因此从而更好的利用机器资源，而回调函数又是异步下不可或缺的一种机制。</p>
<h2 id="回调地狱，callback-hell"><a href="#回调地狱，callback-hell" class="headerlink" title="回调地狱，callback hell"></a>回调地狱，callback hell</h2><p>有的同学可能认为有了异步回调这种机制应付起一切高并发场景就可以高枕无忧了。<br>实际上在计算机科学中还没有任何一种可以横扫一切包治百病的技术，现在没有，在可预见的将来也不会有，一切都是妥协的结果。<br>那么异步回调这种机制有什么问题呢？<br>实际上我们已经看到了，异步回调这种机制和程序员最熟悉的同步模式不一样，在可理解性上比不过同步，而如果业务逻辑相对复杂，比如我们处理某项任务时不止需要调用一项服务，而是几项甚至十几项，如果这些服务调用都采用异步回调的方式来处理的话，那么很有可能我们就陷入回调地狱中。<br>举个例子，假设处理某项任务我们需要调用四个服务，每一个服务都需要依赖上一个服务的结果，如果用同步方式来实现的话可能是这样的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">a = GetServiceA();</span><br><span class="line">b = GetServiceB(a);</span><br><span class="line">c = GetServiceC(b);</span><br><span class="line">d = GetServiceD(c);</span><br></pre></td></tr></table></figure>
<p>代码很清晰，很容易理解有没有。<br>我们知道异步回调的方式会更加高效，那么使用异步回调的方式来写将会是什么样的呢？</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">GetServiceA(function(a)&#123;</span><br><span class="line">     GetServiceB(a, function(b)&#123;</span><br><span class="line">         GetServiceC(b, function(c)&#123;</span><br><span class="line">             GetServiceD(c, function(d) &#123;</span><br><span class="line"> 					....</span><br><span class="line"> 			 &#125;);</span><br><span class="line"> 	 	&#125;);</span><br><span class="line"> 	 &#125;);</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure>
<p>我想不需要再强调什么了吧，你觉得这两种写法哪个更容易理解，代码更容易维护呢？<br>博主有幸曾经维护过这种类型的代码，不得不说每次增加新功能的时候恨不得自己化为两个分身，一个不得不去重读一边代码；另一个在一旁骂自己为什么当初选择维护这个项目。<br>异步回调代码稍不留意就会跌到回调陷阱中，那么有没有一种更好的办法既能结合异步回调的高效又能结合同步编码的简单易读呢？<br>幸运的是，答案是肯定的，我们会在后续文章中详细讲解这一技术。</p>
<h2 id="总结-3"><a href="#总结-3" class="headerlink" title="总结"></a>总结</h2><p>在这篇文章中，我们从一个实际的例子出发详细讲解了回调函数这种机制的来龙去脉，这是应对高并发、高性能场景的一种极其重要的编码机制，异步加回调可以充分利用机器资源，实际上异步回调最本质上就是事件驱动编程，这是我们接下来要重点讲解的内容。</p>
<h1 id="六、自己动手实现malloc内存分配器"><a href="#六、自己动手实现malloc内存分配器" class="headerlink" title="六、自己动手实现malloc内存分配器"></a>六、自己动手实现malloc内存分配器</h1><p><strong>对内存分配器透彻理解是编程高手的标志之一</strong>。<br>如果你不能理解malloc之类内存分配器实现原理的话，那你可能写不出高性能程序，写不出高性能程序就很难参与核心项目，参与不了核心项目那么很难升职加薪，很难升级加薪就无法走向人生巅峰， 没想到内存分配竟如此关键，为了走上人生巅峰你也要势必读完本文。<br>现在我们知道了，对内存分配器透彻的理解是写出高性能程序的关键所在，那么我们该怎样透彻理解内存分配器呢？<br><strong>还有什么能比你自己动手实现一个理解的更透彻吗</strong>？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696747209263-2406abbf-894b-48d9-8747-a2065e95f509.png#averageHue=%23715c47&clientId=u918eaff0-5d89-4&from=paste&height=439&id=u6aa458dc&originHeight=439&originWidth=780&originalType=binary&ratio=1&rotation=0&showTitle=false&size=443866&status=done&style=none&taskId=ub8094fc3-2b50-4a98-8ec9-d59c346221d&title=&width=780" alt="image.png"><br>接下来，我们就自己实现一个malloc内存分配器。读完本文后内存分配对你将不再是一个神秘的黑盒。<br>在讲解实现原理之前，我们需要回答一个基本问题，那就是我们为什么要发明内存分配器这种东西。</p>
<h2 id="内存申请与释放"><a href="#内存申请与释放" class="headerlink" title="内存申请与释放"></a>内存申请与释放</h2><p>程序员经常使用的内存申请方式被称为<strong>动态内存分配</strong>，Dynamic Memory Allocation。我们为什么需要动态的去进行内存分配与释放呢？<br>答案很简单，因为我们不能<strong>提前知道程序到底需要使用多少内存</strong>。那我们什么时候才能知道呢？答案是只有当程序真的<strong>运行</strong>起来后我们才知道。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696747247416-8f07183d-4f12-4c35-8215-6bd84e937e80.png#averageHue=%23f9fcfa&clientId=u918eaff0-5d89-4&from=paste&height=656&id=u64a4f93d&originHeight=656&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=239497&status=done&style=none&taskId=u15bea236-110a-489a-a736-0aaa38ae53c&title=&width=1080" alt="image.png"><br>这就是为什么程序员需要动态的去申请内存的原因，如果能提前知道我们的程序到底需要多少内存，那么直接知道告诉编译器就好了，这样也不必发明malloc等内存分配器了。<br>知道了为什么要发明内存分配器的原因后，接下来我们着手实现一个。</p>
<h2 id="程序员应如何看待内存"><a href="#程序员应如何看待内存" class="headerlink" title="程序员应如何看待内存"></a>程序员应如何看待内存</h2><p>实际上，现代程序员是很幸福的，程序员很少去关心内存分配的问题。作为程序员，<strong>可以简单的认为我们的程序独占内存，注意，是独占哦</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696747846285-bb322360-77bf-43a3-9855-c3aa885361f7.png#averageHue=%237c9bb9&clientId=u918eaff0-5d89-4&from=paste&height=712&id=ubeb7033b&originHeight=712&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=384750&status=done&style=none&taskId=u138120f4-d756-4fd8-ac11-7fe75b70bda&title=&width=1080" alt="image.png"><br>写程序时你从来没有关心过如果我们的程序占用过多内存会不会影响到其它程序，我们可以简单的认为每个程序(进程)独占4G内存(32位操作系统)，即使我们的物理内存512M。不信你可以去试试，<strong>在即使只有512M大小的内存上你依然可以申请到2G内存来使用</strong>，可这是为什么呢？关于这个问题我们会在《深入理解操作系统》系列中详细阐述。<br>总之，程序员可以<strong>放心的</strong>认为我们的程序运行起来后在内存中是这样的：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696747879415-34a3f28e-52f6-4a06-8bdb-035f0fccde3e.png#averageHue=%23629bf2&clientId=u918eaff0-5d89-4&from=paste&height=576&id=u59af00a2&originHeight=576&originWidth=389&originalType=binary&ratio=1&rotation=0&showTitle=false&size=93052&status=done&style=none&taskId=u9f280f15-e8c9-46d5-9719-fdab43d61b3&title=&width=389" alt="image.png"><br>作为程序员我们应该知道，内存动态申请和释放都发生在堆区，heap。<br><strong>我们使用的malloc或者C++中的new申请内存时，就是从堆区这个区域中申请的</strong>。<br>接下来我们就要自己管理堆区这个内存区域。<br>堆区这个区域实际上非常简单，真的是非常简单，你可以将其看做一大数组，就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696747903754-2a46f875-1ee7-4503-bab4-24504c6e8436.png#averageHue=%23f5fafb&clientId=u918eaff0-5d89-4&from=paste&height=672&id=u8e92c950&originHeight=672&originWidth=696&originalType=binary&ratio=1&rotation=0&showTitle=false&size=178736&status=done&style=none&taskId=uf26a5382-2886-430a-944b-684aaf1d8a2&title=&width=696" alt="image.png"><br>从内存分配器的角度看，<strong>内存分配器根本不关心你是整数、浮点数、链表、二叉树等数据结构、还是对象、结构体等这些花哨的概念，</strong>在内存分配器眼里不过就是一个内存块，这些内存块中可以装入原生的字节序列，申请者拿到该内存块后可以塑造成整数、浮点数、链表、二叉树等数据结构以及对象、结构体等，这是使用者的事情，和内存分配器无关。<br>我们要在这片内存上解决两个问题：<br>实现一个malloc函数，也就是如果有人向我申请一块内存，我该怎样从堆区这片区域中找到一块返回给申请者。<br>实现一个free函数，也就是当某一块内存使用完毕后，我该怎样还给堆区这片区域。<br>这是内存分配器要解决的两个最核心的问题，接下来我们先去停车场看看能找到什么启示。</p>
<h2 id="从停车场到内存管理"><a href="#从停车场到内存管理" class="headerlink" title="从停车场到内存管理"></a>从停车场到内存管理</h2><p>实际上你可以把内存看做一条长长的<strong>停车场</strong>，我们申请内存就是要找到一块停车位，释放内存就是把开走让出停车位。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696747981066-be7d894e-4ba1-4518-a4d6-93375c81a1f6.png#averageHue=%236c6f6b&clientId=u918eaff0-5d89-4&from=paste&height=359&id=u68d592c9&originHeight=359&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=664901&status=done&style=none&taskId=u31218445-b913-41cc-86bf-8b5f7a57dd6&title=&width=1080" alt="image.png"><br>只不过这个停车场比较特殊，我们不止可以停小汽车、也可以停占地面积很小的自行车以及占地面积很大的卡车，重点就是申请的内存是<strong>大小不一</strong>的，在这样的条件下你该怎样实现以下两个目标呢？<br>快速找到停车位，在内存申请中，这涉及到以最大速度找到一块满足要求的空闲内存<br>尽最大程度利用停车场，我们的停车场应该能停尽可能多的车，在内存申请中，这涉及到在给定条件下尽可能多的满足内存申请需求<br>现在，我们已经清楚的理解任务了，那么该怎么实现呢</p>
<h2 id="任务拆分"><a href="#任务拆分" class="headerlink" title="任务拆分"></a>任务拆分</h2><p>现在我们已经明确要实现什么以及衡量其好坏的标准，接下来我们就要去设计实现细节了，让我们把任务拆分一下，怎么拆分呢？<br>我们可以自己想一下从内存的申请到释放需要哪些细节。<br>申请内存时，我们需要在内存中找到一块大小合适的空闲内存分配出去，那么<strong>我们怎么知道有哪些内存块是空闲的呢</strong>？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696748497523-ed7fba72-f979-44fc-846e-1ac7020fe71e.png#averageHue=%23fcfefc&clientId=u918eaff0-5d89-4&from=paste&height=665&id=u14dbb996&originHeight=665&originWidth=409&originalType=binary&ratio=1&rotation=0&showTitle=false&size=100083&status=done&style=none&taskId=u957b4a01-a46b-466f-9354-e840e4f7650&title=&width=409" alt="image.png"><br>因此，第一个实现细节出现了，<strong>我们需要把内存块用某种方式组织起来，这样我们才能追踪到每一块内存的分配状态</strong>。<br>现在空闲内存块组织好了，那么一次内存申请可能有很多空闲内存块满足要求，那么我们该选择哪一个空闲内存块分配给用户呢？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696748693669-9e11df55-7ddb-494b-a2b8-9a60a0221571.png#averageHue=%23fbfefd&clientId=u918eaff0-5d89-4&from=paste&height=503&id=u218427d5&originHeight=503&originWidth=876&originalType=binary&ratio=1&rotation=0&showTitle=false&size=133804&status=done&style=none&taskId=u46f3d120-aa9d-4bef-8c34-1a994339f25&title=&width=876" alt="image.png"><br>因此，第二个实现细节出现了，<strong>我们该选择什么样的空闲内存块给到用户</strong>。<br>接下来我们找到了一块大小合适的内存块，假设用户需要16个字节，而我们找到的这块空闲内存块大小为32字节，那么将16字节分配给用户后还剩下16字节，这剩下的内存该怎么处理呢？<br>因此，第三个实现细节出现了，分配出去内存后，<strong>空闲内存块剩余的空间该怎么处理?</strong><br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696748724819-b127ca31-8552-42cf-b55a-4f3f4bd83f03.png#averageHue=%23a1afc1&clientId=u918eaff0-5d89-4&from=paste&height=395&id=ue3bf51f6&originHeight=395&originWidth=876&originalType=binary&ratio=1&rotation=0&showTitle=false&size=145921&status=done&style=none&taskId=ub05972a9-6804-424a-a470-9081ca35049&title=&width=876" alt="image.png"><br>最后，分配给用户的内存使用完毕，这是第四个细节出现了，<strong>我们该怎么处理用户还给我们的内存呢</strong>？<br>以上四个问题是任何一个内存分配器必须要回答的，接下来我们就一一解决这些问题，解决完这些问题后一个崭新的内存分配器就诞生啦。</p>
<h2 id="管理空闲内存块-负载"><a href="#管理空闲内存块-负载" class="headerlink" title="管理空闲内存块(负载)"></a>管理空闲内存块(<strong>负载</strong>)</h2><p>空闲内存块的本质是需要某种办法来来区分哪些是空闲内存哪些是已经分配出去的内存。<br>有的同学可能会说，这还不简单吗，用一个链表之类的结构记录下每个空闲内存块的开始和结尾不就可以了，这句话也对也不对。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696748769113-9f636c32-e63f-4e4b-8ed7-a882d362ff8f.png#averageHue=%23edf0ed&clientId=u918eaff0-5d89-4&from=paste&height=117&id=ucee32e2e&originHeight=117&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=104662&status=done&style=none&taskId=ufdf13f8c-bdb7-487a-b421-7130a22c935&title=&width=1080" alt="image.png"><br>说不对，是因为如果要申请内存来创建这个链表那么这就是不对的，原因很简单，因为创建链表不可避免的要申请内存，申请内存就需要通过内存分配器，可是你要实现的就是一个内存分配器，<strong>你没有办法向一个还没有实现的内存分配器申请内存</strong>。<br>说对也对，我们确实需要一个类似链表这样的结构来维护空闲内存块，但这个链表并不是我们常见的那种。<br>因为我们无法将空闲内存块的信息保存在其它地方，那么没有办法，<strong>我们只能将维护内存块的分配信息保存在内存块本身中</strong>，这也是大多数内存分配器的实现方法。<br>那么，为了维护内存块分配状态，我们需要知道哪些信息呢？很简单：<br>一个标记，用来标识该内存块是否空闲<br>一个数字，用来记录该内存块的大小<br>为了简单起见，我们的内存分配器不对内存对齐有要求，同时一次内存申请允许的最大内存块为2G，<strong>注意，这些假设是为了方便讲解内存分配器的实现而屏蔽一些细节，我们常用的malloc等不会有这样的限制</strong>。<br>因为我们的内存块大小上限为2G，因此我们可以使用31个比特位来记录块大小，剩下的一个比特位用来标识该内存块是空闲的还是已经被分配出去了，下图中的f&#x2F;a是free&#x2F;allocate，也就是标记是已经分配出去还是空闲的。这32个比特位就是header，用来存储块信息。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696748930808-692af6af-5df4-4df2-9f09-cefde589042e.png#averageHue=%2383a4d7&clientId=u918eaff0-5d89-4&from=paste&height=386&id=ucf1c0187&originHeight=386&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=155080&status=done&style=none&taskId=ue9fe535a-08a9-4475-9954-b5db6704e83&title=&width=1080" alt="image.png"><br><strong>剩下的灰色部分才是真正可以分配给用户的内存</strong>，这一部分也被称为<strong>负载</strong>，payload，<strong>我们调用malloc返回的内存起始地址正是这块内存的起始地址</strong>。<br>现在你应该知道了吧，不是说堆上有10G内存，这里面就可以全部用来存储数据的，这里面必然有一部分要拿出来维护内存块的一些信息，就像这里的header一样。</p>
<h2 id="跟踪内存分配状态"><a href="#跟踪内存分配状态" class="headerlink" title="跟踪内存分配状态"></a>跟踪内存分配状态</h2><p>有了上图，<strong>我们就可以将堆这块内存区域组织起来并进行内存分配与释放了</strong>，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749211606-02d035fb-8c7e-4e53-93f2-bf8329ed1774.png#averageHue=%237ea7e4&clientId=u918eaff0-5d89-4&from=paste&height=661&id=u62e84363&originHeight=661&originWidth=685&originalType=binary&ratio=1&rotation=0&showTitle=false&size=228803&status=done&style=none&taskId=uf371501b-4d0f-4a16-a37c-61af26afa4d&title=&width=685" alt="image.png"><br>在这里我们的堆区还很小，每一方框代表4字节，其中红色区域表示已经分配出去的，灰色区域表示空闲内存，每一块内存都有一个header，用带斜线的方框表示，比如16&#x2F;1，就表示该内存块大小是16字节，1表示已经分配出去了；而32&#x2F;0表示该内存块大小是32字节，0表示该内存块当前空闲。<br>细心的同学可能会问，那最后一个方框0&#x2F;1表示什么呢？原来，我们需要某种特殊标记来告诉我们的内存分配器是不是已经到末尾了，这就是最后4字节的作用。<br>通过引入header我们就能知道每一个内存块的大小，从而可以很方便的遍历整个堆区。遍历方法很简单，因为我们知道每一块的大小，那么从当前的位置加上当前块的大小就是下一个内存块的起始位置，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749264468-4d0b8343-94d9-4575-b269-dfd7abb3f2fd.png#averageHue=%23b1bccb&clientId=u918eaff0-5d89-4&from=paste&height=678&id=u585e238f&originHeight=678&originWidth=271&originalType=binary&ratio=1&rotation=0&showTitle=false&size=149697&status=done&style=none&taskId=u4932eb4c-620d-4843-94a6-e395160824e&title=&width=271" alt="image.png"><br>通过每一个header的最后一个bit位就能知道每一块内存是空闲的还是已经分配出去了，这样我们就能追踪到每一个内存块的分配信息，因此上文提到的第一个问题解决了。<br>接下来我们看第二个问题。</p>
<h2 id="怎样选择空闲内存块"><a href="#怎样选择空闲内存块" class="headerlink" title="怎样选择空闲内存块"></a>怎样选择空闲内存块</h2><p>当应用程序调用我们实现的malloc时，内存分配器需要遍历整个空闲内存块找到一块能满足应用程序要求的内存块返回，就像下图这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749342736-3e60190c-fcff-4810-b472-cd404c8713dd.png#averageHue=%23adb9c9&clientId=u918eaff0-5d89-4&from=paste&height=662&id=u10adf63b&originHeight=662&originWidth=207&originalType=binary&ratio=1&rotation=0&showTitle=false&size=131991&status=done&style=none&taskId=u9cf02b17-b556-4313-961d-795add655f0&title=&width=207" alt="image.png"><br>假设应用程序需要申请4字节内存，从图中我们可以看到有两个空闲内存块满足要求，第一个大小为8字节的内存块和第三个大小为32字节的内存块，那么我们到底该选择哪一个返回呢？这就涉及到了分配策略的问题，实际上这里有很多的策略可供选择。</p>
<h3 id="首次适应方法-First-Fit"><a href="#首次适应方法-First-Fit" class="headerlink" title="首次适应方法 First Fit"></a>首次适应方法 First Fit</h3><p>最简单的就是<strong>每次从头开始找起</strong>，找到第一个满足要求的就返回，这就是所谓的First fit方法，教科书中一般称为首次适应方法，当然我们不需要记住这样拗口的名字，只需要记住这是什么意思就可以了<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749426536-ba2d3402-63a1-4e72-b319-2f6167ef5524.png#averageHue=%239eabbf&clientId=u918eaff0-5d89-4&from=paste&height=656&id=ud393d546&originHeight=656&originWidth=1031&originalType=binary&ratio=1&rotation=0&showTitle=false&size=258342&status=done&style=none&taskId=u986c8166-f9bb-4752-b098-3cb04c34332&title=&width=1031" alt="image.png"><br>这种方法的优势在于<strong>简单</strong>，但该策略总是从前面的空闲块找起，因此很容易在堆区前半部分因分配出内存留下很多小的内存块，因此下一次内存申请搜索的空闲块数量将会越来越多。</p>
<h3 id="Next-Fit"><a href="#Next-Fit" class="headerlink" title="Next Fit"></a>Next Fit</h3><p>该方法是大名鼎鼎的Donald Knuth首次提出来的，如果你不知道谁是Donald Knuth，那么数据结构课上折磨的你痛不欲生的字符串匹配KMP算法你一定不会错过，KMP其中的K就是指Donald Knuth，该算法全称<strong>Knuth–Morris–Pratt string-searching algorithm</strong>，如果你也没听过KMP算法那么你<br>一定听过下面这本书：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749480252-cc890edb-4f95-401f-926a-f4cfd76189d5.png#averageHue=%23d3d3d3&clientId=u918eaff0-5d89-4&from=paste&height=746&id=ufc0ae711&originHeight=746&originWidth=781&originalType=binary&ratio=1&rotation=0&showTitle=false&size=424060&status=done&style=none&taskId=uf7c9461d-f861-4044-998b-879281b5a08&title=&width=781" alt="image.png"><br>这就是更加大名鼎鼎的《计算机程序设计艺术》，这本书就是Donald Knuth写的，如果你没有听过这本书请面壁思过一分钟，比尔盖茨曾经说过，如果你看懂了这本书就去给微软投简历吧，这本书也是很多程序员买回来后从来不会翻一眼只是拿来当做镇宅之宝用的。<br>不止比尔盖茨，有一次乔布斯见到Knuth老爷子后。。算了，扯远了，有机会再和大家讲这个故事，拉回来。<br>Next Fit说的是什么呢？这个策略和First Fit很相似，是说我们别总是从头开始找了，而是从上一次找到合适的空闲内存块的位置找起，老爷子观察到上一次找到某个合适的内存块的地方很有可能剩下的内存块能满足接下来的内存分配请求，由于不需要从头开始搜索，因此<strong>Next Fit将远快于First Fit。</strong><br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749532208-ff756ec4-006f-4e59-a441-925e819c836e.png#averageHue=%23b5c1d0&clientId=u918eaff0-5d89-4&from=paste&height=681&id=u69d46286&originHeight=681&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=300396&status=done&style=none&taskId=u459960ad-f712-4756-8fdc-93011a559e1&title=&width=1080" alt="image.png"><br>然而也有研究表明Next Fit方法内存使用率不及First Fit，也就是同样的停车场面积，First Fit方法能停更多的车。<br>**Best Fit **<br>First Fit和Next Fit都是找到第一个满足要求的内存块就返回，但Best Fit不是这样。<br>Best Fit算法会找到所有的空闲内存块，然后将所有满足要求的并且大小为最小的那个空闲内存块返回，这样的空闲内存块才是最Best的，因此被称为Best Fit。就像下图虽然有三个空闲内存块满足要求，但是Best Fit会选择大小为8字节的空闲内存块。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749675885-0ad4ff41-0b60-48e0-9417-b88821f9a812.png#averageHue=%23fbfefd&clientId=u918eaff0-5d89-4&from=paste&height=503&id=uea570ae6&originHeight=503&originWidth=876&originalType=binary&ratio=1&rotation=0&showTitle=false&size=133804&status=done&style=none&taskId=u1360c2cd-f754-42ee-9a02-c282d660932&title=&width=876" alt="image.png"><br>显然，从直觉上我们就能得出Best Fit会比前两种方法能更合理利用内存的结论，各项研究也证实了这一点。<br>然而Best Fit最大的缺点就是分配内存时需要遍历堆上所有的空闲内存块，在速度上显然不及前面两种方法。<br>以上介绍的这三种策略在各种内存分配器中非常常见，当然分配策略远不止这几种，但这些算法不是该主题下关注的重点，因此就不在这里详细阐述了，假设在这里我们选择First Fit算法。</p>
<h2 id="没有银弹"><a href="#没有银弹" class="headerlink" title="没有银弹"></a>没有银弹</h2><p>重要的是，从上面的介绍中我们能够看到，<strong>没有一种完美的策略</strong>，每一种策略都有其优点和缺点，<strong>我们能做到的只有取舍和权衡</strong>。因此，要实现一个内存分配器，设计空间其实是非常大的，要想设计出一个通用的内存分配器，就像我们常用的malloc是很不容易的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749707170-ca6c24e8-8212-43ec-a3ed-9b81a6f18a02.png#averageHue=%23a8abaf&clientId=u918eaff0-5d89-4&from=paste&height=141&id=ucc951bfe&originHeight=141&originWidth=357&originalType=binary&ratio=1&rotation=0&showTitle=false&size=57899&status=done&style=none&taskId=uc4b1cdee-c887-47f2-8f51-d8185753cdc&title=&width=357" alt="image.png"><br>其实不止内存分配器，在设计其它软件系统时我们也没有银弹。</p>
<h2 id="分配内存"><a href="#分配内存" class="headerlink" title="分配内存"></a>分配内存</h2><p>现在我们找到合适的空闲内存块了，接下来我们又将面临一个新的问题。<br>如果用户需要12字节，而我们的空闲内存块也恰好是12字节，那么很好，直接返回就可以了。<br>但是，如果用户申请12字节内存，而我们找到的空闲内存块大小为32字节，那么我们是要将这32字节的整个空闲内存块标记为已分配吗？就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749757408-8c90c365-e571-4d3e-9b2f-5b056dc7bc00.png#averageHue=%23acb8c9&clientId=u918eaff0-5d89-4&from=paste&height=571&id=u41422e13&originHeight=571&originWidth=914&originalType=binary&ratio=1&rotation=0&showTitle=false&size=250325&status=done&style=none&taskId=u87d2581e-fe89-4515-a949-16f82531dad&title=&width=914" alt="image.png"><br>这样虽然速度最快，但显然会浪费内存，形成<strong>内部碎片</strong>，也就是说该内存块剩下的空间将无法被利用到。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749767804-42bab961-8026-4c01-8f79-5de76cb8e52b.png#averageHue=%23e2e9ed&clientId=u918eaff0-5d89-4&from=paste&height=578&id=uf043bd0f&originHeight=578&originWidth=917&originalType=binary&ratio=1&rotation=0&showTitle=false&size=298783&status=done&style=none&taskId=uc1e190f4-ede8-438b-9a25-25c0c9dfdf1&title=&width=917" alt="image.png"><br>一种显而易见的方法就是将空闲内存块进行划分，前一部分设置为已分配，返回给内存申请者使用，后一部分变为一个新的空闲内存块，只不过大小会更小而已，就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749779622-0e3bc32a-c1de-4058-818b-d1d0bfa40d2d.png#averageHue=%23f6fafa&clientId=u918eaff0-5d89-4&from=paste&height=574&id=ue1817297&originHeight=574&originWidth=912&originalType=binary&ratio=1&rotation=0&showTitle=false&size=271622&status=done&style=none&taskId=u68853531-8584-42d9-9864-49db0788bda&title=&width=912" alt="image.png"><br>我们需要将空闲内存块大小从32修改为16，其中消息头header占据4字节，剩下的12字节分配出去，并将标记为置为1，表示该内存块已分配。<br>分配出16字节后，还剩下16字节，我们需要拿出4字节作为新的header并将其标记为空闲内存块。</p>
<h2 id="释放内存"><a href="#释放内存" class="headerlink" title="释放内存"></a>释放内存</h2><p>到目前为止，我们的malloc已经能够处理内存分配请求了，还差最后的内存释放。<br>内存释放和我们想象的不太一样，该过程并不比前几个环节简单。我们要考虑到的关键一点就在于，与被释放的内存块相邻的内存块可能也是空闲的。如果释放一块内存后我们仅仅简单的将其标志位置为空闲，那么可能会出现下面的场景：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749872362-5e45fbd9-a666-4c04-a042-e063851d804a.png#averageHue=%23f9fdfc&clientId=u918eaff0-5d89-4&from=paste&height=486&id=ud06172d6&originHeight=486&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=259555&status=done&style=none&taskId=ua3de8ac7-4510-490f-bc99-9f25103ebff&title=&width=1080" alt="image.png"><br>从图中我们可以看到，被释放内存的下一个内存块也是空闲的，如果我们仅仅将这16个字节的内存块标记为空闲的话，那么当下一次申请20字节时图中的这两个内存块都不能满足要求，尽管这两个空闲内存块的总数要超过20字节。<br>因此一种更好的方法是当应用程序向我们的malloc释放内存时，我们查看一下相邻的内存块是否是空闲的，<strong>如果是空闲的话我们需要合并空闲内存块</strong>，就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749904545-9f1669b3-ac61-400e-9866-845ffe589ed2.png#averageHue=%23eff4f5&clientId=u918eaff0-5d89-4&from=paste&height=480&id=u0d37bd89&originHeight=480&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=245071&status=done&style=none&taskId=ude650edb-c218-4bd6-83f2-6800ac88e1a&title=&width=1080" alt="image.png"><br>在这里我们又面临一个新的决策，那就是释放内存时我们要立即去检查能否够合并相邻空闲内存块吗？还是说我们可以推迟一段时间，推迟到下一次分配内存找不到满足要的空闲内存块时再合并相邻空闲内存块。<br>释放内存时立即合并空闲内存块相对简单，但每次释放内存时将引入合并内存块的开销，如果应用程序总是释放12字节然后申请12字节，然后在释放12字节等等这样重复的模式：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">free</span>(ptr);obj* ptr = <span class="built_in">malloc</span>(<span class="number">12</span>);<span class="built_in">free</span>(ptr);obj* ptr = <span class="built_in">malloc</span>(<span class="number">12</span>);...</span><br></pre></td></tr></table></figure>
<p><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696749976823-8668e4e4-f68e-4d90-ba7b-9657ea2a44e7.png#averageHue=%23fefefc&clientId=u918eaff0-5d89-4&from=paste&height=723&id=u26a4483d&originHeight=723&originWidth=941&originalType=binary&ratio=1&rotation=0&showTitle=false&size=277231&status=done&style=none&taskId=ud61ef909-7f16-41f0-821a-5e3585c599b&title=&width=941" alt="image.png"><br>那么这种内存使用模式对立即合并空闲内存块这种策略非常不友好，我们的内存分配器会有很多的<strong>无用功</strong>。但这种策略最为简单，在这里我们依然选择使用这种简单的策略。<br>实际上我们需要意识到，实际使用的内存分配器都会有某种推迟合并空闲内存块的策略。</p>
<h2 id="高效合并空闲内存块"><a href="#高效合并空闲内存块" class="headerlink" title="高效合并空闲内存块"></a>高效合并空闲内存块</h2><p>合并空闲内存块的故事到这里就完了吗？问题没有那么简单。<br>让我们来看这样一个场景：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750007793-d19ee68f-f8e4-4191-83c2-9f380526a520.png#averageHue=%23f9fdfa&clientId=u918eaff0-5d89-4&from=paste&height=444&id=u782cf4d2&originHeight=705&originWidth=615&originalType=binary&ratio=1&rotation=0&showTitle=false&size=221736&status=done&style=none&taskId=u3186c786-906a-4434-9372-65c3d3b4be4&title=&width=387" alt="image.png"><br>使用的内存块其前和其后都是空闲的，在当前的设计中我们可以很容易的知道后一个内存块是空闲的，因为我们只需要从当前位置向下移动16字节就是下一个内存块，但我们怎么能知道上一个内存块是不是空闲的呢？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750041985-2c96e9a5-bd97-4b30-b8da-b13a121f4f1a.png#averageHue=%23fbfefe&clientId=u918eaff0-5d89-4&from=paste&height=439&id=uf129fe08&originHeight=689&originWidth=738&originalType=binary&ratio=1&rotation=0&showTitle=false&size=256457&status=done&style=none&taskId=uc379e9c7-c331-4fe0-a36d-531d93a24d3&title=&width=470" alt="image.png"><br>我们之所以能向后跳是因为当前内存块的大小是知道的，那么我们该怎么向前跳找到上一个内存块呢？<br>还是我们上文提到的Donald Knuth，老爷子提出了一个很聪明的设计，我们之所以不能往前跳是因为不知道前一个内存块的信息，那么我们该怎么快速知道前一个内存块的信息呢？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750092773-6e73d0af-17e5-4a62-8bf4-84894d78477e.png#averageHue=%23cad0df&clientId=u918eaff0-5d89-4&from=paste&height=584&id=u33c236c8&originHeight=584&originWidth=888&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53124&status=done&style=none&taskId=ueb5652c0-8818-4988-b12c-8129a125f7a&title=&width=888" alt="image.png"><br>Knuth老爷子的设计是这样的，我们不是有一个信息头header吗，那么我们就在该内存块的末尾再加一个信息尾，footer，footer一词用的很形象，<strong>header和footer的内容是一样的</strong>。<br>因为上一内存块的footer和下一个内存块的header是相邻的，<strong>因此我们只需要在当前内存块的位置向上移动4直接就可以等到上一个内存块的信息</strong>，这样当我们释放内存时就可以快速的进行相邻空闲内存块的合并了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750144480-329ae235-6c7d-4942-9aa1-9c462a806f99.png#averageHue=%23fbfefb&clientId=u918eaff0-5d89-4&from=paste&height=407&id=u1ce0b242&originHeight=703&originWidth=730&originalType=binary&ratio=1&rotation=0&showTitle=false&size=315883&status=done&style=none&taskId=u8fee9fd3-d5a9-4e48-8513-48d38a58d5d&title=&width=423" alt="image.png"></p>
<h2 id="收工"><a href="#收工" class="headerlink" title="收工"></a>收工</h2><p>至此，我们的内存分配器就已经设计完毕了。<br>我们的简单内存分配器采用了First Fit分配算法；找到一个满足要求的内存块后会进行切分，剩下的作为新的内存块；同时当释放内存时会立即合并相邻的空闲内存块，同时为加快合并速度，我们引入了Donald Knuth的设计方法，为每个内存块增加footer信息。<br>这样，我们自己实现的内存分配就可以运行起来了，<strong>可以真正的申请和释放内存</strong>。</p>
<h2 id="总结-4"><a href="#总结-4" class="headerlink" title="总结"></a>总结</h2><p>本文从0到1实现了一个简单的内存分配器，但不希望这里的阐述给大家留下内存分配器实现很简单的印象，实际上本文实现的内存分配器还有大量的优化空间，同时我们也没有考虑线程安全问题，但这些都不是本文的目的。<br>本文的目的在于把内存分配器的本质告诉大家，对于想理解内存分配器实现原理的同学来说这些已经足够了，而对于要编写高性能程序的同学来说实现自己的内存池是必不可少的，内存池实现也离不开这里的讨论。</p>
<h1 id="七、线程池是如何实现的？"><a href="#七、线程池是如何实现的？" class="headerlink" title="七、线程池是如何实现的？"></a>七、线程池是如何实现的？</h1><p>大家生活中肯定都有这样的经验，那就是大众化的产品都比较便宜，但便宜的大众产品就是一个词，普通；而可以定制的产品一般都价位不凡，这种定制的产品注定不会在大众中普及，因此定制产品就是一个词，独特。<br>有的同学可能会有疑问，你不是要聊技术吗？怎么又说起消费了？<br>原来技术也有大众货以及定制品。<br><strong>通用 VS 定制 **<br>作为程序员(C&#x2F;C++)我们知道申请内存使用的是malloc，malloc其实就是一个通用的大众货，什么场景下都可以用，</strong>但是什么场景下都可以用就意味着什么场景下都不会有很高的性能。**<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750318829-434d821d-aaa1-45a2-84b9-a55b4f0f712a.png#averageHue=%237ea7b3&clientId=u918eaff0-5d89-4&from=paste&height=508&id=ua24ad7b0&originHeight=1139&originWidth=979&originalType=binary&ratio=1&rotation=0&showTitle=false&size=459437&status=done&style=none&taskId=u21bf8374-3658-4f0c-ac31-5c75543d8be&title=&width=437" alt="image.png"><br>malloc性能不高的原因一在于其没有为特定场景做优化，除此之外还在于malloc看似简单，但是其调用过程是很复杂的，一次malloc的调用过程可能需要经过操作系统的配合才能完成。<br>那么调用malloc时底层都发生了什么呢？简单来说会有这样典型的几个步骤： </p>
<ol>
<li>malloc开始搜索空闲内存块，如果能找到一块大小合适的就分配出去 </li>
<li>如果malloc找不到一块合适的空闲内存，那么调用brk等系统调用扩大堆区从而获得更多的空闲内存</li>
<li>malloc调用brk后开始转入内核态，此时操作系统中的虚拟内存系统开始工作，扩大进程的堆区，注意额外扩大的这一部分内存仅仅是虚拟内存，操作系统并没有为此分配真正的物理内存 </li>
<li>brk执行结束后返回到malloc，从内核态切换到用户态，malloc找到一块合适的空闲内存后返回<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750388216-036873de-b786-48be-8ba4-578d420cc3c6.png#averageHue=%237d9aca&clientId=u918eaff0-5d89-4&from=paste&height=595&id=R2lRJ&originHeight=595&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=353994&status=done&style=none&taskId=uc4843be0-81e9-4139-a6ee-c227bef5c30&title=&width=1080" alt="image.png"><br>以上就是一次内存申请的完整过程，我们可以看到，<strong>一次内存申请过程其实是非常复杂的，</strong>关于这个问题的详细讨论你可以参考<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485719&idx=1&sn=29d47752010326eb02edf6dadd505d4c&source=41#wechat_redirect">这里</a>。<br>既然每次分配内存都要经过这么复杂的过程，<strong>那么如果程序大量使用malloc申请内存那么该程序注定无法获得高性能</strong>。<br>幸好，除了大众货的malloc，我们还可以私人定制，也就是针对特定场景自己来维护内存申请和分配，<strong>这就是高性能高并发必备的内存池技术</strong>。</li>
</ol>
<h2 id="内存池技术有什么特殊的吗？"><a href="#内存池技术有什么特殊的吗？" class="headerlink" title="内存池技术有什么特殊的吗？"></a>内存池技术有什么特殊的吗？</h2><p>有的同学可能会说，等等，那malloc和这里提到的内存池技术有什么区别呢？<br>第一个区别在于我们所说的malloc其实是标准库的一部分，位于标准库这一层；而内存池是应用程序的一部分。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750479124-301d86d0-7625-40bc-8b3c-9bc7259def39.png#averageHue=%2387f1c6&clientId=u918eaff0-5d89-4&from=paste&height=369&id=u95c2a5b8&originHeight=653&originWidth=1057&originalType=binary&ratio=1&rotation=0&showTitle=false&size=219261&status=done&style=none&taskId=u53677af8-dee8-4430-bd7f-40420038769&title=&width=597" alt="image.png"><br>其次在于定位，我们<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485718&idx=1&sn=1c6f4c3809d109e1a7c177cce605c5ab&source=41#wechat_redirect">自己实现的malloc</a>其实也是定位<strong>通用性</strong>的，通用性的内存分配器设计实现往往比较复杂，但是内存池技术就不一样了，<strong>内存池技术专用于某个特定场景</strong>，以此优化程序性能，但内存池技术的通用性是很差的，在一种场景下有很高性能的内存池基本上没有办法在其它场景也能获得高性能，甚至根本就不能用于其它场景，这就是内存池这种技术的定位。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750533882-86f0b6af-65d8-455c-842f-6e01ff83fc18.png#averageHue=%238fa3bb&clientId=u918eaff0-5d89-4&from=paste&height=571&id=ua07cb6e3&originHeight=571&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=287042&status=done&style=none&taskId=u5749c91a-45dc-4178-ad2f-0e5b27490f6&title=&width=1080" alt="image.png"><br>那么内存池技术是怎样优化性能的呢？</p>
<h2 id="内存池技术原理"><a href="#内存池技术原理" class="headerlink" title="内存池技术原理"></a>内存池技术原理</h2><p>简单来说，内存池技术一次性获取到大块内存，然后在其之上自己管理内存的申请和释放，这样就<strong>绕过了标准库以及操作系统</strong>：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750554848-4a3f268f-b2f9-49c1-b7e0-c1f96f979ecc.png#averageHue=%238eb2eb&clientId=u918eaff0-5d89-4&from=paste&height=673&id=ub40c62ca&originHeight=673&originWidth=1077&originalType=binary&ratio=1&rotation=0&showTitle=false&size=220280&status=done&style=none&taskId=u7f8c26a6-ac79-43d5-aff3-5ae5467f7cf&title=&width=1077" alt="image.png"><br>也就是说，通过内存池，一次内存的申请再也不用去绕一大圈了。<br>除此之外，我们可以根据特定的使用模式来进一步优化，比如在服务器端，每次用户请求需要创建的对象可能就那几种，那么这时我们就可以在自己的内存池上<strong>提前创建</strong>出这些对象，当业务逻辑需要时就从内存池中申请已经创建好的对象，使用完毕后还回内存池。<br>因此我们可以看到，这种为某些应用场景定制的内存池相比通用的比如malloc内存分配器会有大的优势。<br>接下来我们就着手实现一个。</p>
<h2 id="实现内存池的考虑"><a href="#实现内存池的考虑" class="headerlink" title="实现内存池的考虑"></a>实现内存池的考虑</h2><p>值得注意的是，内存池实际上有很多的实现方法，在这里我们还是以服务器端编程为例来说明。<br>假设你的服务器程序非常简单，处理用户请求时只使用一种对象(数据结构)，那么最简单的就是我们提前申请出一堆来，使用的时候拿出一个，使用完后还回去：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750689026-4d8e25a2-d41c-47fd-af18-13770eb06b32.png#averageHue=%23fafdfd&clientId=u918eaff0-5d89-4&from=paste&height=624&id=u22e11daf&originHeight=624&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=180395&status=done&style=none&taskId=ue38754a7-4f35-407f-ac2d-cd2e9d3fa22&title=&width=1080" alt="image.png"><br>怎么样，足够简单吧！这样的内存池只能分配特定对象(数据结构)，当然这样的内存池需要自己维护哪些对象是已经被分配出去的，哪些是还没有被使用的。<br>但是，在这里我们可以实现一个稍微复杂一些的，那就是可以申请不同大小的内存，而且由于是服务器端编程，那么一次用户请求过程中我们只申请内存，只有当用户请求处理完毕后<strong>一次性释放所有内存</strong>，从而将内存申请释放的开销降低到最小。<br>因此，你可以看到，内存池的设计都是针对特定场景的。<br>现在，有了初步的设计，接下来就是细节了。</p>
<h2 id="数据结构"><a href="#数据结构" class="headerlink" title="数据结构"></a>数据结构</h2><p>为了能够分配大小可变的对象，显然我们需要管理空闲内存块，我们可以用一个链表把所有内存块链接起来，然后使用一个指针来记录当前空闲内存块的位置，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750785335-66752a78-5f37-4a7e-a737-d8cd1443c5e9.png#averageHue=%23f2f6f7&clientId=u918eaff0-5d89-4&from=paste&height=639&id=u2db7b523&originHeight=639&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=214585&status=done&style=none&taskId=u7e6eaec8-37e7-47b3-a1a3-88c5ee2f0bc&title=&width=1080" alt="image.png"><br>从图中我们可以看到，有两个空闲内存块，空闲内存之间使用链表链接起来，每个内存块都是前一个的2倍，也就是说，当内存池中的空闲内存不足以分配时我们就向malloc申请内存，只不过其大小是前一个的2倍：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750802818-47e9f016-f12e-4241-bb77-0da449babff5.png#averageHue=%2397b0d7&clientId=u918eaff0-5d89-4&from=paste&height=595&id=ud0df5ad7&originHeight=595&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=157689&status=done&style=none&taskId=uc114c72b-d354-4227-ba8d-c56bf19e3d0&title=&width=1080" alt="image.png"><br>其次，我们有一个指针free_ptr，指向接下来的空闲内存块起始位置，当向内存池分配内存时找到free_ptr并判断当前内存池剩余空闲是否足够就可以了，有就分配出去并修改free_ptr，否则向malloc再次成倍申请内存。<br>从这里的设计可以看出，我们的内存池其实是不会提供类似free这样的内存释放函数的，如果要释放内存，那么会一次性将整个内存池释放掉，这一点和通用的内存分配器是不一样。<br>现在，我们可以分配内存了，还有一个问题是所有内存池设计不得不考虑的，那就是线程安全，这个话题你可以参考<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485717&idx=1&sn=560036bc3431feee0b549fe60625ae23&source=41#wechat_redirect">这里</a>。</p>
<h2 id="线程安全"><a href="#线程安全" class="headerlink" title="线程安全"></a>线程安全</h2><p>显然，内存池不应该局限在单线程场景，那我们的内存池要怎样实现线程安全呢？<br>有的同学可能会说这还不简单，直接给内存池一把锁保护就可以了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696750915712-5fd34513-79df-4cfd-8014-f98b6cd7cc8c.png#averageHue=%2395b4e5&clientId=u918eaff0-5d89-4&from=paste&height=678&id=ue141f7c2&originHeight=1026&originWidth=842&originalType=binary&ratio=1&rotation=0&showTitle=false&size=367144&status=done&style=none&taskId=uaab1a5ee-46ec-4bb5-b57d-8e0dccc2c76&title=&width=556" alt="image.png"><br>这种方法是不是可行呢？还是那句话，It depends，要看情况。<br>如果你的程序有大量线程申请释放内存，那么这种方案下锁的竞争将会非常激烈，线程这样的场景下使用该方案不会有很好的性能。<br>那么还有没有一种更好的办法吗？答案是肯定的</p>
<h2 id="线程局部存储"><a href="#线程局部存储" class="headerlink" title="线程局部存储"></a>线程局部存储</h2><p>既然多线程使用线程池存在竞争问题，那么干脆我们为每个线程维护一个内存池就好了，这样多线程间就不存在竞争问题了。<br>那么我们该怎样为每个线程维护一个内存池呢？<br>线程局部存储，Thread Local Storage正是用于解决这一类问题的，什么是线程局部存储呢？<br>简单说就是，我们可以创建一个全局变量，因此所有线程都可以使用该全局变量，但与此同时，我们将该全局变量声明为线程私有存储，那么这时虽然所有线程依然看似使用同一个全局变量，但该全局变量在每个线程中都有自己的副本，<strong>变量指向的值是线程私有的</strong>，相互之间不会干扰<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696751010477-0a6174d0-11f2-4557-b7b4-4b4948360071.png#averageHue=%23fcfefe&clientId=u918eaff0-5d89-4&from=paste&height=440&id=u66baaa94&originHeight=440&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=230864&status=done&style=none&taskId=uaf583bd4-2c97-4438-bb01-327066c0b74&title=&width=1080" alt="image.png"><br>关于线程局部存储，可以参考<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485716&idx=1&sn=b90b4044d9ac0024c9a8fd7d7ba2122a&source=41#wechat_redirect">这里</a>。<br>假设这个全局变量是一个整数，变量名字为global_value，初始值为100，那么当线程A将global_value修改为200时，线程B看到的global_value的值依然为100，只有线程A看到的global_value为200，这就是线程局部存储的作用。</p>
<h2 id="线程局部存储-内存池"><a href="#线程局部存储-内存池" class="headerlink" title="线程局部存储+内存池"></a>线程局部存储+内存池</h2><p>有了线程局部存储问题就简单了，我们可以将内存池声明为线程局部存储，这样每个线程都只会操作属于自己的内存池，这样就再也不会有锁竞争问题了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696752611143-3addd206-3fcf-448d-b24f-e269afa82818.png#averageHue=%23b1c9ec&clientId=u918eaff0-5d89-4&from=paste&height=390&id=ucc9a46fd&originHeight=390&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=278809&status=done&style=none&taskId=u34b65e14-5008-4347-ab22-703f53684bc&title=&width=1080" alt="image.png"><br>注意，虽然这里给出了线程局部存储的设计，但并不是说加锁的方案就比不上线程局部存储方案，还是那句话，一切要看使用场景，如果加锁的方案够用，那么我们就没有必要绞尽脑汁的去用其它方案，因为加锁的方案更简单，代码也更容易维护。<br>还需要提醒的是，这里只是给出了内存池的一种实现方法，并不是说所有内存池都要这么设计，内存池可以简单也可复杂，一切要看实际场景，这一点也需要注意。</p>
<h2 id="其它内存池形式"><a href="#其它内存池形式" class="headerlink" title="其它内存池形式"></a>其它内存池形式</h2><p>到目前为止我们给出了两种内存池的设计方法，第一种是提前创建出一堆需要的对象(数据结构)，自己维护好哪些对象(数据结构)可用哪些已被分配；第二种可以申请任意大小的内存空间，使用过程中只申请不释放，最后一次性释放。这两种内存池天然适用于服务器端编程。<br>最后我们再来介绍一种内存池实现技术，这种内存池会提前申请出一大段内存，然后将这一大段内存切分为大小相同的小内存块。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696752679224-fd573350-6a56-4019-b9ea-202f5b21ef52.png#averageHue=%23b4c0ce&clientId=u918eaff0-5d89-4&from=paste&height=388&id=u11353ceb&originHeight=708&originWidth=842&originalType=binary&ratio=1&rotation=0&showTitle=false&size=141630&status=done&style=none&taskId=u28e91bc4-8f61-4563-9f8f-a4589b31ee5&title=&width=462" alt="image.png"><br>然后我们自己来维护这些被切分出来的小内存块哪些是空闲的哪些是已经被分配的，比如我们可以使用栈这种数据结构，最初把所有空闲内存块地址push到栈中，分配内存是就pop出来一个，用户使用完毕后再push回栈里。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696752720426-edd3d311-daf9-4130-b092-0d123c35e440.png#averageHue=%23fcfefc&clientId=u918eaff0-5d89-4&from=paste&height=400&id=u06c9af7e&originHeight=400&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=159320&status=done&style=none&taskId=u83775f77-de42-453c-b3f0-1f74540c380&title=&width=1080" alt="image.png"><br>从这里的设计我们可以看出，这种内存池有一个限制，这个限制就是说<strong>程序申请的最大内存不能超过这里内存块的大小</strong>，否则不足以装下用户数据，这需要我们对程序所涉及的业务非常了解才可以。<br>用户申请到内存后根据需要将其塑造成特定对象(数据结构)。<br>关于线程安全的问题，可以同样采用线程局部存储的方式来实现：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696752929087-a9323cdf-ed4e-463d-84e6-61d85a2b9779.png#averageHue=%23acb8c9&clientId=u918eaff0-5d89-4&from=paste&height=568&id=u3f97bc9e&originHeight=568&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=274869&status=done&style=none&taskId=u40933d9f-6e22-488a-8bd9-3a8176f2ef8&title=&width=1080" alt="image.png"></p>
<h2 id="一个有趣的问题"><a href="#一个有趣的问题" class="headerlink" title="一个有趣的问题"></a>一个有趣的问题</h2><p>除了线程安全，这里还有一个非常有趣的问题，那就是如果线程A申请的对象被线程B拿去释放，我们的内存池该怎么处理呢？<br>这个问题之所以有趣是因为我们<strong>必须知道该内存属于哪个线程的局部存储，但申请的内存本身并不能告诉你这样的信息</strong>。<br>有的同学可能会说这还不简单，不就是一个指针到另一个指针的映射吗，直接用map之类存起来就好了，但问题并没有这么简单，原因就在于如果我们切分的内存块很小，那么会存在大量内存块，这就需要存储大量的映射关系，有没有办法改进呢？<br>改进方法是这样的，一般来说，我们申请到的大段内存其实是会按照特定大小进行内存对齐，我们假设总是按照4K字节对齐，那么该大段内存的起始地址后12个bit(4K &#x3D; 2^12)为总是0，比如地址0x9abcd<strong>000</strong>，同时我们也假设申请到的大段内存大小也是4K：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696752984379-86a163fc-a803-4eee-b1ff-55adaf9fd792.png#averageHue=%23a1afc2&clientId=u918eaff0-5d89-4&from=paste&height=332&id=u0e717030&originHeight=677&originWidth=720&originalType=binary&ratio=1&rotation=0&showTitle=false&size=75415&status=done&style=none&taskId=ud2f7c950-625d-495d-8df5-b020a382cf7&title=&width=353" alt="image.png"><br>那么我们就能知道该大段内存中的各个小内存块起始地址除了后12个bit位外都是一样的：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696753000824-c8d295a1-8f9a-47d2-a3bc-0493d410856e.png#averageHue=%23a6b2c4&clientId=u918eaff0-5d89-4&from=paste&height=455&id=u2b56d8f9&originHeight=663&originWidth=728&originalType=binary&ratio=1&rotation=0&showTitle=false&size=249121&status=done&style=none&taskId=u743581a8-d168-4069-b238-edff2f03204&title=&width=500" alt="image.png"><br>这样拿到任意一个内存的地址我们就能知道对应的大段内存的起始地址，只需要简单的将后12个bit置为0即可，有了大段内存的起始地址剩下的就简单了，我们可以在大段内存中的最后保存对应的线程局部存储信息：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696753438357-f20fe9ad-1450-4713-b916-86e3a7cd4943.png#averageHue=%23fcfefd&clientId=u918eaff0-5d89-4&from=paste&height=375&id=uaac89e3a&originHeight=620&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=294458&status=done&style=none&taskId=u7e6382c2-7067-44b7-aadd-968576d08d9&title=&width=654" alt="image.png"><br><strong>这样我们对任意一个内存块地址进行简单的位运算就可以得到对应的线程局部存储信息</strong>，大大减少了维护映射信息对内存的占用。 </p>
<h2 id="总结-5"><a href="#总结-5" class="headerlink" title="总结"></a>总结</h2><p>内存池是高性能服务器中常见的一种优化技术，在这里我们介绍了三种实现方法，值得注意的是，内存池实现没有统一标准，一切都要根据具体场景定制，因此我们可以看到内存池设计是有针对性的，当然其反面就是不具备通用性。 </p>
<h1 id="八、线程安全代码到底是怎么编写的？"><a href="#八、线程安全代码到底是怎么编写的？" class="headerlink" title="八、线程安全代码到底是怎么编写的？"></a>八、线程安全代码到底是怎么编写的？</h1><p>相信有很多同学在面对多线程代码时都会<strong>望而生畏</strong>，认为多线程代码就像一头难以驯服的怪兽，你制服不了这头怪兽它就会反过来吞噬你。<br>夸张了哈，总之，多线程程序有时就像一潭淤泥，走不进去退不出来。<br>可这是为什么呢？<strong>为什么多线程代码如此难以正确编写呢</strong>？ </p>
<h2 id="从根源上思考"><a href="#从根源上思考" class="headerlink" title="从根源上思考"></a>从根源上思考</h2><p>关于这个问题，本质上是有一个词语你没有透彻理解，这个词就是所谓的<strong>线程安全</strong>，thread safe。<br><strong>如果你不能理解线程安全，那么给你再多的方案也是无用武之地</strong>。<br>接下来我们了解一下什么是线程安全，怎样才能做到线程安全。<br>这些问题解答后，多线程这头大怪兽自然就会变成温顺的小猫咪。</p>
<h2 id="关你什么屁事"><a href="#关你什么屁事" class="headerlink" title="关你什么屁事"></a>关你什么屁事</h2><p>生活中我们口头上经常说的一句话就是“<strong>关你屁事</strong>”，大家想一想，为什么我们的屁事不关别人？<br>原因很简单，这是我的<strong>私事</strong>啊！我的衣服、我的电脑，我的手机、我的车子、我的别墅以及私人泳池(可以没有，但不妨碍想象)，我想怎么处理就怎么处理，妨碍不到别人，只属于我一个人的东西以及事情当然不关别人，<strong>即使是屁事也不关别人</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696753896634-6bb64d46-951c-40fc-a8dc-26502e38235c.png#averageHue=%23465630&clientId=u918eaff0-5d89-4&from=paste&height=720&id=u53b3c916&originHeight=720&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=1367662&status=done&style=none&taskId=u44872e07-8d14-4fd9-a8d2-c80fe6679e2&title=&width=1080" alt="image.png"><br>我们在自己家里想吃什么吃什么，想去厕所就去厕所！因为这些都是我<strong>私有</strong>的，<strong>只有我自己使用</strong>。<br>那么什么时候会和其它人有交集呢？<br>答案就是<strong>公共场所</strong>。<br>在公共场所下你不能像在自己家里一样想去哪就去哪，想什么时候去厕所就去厕所，为什么呢？原因很简单，因为公共场所下的饭馆、卫生间不是你家的，这是<strong>公共资源</strong>，大家都可以使用的公共资源。<br>如果你想去饭馆、去公共卫生间那么就必须遵守规则，这个规则就是<strong>排队</strong>，只有前一个人用完公共资源后下一个人才可以使用，而且<strong>不能同时使用，想使用就必须排队等待</strong>。<br>上面这段话道理足够简单吧。<br>如果你能理解这段话，那么驯服多线程这头小怪兽就不在话下。</p>
<h2 id="维护公共场所秩序"><a href="#维护公共场所秩序" class="headerlink" title="维护公共场所秩序"></a>维护公共场所秩序</h2><p>如果把你自己理解为线程的话，那么在你自己家里使用私有资源就是所谓的线程安全，原因很简单，因为<strong>你随便怎么折腾自己的东西(资源)都不会妨碍到别人</strong>；<br>但到公共场所浪的话就不一样了，在公共场所使用的是公共资源，这时你就不能像在自己家里一样想怎么用就怎么用想什么时候用就什么时候用，公共场所必须有相应<strong>规则</strong>，这里的规则通常是<strong>排队</strong>，只有这样公共场所的秩序才不会被破坏，线程以某种不妨碍到其它线程的秩序使用共享资源就能实现线程安全。<br>因此我们可以看到，这里有两种情况：<br>线程私有资源，没有线程安全问题<br>共享资源，线程间以某种秩序使用共享资源也能实现线程安全。<br>本文都是围绕着上述两个核心点来讲解的，现在我们就可以正式的聊聊编程中的线程安全了。</p>
<h2 id="什么是线程安全"><a href="#什么是线程安全" class="headerlink" title="什么是线程安全"></a>什么是线程安全</h2><p>我们说一段代码是线程安全的，<strong>当且仅当我们在多个线程中同时且多次调用的这段代码都能给出正确的结果</strong>，这样的代码我们才说是线程安全代码，Thread Safety，否则就不是线程安全代码，thread unsafe.。<br>非线程安全的代码其运行结果是由掷骰子决定的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696754098981-38948544-374a-4291-9313-3750b8093df7.png#averageHue=%231a191c&clientId=u918eaff0-5d89-4&from=paste&height=346&id=u7c7c9c8f&originHeight=717&originWidth=1080&originalType=binary&ratio=1&rotation=0&showTitle=false&size=437491&status=done&style=none&taskId=u7b2b6572-3967-41cf-9497-a8237d94767&title=&width=521" alt="image.png"><br>怎么样，线程安全的定义很简单吧，也就是说你的代码不管是在单个线程还是多个线程中被执行都应该能给出正确的运行结果，这样的代码是不会出现多线程问题的，就像下面这段代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123;</span><br><span class="line"> <span class="type">int</span> a = <span class="number">1</span>;</span><br><span class="line"> <span class="type">int</span> b = <span class="number">1</span>;</span><br><span class="line"> <span class="keyword">return</span> a + b;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>对于这样段代码，<strong>无论你用多少线程同时调用、怎么调用、什么时候调用都会返回2</strong>，这段代码就是线程安全的。<br>那么我们该怎样写出线程安全的代码呢？<br>要回答这个问题，我们需要知道我们的代码什么时候呆在自己家里使用私有资源，什么时候去公共场所浪使用公共资源，也就是说你需要识别线程的私有资源和共享资源都有哪些，这是解决线程安全问题的<strong>核心</strong>所在。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696754170750-48b14da9-850f-414b-b7ea-d5b68266e783.png#averageHue=%23edf8fd&clientId=u918eaff0-5d89-4&from=paste&height=364&id=u189ca664&originHeight=567&originWidth=969&originalType=binary&ratio=1&rotation=0&showTitle=false&size=228170&status=done&style=none&taskId=u254a8b6f-c9bb-48e2-b9bc-c53a0afe999&title=&width=622" alt="image.png"></p>
<h2 id="线程私有资源"><a href="#线程私有资源" class="headerlink" title="线程私有资源"></a>线程私有资源</h2><p>线程都有哪些私有资源呢？啊哈，我们在上一篇《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485716&idx=1&sn=b90b4044d9ac0024c9a8fd7d7ba2122a&source=41#wechat_redirect">线程到底共享了哪些进程资源</a>》中详细讲解了这个问题。<br>线程运行的本质其实就是函数的执行，函数的执行总会有一个源头，这个源头就是所谓的入口函数，CPU从入口函数开始执行从而形成一个执行流，只不过我们人为的给执行流起一个名字，这个名字就叫线程。<br>既然线程运行的本质就是函数的执行，那么<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485714&idx=1&sn=1a315fe4da87fde2758fc9dd5366ba01&source=41#wechat_redirect">函数运行时信息都保存在哪里呢</a>？<br>答案就是栈区，每个线程都有一个私有的栈区，因此在栈上分配的局部变量就是线程私有的，无论我们怎样使用这些局部变量都不管其它线程屁事。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696754239023-d0ea91f2-c41e-4792-b80e-00bb6a3fb069.png#averageHue=%23f6f8f6&clientId=u918eaff0-5d89-4&from=paste&height=663&id=ue7abdd37&originHeight=663&originWidth=977&originalType=binary&ratio=1&rotation=0&showTitle=false&size=192518&status=done&style=none&taskId=u0b3cfd83-f165-482a-8384-b7f29c59d61&title=&width=977" alt="image.png"><br><strong>线程私有的栈区就是线程自己家</strong>。</p>
<h2 id="线程间共享数据"><a href="#线程间共享数据" class="headerlink" title="线程间共享数据"></a>线程间共享数据</h2><p>除了上一节提到的剩下的区域就是公共场合了，这包括：<br>用于动态分配内存的堆区，我们用C&#x2F;C++中的malloc或者new就是在堆区上申请的内存<br>全局区，这里存放的就是全局变量<br>文件，我们知道线程是共享进程打开的文件<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696754411361-7ef93d95-5529-4e09-b7c5-514ea7637f80.png#averageHue=%2374a7f0&clientId=u918eaff0-5d89-4&from=paste&height=572&id=u9b8d92fb&originHeight=572&originWidth=628&originalType=binary&ratio=1&rotation=0&showTitle=false&size=146537&status=done&style=none&taskId=u858242ee-bab2-4a52-ae4b-ef3419dcf85&title=&width=628" alt="image.png"><br>有的同学可能说，等等，在上一篇文章不是说还有代码区和动态链接库吗？<br>要知道这两个区域是不能被修改的，也就是说这两个区域是只读的，因此多个线程使用是没有问题的。<br>在刚才我们提到的堆区、数据区以及文件，这些就是所有的线程都可以共享的资源，也就是公共场所，线程在这些公共场所就不能随便浪了。<br>线程使用这些共享资源必须要遵守秩序，这个秩序的核心就是<strong>对共享资源的使用不能妨碍到其它线程</strong>，无论你使用各种锁也好、信号量也罢，其目的都是在维护公共场所的秩序。<br>知道了哪些是线程私有的，哪些是线程间共享的，接下来就简单了。<br>值得注意的是，关于线程安全的一切问题全部围绕着线程私有数据与线程共享数据来处理，<strong>抓住了线程私有资源和共享资源这个主要矛盾也就抓住了解决线程安全问题的核心</strong>。<br>接下来我们看下在各种情况下该怎样实现线程安全，依然以C&#x2F;C++代码为例，<strong>但是这里讲解的方法适用于任何语言</strong>，请放心，这些代码足够简单。</p>
<h2 id="只使用线程私有资源"><a href="#只使用线程私有资源" class="headerlink" title="只使用线程私有资源"></a>只使用线程私有资源</h2><p>我们来看这段代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123; <span class="type">int</span> a = <span class="number">1</span>; <span class="type">int</span> b = <span class="number">1</span>; <span class="keyword">return</span> a + b;&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码在前面提到过，<strong>无论你在多少个线程中怎么调用什么时候调用，func函数都会确定的返回2</strong>，该函数不依赖任何全局变量，不依赖任何函数参数，且使用的局部变量都是线程私有资源，这样的代码也被称为<strong>无状态函数</strong>，stateless，很显然这样的代码是线程安全的。<br>这样的代码请放心大胆的在多线程中使用，不会有任何问题。<br>有的同学可能会说，那如果我们还是使用线程私有资源，但是传入函数参数呢？</p>
<h2 id="线程私有资源-函数参数"><a href="#线程私有资源-函数参数" class="headerlink" title="线程私有资源+函数参数"></a>线程私有资源+函数参数</h2><p>这样的代码是线程安全的吗？自己先想一想这个问题。<br>答案是<strong>it depends</strong>，也就是要看情况。看什么情况呢？ </p>
<h3 id="1，按值传参"><a href="#1，按值传参" class="headerlink" title="1，按值传参"></a>1，按值传参</h3><p>如果你传入的参数的方式是<strong>按值传入</strong>，那么没有问题，代码依然是线程安全的：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span> num)</span> &#123; num++; <span class="keyword">return</span> num;&#125;</span><br></pre></td></tr></table></figure>
<p>这这段代码无论在多少个线程中调用怎么调用什么时候调用都会正确返回参数加1后的值。原因很简单，按值传入的这些参数是线程私有资源。</p>
<h3 id="2，按引用传参"><a href="#2，按引用传参" class="headerlink" title="2，按引用传参"></a>2，按引用传参</h3><p>但如果是按引用传入参数，那么情况就不一样了：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span>* num)</span> &#123;</span><br><span class="line"> ++(*num);</span><br><span class="line"> <span class="keyword">return</span> *num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果调用该函数的线程传入的参数是线程私有资源，那么该函数依然是线程安全的，能正确的返回参数加1后的值。<br>但如果传入的参数是全局变量，就像这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> global_num = <span class="number">1</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span>* num)</span> &#123; ++(*num); <span class="keyword">return</span> *num;&#125;</span><br><span class="line"><span class="comment">// 线程1void thread1() &#123; func(&amp;global_num);&#125;</span></span><br><span class="line"><span class="comment">// 线程2void thread1() &#123; func(&amp;global_num);&#125;</span></span><br></pre></td></tr></table></figure>
<p>那此时func函数将不再是线程安全代码，因为传入的参数指向了全局变量，这个全局变量是所有线程可共享资源，这种情况下如果不改变全局变量的使用方式，那么对该全局变量的加1操作必须施加某种秩序，比如加锁。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696754680847-9ed2f532-528c-454c-90ac-f1075f81e0b0.png#averageHue=%23f2f9fb&clientId=u6fb5e4aa-5e24-4&from=paste&height=577&id=u559f7dd9&originHeight=577&originWidth=684&originalType=binary&ratio=1&rotation=0&showTitle=false&size=136018&status=done&style=none&taskId=u018bd63a-8d6f-4269-be1b-bcf4aa463d0&title=&width=684" alt="image.png"><br>有的同学可能会说如果我传入的不是全局变量的指针(引用)是不是就不会有问题了？<br>答案依然是it depends，要看情况。<br>即便我们传入的参数是在堆上(heap)用malloc或new出来的，依然可能会有问题，为什么？<br>答案很简单，因为<strong>堆上的资源也是所有线程可共享的</strong>。<br>假如有两个线程调用func函数时传入的指针(引用)指向了同一个堆上的变量，那么该变量就变成了这两个线程的<strong>共享资源</strong>，在这种情况下func函数依然不是线程安全的。<br>改进也很简单，那就是每个线程调用func函数传入一个独属于该线程的资源地址，这样各个线程就不会妨碍到对方了，因此，<strong>写出线程安全代码的一大原则就是能用线程私有的资源就用私有资源，线程之间尽最大可能不去使用共享资源</strong>。<br>如果线程不得已要使用全局资源呢？</p>
<h2 id="使用全局资源"><a href="#使用全局资源" class="headerlink" title="使用全局资源"></a><strong>使用全局资源</strong></h2><p>使用全局资源就一定不是线程安全代码吗？<br>答案还是。。有的同学可能已经猜到了，答案依然是要看情况。<br>如果使用的全局资源只在程序运行时初始化一次，此后所有代码对其使用都是只读的，那么没有问题，就像这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> global_num = <span class="number">100</span>; <span class="comment">//初始化一次，此后没有其它代码修改其值</span></span><br><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123;</span><br><span class="line"> <span class="keyword">return</span> global_num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们看到，即使func函数使用了全局变量，但该全局变量只在运行前初始化一次，此后的代码都不会对其进行修改，那么func函数依然是线程安全的。<br>但，如果我们简单修改一下func：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> global_num = <span class="number">100</span>; </span><br><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123; ++global_num; <span class="keyword">return</span> global_num;&#125;</span><br></pre></td></tr></table></figure>
<p>这时，func函数就不再是线程安全的了，对全局变量的修改必须加锁保护。</p>
<h2 id="线程局部存储-1"><a href="#线程局部存储-1" class="headerlink" title="线程局部存储"></a><strong>线程局部存储</strong></h2><p>接下来我们再对上述func函数简单修改：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">__thread <span class="type">int</span> global_num = <span class="number">100</span>; </span><br><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123;</span><br><span class="line"> ++global_num;</span><br><span class="line"> <span class="keyword">return</span> global_num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我们看到全局变量global_num前加了关键词__thread修饰，这时，func代码就是又是线程安全的了。<br>为什么呢？<br>其实在上一篇文章中我们讲过，被__thread关键词修饰过的变量放在了线程私有存储中，Thread Local Storage，什么意思呢？<br>意思是说这个变量是线程私有的全局变量：<br>global_num是全局变量<br>global_num是线程私有的<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696755895197-47dae773-8a7e-4be4-a3e1-b01ac9981c96.png#averageHue=%23fafefe&clientId=u6fb5e4aa-5e24-4&from=paste&height=401&id=u762f2b6c&originHeight=564&originWidth=723&originalType=binary&ratio=1&rotation=0&showTitle=false&size=148815&status=done&style=none&taskId=u7752a0d5-bab2-432f-9f5e-6d9ce52e0d7&title=&width=514" alt="image.png"><br>各个线程对global_num的修改不会影响到其它线程，因为是<strong>线程私有资源</strong>，因此func函数是线程安全的。<br>说完了局部变量、全局变量、函数参数，那么接下来就到函数返回值了。</p>
<h2 id="函数返回值"><a href="#函数返回值" class="headerlink" title="函数返回值"></a>函数返回值</h2><p>这里也有两种情况，一种是函数返回的是值；另一种返回对变量的引用。 </p>
<h3 id="1，返回的是值"><a href="#1，返回的是值" class="headerlink" title="1，返回的是值"></a>1，返回的是值</h3><p>我们来看这样一段代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123; <span class="type">int</span> a = <span class="number">100</span>; <span class="keyword">return</span> a;&#125;</span><br></pre></td></tr></table></figure>
<p>毫无疑问，这段代码是线程安全的，无论我们怎样调用该函数都会返回确定的值100。</p>
<h3 id="2，返回的是引用"><a href="#2，返回的是引用" class="headerlink" title="2，返回的是引用"></a>2，返回的是引用</h3><p>我们把上述代码简单的改一改：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span>* <span class="title function_">func</span><span class="params">()</span> &#123; <span class="type">static</span> <span class="type">int</span> a = <span class="number">100</span>; <span class="keyword">return</span> &amp;a;&#125;</span><br></pre></td></tr></table></figure>
<p>如果我们在多线程中调用这样的函数，那么接下来等着你的可能就是难以调试的bug以及漫漫的加班长夜。。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696755999162-947e0db4-1ca4-474a-84a1-33f9d8435cd6.png#averageHue=%23f4f4f3&clientId=u6fb5e4aa-5e24-4&from=paste&height=575&id=u61ba5a9e&originHeight=575&originWidth=705&originalType=binary&ratio=1&rotation=0&showTitle=false&size=53184&status=done&style=none&taskId=u20584a91-66a4-4b58-9703-a3ce4a9b690&title=&width=705" alt="image.png"><br>很显然，这不是线程安全代码，产生bug的原因也很简单，你在使用该变量前其值可能已经被其它线程修改了。因为该函数使用了一个静态全局变量，只要能拿到该变量的地址那么所有线程都可以修改该变量的值，因为这是线程间的共享资源，不到万不得已不要写出上述代码，除非老板拿刀架在你脖子上。<br>但是，请注意，<strong>有一个特例</strong>，这种使用方法可以用来实现设计模式中的<strong>单例模式</strong>，就像这样：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">S</span> &#123;</span></span><br><span class="line"> public:</span><br><span class="line"> <span class="type">static</span> S&amp; <span class="title function_">getInstance</span><span class="params">()</span> &#123;</span><br><span class="line"> <span class="type">static</span> S instance;</span><br><span class="line"> <span class="keyword">return</span> instance;</span><br><span class="line"> &#125;</span><br><span class="line"> private: S() &#123;&#125; <span class="comment">// 其它省略</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>为什么呢？<br>因为无论我们调用多少次func函数，static局部变量都只会被初始化一次，这种特性可以很方便的让我们实现单例模式。<br>最后让我们来看下这种情况，那就是如果我们调用一个非线程安全的函数，那么我们的函数是线程安全的吗？</p>
<h2 id="调用非线程安全代码"><a href="#调用非线程安全代码" class="headerlink" title="调用非线程安全代码"></a>调用非线程安全代码</h2><p>假如一个函数A调用另一个函数B，但B不是线程安全，那么函数A是线程安全的吗？<br>答案依然是，要看情况。<br>我们看下这样一段代码，这段代码在之前讲解过：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> global_num = <span class="number">0</span>;</span><br><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">()</span> &#123; ++global_num; <span class="keyword">return</span> global_num;&#125;</span><br></pre></td></tr></table></figure>
<p>我们认为func函数是非线程安全的，因为func函数使用了全局变量并对其进行了修改，但如果我们这样调用func函数：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">funcA</span><span class="params">()</span> &#123;</span><br><span class="line"> mutex l;</span><br><span class="line"> l.lock();</span><br><span class="line"> func();</span><br><span class="line"> l.unlock();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>虽然func函数是非线程安全的，但是我们在调用该函数前加了一把锁进行保护，那么这时funcA函数就是线程安全的了，其本质就是我们用一把锁间接的保护了全局变量。<br>再看这样一段代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> <span class="title function_">func</span><span class="params">(<span class="type">int</span> *num)</span> &#123;</span><br><span class="line"> ++(*num);</span><br><span class="line"> <span class="keyword">return</span> *num;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>一般我们认为func函数是非线程安全的，因为我们不知道传入的指针是不是指向了一个全局变量，但如果调用func函数的代码是这样的： </p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">funcA</span><span class="params">()</span> &#123;</span><br><span class="line"> <span class="type">int</span> a = <span class="number">100</span>;</span><br><span class="line"> func(&amp;a);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>那么这时funcA函数依然是线程安全的，因为传入的参数是线程<strong>私有</strong>的局部变量，无论多少线程调用funcA都不会干扰到其它线程。<br>看了各种情况下的线程安全问题，最后让我们来总结一下实现线程安全代码都有哪些措施。</p>
<h2 id="如何实现线程安全"><a href="#如何实现线程安全" class="headerlink" title="如何实现线程安全"></a>如何实现线程安全</h2><p>从上面各种情况的分析来看，实现线程安全无外乎围绕线程私有资源和线程共享资源这两点，你需要识别出哪些是线程私有，哪些是共享的，这是核心，然后对症下药就可以了。<br><strong>不使用任何全局资源</strong>，只使用线程私有资源，这种通常被称为无状态代码<br><strong>线程局部存储</strong>，如果要使用全局资源，是否可以声明为线程局部存储，因为这种变量虽然是全局的，但每个线程都有一个属于自己的副本，对其修改不会影响到其它线程<br><strong>只读</strong>，如果必须使用全局资源，那么全局资源是否可以是只读的，多线程使用只读的全局资源不会有线程安全问题。<br><strong>原子操作</strong>，原子操作是说其在执行过程中是不可能被其它线程打断的，像C++中的std::atomic修饰过的变量，对这类变量的操作无需传统的加锁保护，因为C++会确保在变量的修改过程中不会被打断。**我们常说的各种无锁数据结构通常是在这类原子操作的基础上构建的 **。<br><strong>同步互斥</strong>，到这里也就确定了你必须要以某种形式使用全局资源，那么在这种情况下公共场所的秩序必须得到维护，那么怎么维护呢？通过同步或者互斥的方式，这是一大类问题，我们将在《深入理解操作系统》系列文章中详细阐述这一问题。</p>
<h2 id="总结-6"><a href="#总结-6" class="headerlink" title="总结"></a>总结</h2><p>怎么样，想写出线程安全的还是不简单的吧，如果本文你只能记住一句话的话，那么我希望是这句，<br>这也是本文的核心：**实现线程安全无外乎围绕线程私有资源和线程共享资源来进行，你需要识别出哪些是线程私有，哪些是共享的，然后对症下药就可以了。 **</p>
<h1 id="九、程序员应如何理解协程（待看）"><a href="#九、程序员应如何理解协程（待看）" class="headerlink" title="九、程序员应如何理解协程（待看）"></a><strong>九、程序员应如何理解协程（待看）</strong></h1><h2 id="普通的函数"><a href="#普通的函数" class="headerlink" title="普通的函数"></a>普通的函数</h2><h2 id="从普通函数到协程"><a href="#从普通函数到协程" class="headerlink" title="从普通函数到协程"></a>从普通函数到协程</h2><h2 id="Show-Me-The-Code"><a href="#Show-Me-The-Code" class="headerlink" title="Show Me The Code"></a>Show Me The Code</h2><h2 id="图形化解释"><a href="#图形化解释" class="headerlink" title="图形化解释"></a>图形化解释</h2><h2 id="函数只是协程的一种特例"><a href="#函数只是协程的一种特例" class="headerlink" title="函数只是协程的一种特例"></a>函数只是协程的一种特例</h2><h2 id="协程的历史"><a href="#协程的历史" class="headerlink" title="协程的历史"></a>协程的历史</h2><h2 id="协程是如何实现的"><a href="#协程是如何实现的" class="headerlink" title="协程是如何实现的"></a>协程是如何实现的</h2><h2 id="总结-7"><a href="#总结-7" class="headerlink" title="总结"></a>总结</h2><h1 id="十、10个内存引发的大坑（待看）"><a href="#十、10个内存引发的大坑（待看）" class="headerlink" title="十、10个内存引发的大坑（待看）"></a><strong>十、10个内存引发的大坑（待看）</strong></h1><h2 id="返回局部变量地址"><a href="#返回局部变量地址" class="headerlink" title="返回局部变量地址"></a><strong>返回局部变量地址</strong></h2><h2 id="错误的理解指针运算"><a href="#错误的理解指针运算" class="headerlink" title="错误的理解指针运算"></a>错误的理解指针运算</h2><h2 id="解引用有问题的指针"><a href="#解引用有问题的指针" class="headerlink" title="解引用有问题的指针"></a>解引用有问题的指针</h2><h2 id="读取未初始化的内存"><a href="#读取未初始化的内存" class="headerlink" title="读取未初始化的内存"></a>读取未初始化的内存</h2><h2 id="内存泄漏"><a href="#内存泄漏" class="headerlink" title="内存泄漏"></a>内存泄漏</h2><h2 id="引用已被释放的内存"><a href="#引用已被释放的内存" class="headerlink" title="引用已被释放的内存"></a>引用已被释放的内存</h2><h2 id="循环遍历是0开始的"><a href="#循环遍历是0开始的" class="headerlink" title="循环遍历是0开始的"></a>循环遍历是0开始的</h2><h2 id="指针大小与指针所指向对象的大小不同"><a href="#指针大小与指针所指向对象的大小不同" class="headerlink" title="指针大小与指针所指向对象的大小不同"></a>指针大小与指针所指向对象的大小不同</h2><h2 id="栈缓冲器溢出"><a href="#栈缓冲器溢出" class="headerlink" title="栈缓冲器溢出"></a>栈缓冲器溢出</h2><h2 id="操作指针所指对象而非指针本身"><a href="#操作指针所指对象而非指针本身" class="headerlink" title="操作指针所指对象而非指针本身"></a>操作指针所指对象而非指针本身</h2><h2 id="总结-8"><a href="#总结-8" class="headerlink" title="总结"></a>总结</h2><h1 id="十一、CPU是如何读写内存的？"><a href="#十一、CPU是如何读写内存的？" class="headerlink" title="十一、CPU是如何读写内存的？"></a>十一、CPU是如何读写内存的？</h1><p>看一下这个段代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> a = mem[<span class="number">2</span>];</span><br></pre></td></tr></table></figure>
<p>这是一段简单内存读取代码，可就是这段代码底层发生了什么呢？<br>如果你觉得这是一个非常简单的问题，那么你真应该好好读读本文，<strong>我敢保证这个问题绝没有你想象的那么简单</strong>。<br>注意，一定要完本文，<strong>否则可能会得出错误的结论</strong>。<br>闲话少说，让我们来看看CPU在读写内存时底层究竟发生了什么。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696759987048-cbe8f2e6-d647-4fd0-b9e7-7683d04b50bb.png#averageHue=%23ced2cd&clientId=u7c376b92-d600-4&from=paste&height=473&id=ud945dee2&originHeight=712&originWidth=823&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=322652&status=done&style=none&taskId=u25474f71-85ac-4b14-8d5c-c615da274a8&title=&width=547" alt="image.png"></p>
<h2 id="谁来告诉CPU读写内存"><a href="#谁来告诉CPU读写内存" class="headerlink" title="谁来告诉CPU读写内存"></a>谁来告诉CPU读写内存</h2><p>我们第一个要搞清楚的问题是：谁来告诉CPU去读写内存？<br>答案很明显，是程序员，更具体的是编译器。<br>CPU只是按照指令按部就班的执行，机器指令从哪里来的呢？是编译器生成的，程序员通过高级语言编写程序，编译器将其翻译为机器指令，机器指令来告诉CPU去读写内存。<br>在精简指令集架构下会有特定的机器指令，Load&#x2F;Store指令来读写内存，以x86为代表的复杂指令集架构下没有特定的访存指令。<br><strong>精简指令集</strong>下，一条机器指令操作的数据必须来存放在寄存器中，不能直接操作内存数据，因此RISC下，数据必须先从内存搬运到寄存器，这就是为什么RISC下会有特定的Load&#x2F;Store访存指令。<br>而x86下无此限制，一条机器指令操作的数据可以来自于寄存器也可以来自内存，因此这样一条机器指令在执行过程中会首先从内存中读取数据。<br>关于复杂指令集以及精简指令集你可以参考这两篇文章《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485741&idx=1&sn=45afcce8e8e8ec198a9b09c32c1e6aa8&chksm=cfe995adf89e1cbb833ca61741028bee6ccfeb1e928efe60a3a8fcf1fa01da3df4ef49a063de&scene=21#wechat_redirect">CPU进化论：复杂指令集</a>》与《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485741&idx=1&sn=45afcce8e8e8ec198a9b09c32c1e6aa8&chksm=cfe995adf89e1cbb833ca61741028bee6ccfeb1e928efe60a3a8fcf1fa01da3df4ef49a063de&scene=21#wechat_redirect">不懂精简指令集还敢说自己是程序员？</a>》</p>
<h2 id="两种内存读写"><a href="#两种内存读写" class="headerlink" title="两种内存读写"></a>两种内存读写</h2><p>现在我们知道了，是特定的机器指令告诉CPU要去访问内存。<br>不过，值得注意的是，不管是RISC下特定的Load&#x2F;Store指令还是x86下包含在一条指令内部的访存操作，这里读写的都是内存中的数据，除此之外还要意识到，CPU除了从内存中读写数据外，还要从内存中读取下一条要执行的机器指令。<br>毕竟，我们的计算设备都遵从冯诺依曼架构：<strong>程序和数据一视同仁，都可以存放在内存中</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696760242845-a488ad2b-5827-42be-b65a-c3bce553e8ca.png#averageHue=%23ebebe9&clientId=u7c376b92-d600-4&from=paste&height=625&id=u5373b53d&originHeight=625&originWidth=1080&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=115593&status=done&style=none&taskId=uc48e0569-c47b-4e0e-80d6-8871d718634&title=&width=1080" alt="image.png"><br>现在，我们清楚了CPU读写内存其实是由两个因素来驱动的： </p>
<ol>
<li>程序执行过程中需要读写来自内存中的数据 </li>
<li>CPU需要访问内存读取下一条要执行的机器指令<br>然后CPU根据机器指令中包含的内存地址或者PC寄存器中下一条机器指令的地址访问内存。<br>这不就完了吗？有了内存地址，CPU利用硬件通路直接读内存就好了，你可能也是这样的想的。<br>真的是这样吗？别着急，我们接着往下看，这两节只是开胃菜，正餐才刚刚开始。</li>
</ol>
<h2 id="急性子吃货-VS-慢性子厨师"><a href="#急性子吃货-VS-慢性子厨师" class="headerlink" title="急性子吃货 VS 慢性子厨师"></a>急性子吃货 VS 慢性子厨师</h2><p>假设你是一个整天无所事事的吃货，整天无所事事，唯一的爱好就是找一家餐厅吃吃喝喝，由于你是职业吃货，因此吃起来非常职业，1分钟就能吃完一道菜，但这里的厨师就没有那么职业了，炒一道菜速度非常慢，大概需要1小时40分钟才能炒出一道菜，速度比你慢了100倍，如果你是这个吃货，大概率会疯掉的。<br>而CPU恰好就是这样一个吃货，内存就是这样一个慢吞吞的厨师，而且随着时间的推移这两者的速度差异正在越来越大：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696761667590-d58e4065-7ea9-4418-97e1-8b15ead1bfaa.png#averageHue=%23f0f0ef&clientId=u7c376b92-d600-4&from=paste&height=440&id=u97a64bf6&originHeight=440&originWidth=850&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=261247&status=done&style=none&taskId=u84b1828d-5abc-46ff-82ed-ac4f52b2811&title=&width=850" alt="image.png"><br>在这种速度差异下，CPU执行一条涉及内存读写指令时需要等<strong>“很长一段时间“</strong>数据才能<strong>”缓缓的“</strong>从内存读取到CPU中，在这种情况<strong>你还认为CPU应该直接读写内存吗</strong>？</p>
<h2 id="无处不在的28定律（缓存Cache）"><a href="#无处不在的28定律（缓存Cache）" class="headerlink" title="无处不在的28定律（缓存Cache）"></a>无处不在的28定律（缓存Cache）</h2><p>28定律我想就不用多介绍了吧，在《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485741&idx=1&sn=45afcce8e8e8ec198a9b09c32c1e6aa8&chksm=cfe995adf89e1cbb833ca61741028bee6ccfeb1e928efe60a3a8fcf1fa01da3df4ef49a063de&scene=21#wechat_redirect">不懂精简指令集还敢说自己是程序员</a>》这篇文章中也介绍过，CPU执行指令符合28定律，大部分时间都在执行那一少部分指令，这一现象的发现奠定了精简指令集设计的基础。<br>而程序操作的数据也符合类似的定律，只不过不叫28定律，而是叫principle of locality，<strong>程序局部性原理</strong>。<br>如果我们访问内存中的一个数据A，那么很有可能接下来再次访问到，同时还很有可能访问与数据A相邻的数据B，这分别叫做<strong>时间局部性</strong>和<strong>空间局部性</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696761776250-366e401b-33f1-4f4a-9c69-9793ad762681.png#averageHue=%23fefefc&clientId=u7c376b92-d600-4&from=paste&height=462&id=u5ef049e7&originHeight=687&originWidth=611&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=167632&status=done&style=none&taskId=u63d49c4d-9baa-4c69-b530-6c3f3e0a6c3&title=&width=411" alt="image.png"><br>如图所示，该程序占据的内存空间<strong>只有一少部分在程序执行过程经常用到</strong>。<br>有了这个发现重点就来了，既然只用到很少一部分，那么我们能不能把它们<strong>集中起来</strong>呢？就像这样：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696761799745-5d39a0ab-fc44-44dd-9510-3007701aea68.png#averageHue=%23fbfefc&clientId=u7c376b92-d600-4&from=paste&height=460&id=ufc5722c8&originHeight=699&originWidth=695&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=173685&status=done&style=none&taskId=u2c4ac091-e346-457e-be5b-e49c8708a42&title=&width=457" alt="image.png"><br>集中起来然后呢？放到哪里呢？<br>当然是放到一种比内存速度更快的存储介质上，这种介质就是我们熟悉的SRAM，普通内存一般是DRAM，这种读写速度更快的介质充当CPU和内存之间的Cache，这就是所谓的缓存。</p>
<h2 id="四两拨千斤"><a href="#四两拨千斤" class="headerlink" title="四两拨千斤"></a>四两拨千斤</h2><p>我们把经常用到的数据放到cache中存储，CPU访问内存时首先查找cache，如果能找到，也就是命中，那么就赚到了，直接返回即可，找不到再去查找内存并更新cache。<br>我们可以看到，<strong>有了cache，CPU不再直接与内存打交道了</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696762056629-1fea2d89-5abb-49a1-ba51-f7acd80fdf09.png#averageHue=%23fcfefb&clientId=u7c376b92-d600-4&from=paste&height=695&id=ue622eb32&originHeight=695&originWidth=974&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=124065&status=done&style=none&taskId=u0d57c915-dde1-4c7c-8402-82ba9cca055&title=&width=974" alt="image.png"><br>但cache的快速读写能力是有代价的，代价就是Money，造价不菲，<strong>因此我们不能把内存完全替换成cache的SRAM，那样的计算机你我都是买不起的</strong>。<br>因此cache的容量不会很大，但由于程序局部性原理，<strong>因此很小的cache也能有很高的命中率</strong>，从而带来性能的极大提升，有个词叫<strong>四两拨千斤</strong>，用到cache这里再合适不过。</p>
<h2 id="天下没有免费的午餐"><a href="#天下没有免费的午餐" class="headerlink" title="天下没有免费的午餐"></a>天下没有免费的午餐</h2><p>虽然小小的cache能带来性能的极大提升，但，这也是有代价的。<br>这个代价出现在写内存时。<br>当CPU需要写内存时该怎么办呢？<br>现在有了cache，CPU不再直接与内存打交道，因此CPU直接写cache，但此时就会有一个问题，那就是cache中的值更新了，但内存中的值还是旧的，这就是所谓的不一致问题，inconsistent.<br>就像下图这样，cache中变量的值是4，但内存中的值是2。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696762157701-57d34aae-74e3-468c-a8c7-ebfee5fcbb0f.png#averageHue=%23fdfefc&clientId=u7c376b92-d600-4&from=paste&height=690&id=u02b66b67&originHeight=690&originWidth=980&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=138116&status=done&style=none&taskId=ud5cfc16f-e2ca-4fd7-b6a3-3718d7439a0&title=&width=980" alt="image.png"></p>
<h2 id="同步缓存更新"><a href="#同步缓存更新" class="headerlink" title="同步缓存更新"></a>同步缓存更新</h2><p>常用 redis 的同学应该很熟悉这个问题，<strong>可是你知道吗？这个问题早就在你读这篇文章用的计算设备其包含的CPU中已经遇到并已经解决了。 **<br>最简单的方法是这样的，当我们更新cache时一并把内存也更新了，这种方法被称为 write-through，很形象吧。<br>可是如果当CPU写cache时，cache中没有相应的内存数据该怎么呢？这就有点麻烦了，首先我们需要把该数据从内存加载到cache中，然后更新cache，再然后更新内存。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696762195181-548d62ac-40d0-45d2-aca3-919e331961c5.png#averageHue=%23fefefc&clientId=u7c376b92-d600-4&from=paste&height=682&id=ua0042e1c&originHeight=682&originWidth=904&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=163488&status=done&style=none&taskId=u8bc40f81-3577-49dd-b0f7-04df4bc753e&title=&width=904" alt="image.png"><br>这种实现方法虽然简单，但有一个问题，那就是性能问题，在这种方案下</strong>写内存就不得不访问内存**，上文也提到过CPU和内存可是有很大的速度差异哦，因此这种方案性能比较差。<br>有办法解决吗？答案是肯定的。</p>
<h2 id="异步更新缓存"><a href="#异步更新缓存" class="headerlink" title="异步更新缓存"></a>异步更新缓存</h2><p>这种方法性能差不是因为写内存慢，写内存确实是慢，更重要的原因是CPU在同步等待，因此很自然的，这类问题的统一解法就是把同步改为异步。<br>关于同步和异步的话题，你可以参考这篇文章《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485709&idx=1&sn=86738d509091e7ff0e0c16d4b9aa354f&chksm=cfe9958df89e1c9ba51c562359933ef954000717510741214250abf0d973c24f432fa20f4892&scene=21#wechat_redirect">从小白到高手，你需要理解同步和异步</a>》。<br>异步的这种方法是这样的，当CPU写内存时，直接更新cache，然后，注意，更新完cache后CPU就可以认为写内存的操作已经完成了，尽管此时内存中保存的还是旧数据。<br>当包含该数据的cache块被剔除时再更新到内存中，这样CPU更新cache与更新内存就解耦了，也就是说，CPU更新cache后不再等待内存更新，这就是异步，这种方案也被称之为write-back，这种方案相比write-through来说更复杂，但很显然，性能会更好。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696762270164-97774eb0-311a-407f-b3f8-b6a1d186ed3e.png#averageHue=%23fcfefc&clientId=u7c376b92-d600-4&from=paste&height=703&id=u5b416392&originHeight=703&originWidth=979&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=171378&status=done&style=none&taskId=u497f6381-3341-41ec-b834-14f28a33d12&title=&width=979" alt="image.png"><br>现在你应该能看到，添加cache后会带来一系列问题，更不用说cache的替换算法，毕竟cache的容量限，当cache已满时，增加一项新的数据就要剔除一项旧的数据，那么该剔除谁就是一个非常关键的问题，限于篇幅就不在这里详细讲述了，你可以参考《深入理解操作系统》第7章有关于该策略的讲解。</p>
<h2 id="多级cache"><a href="#多级cache" class="headerlink" title="多级cache"></a>多级cache</h2><p>现代CPU为了增加CPU读写内存性能，已经在CPU和内存之间增加了多级cache，典型的有三级，L1、L2和L3，CPU读内存时首先从L1 cache找起，能找到直接返回，否则就要在L2 cache中找，L2 cache中找不到就要到L3 cache中找，还找不到就不得不访问内存了。<br>因此我们可以看到，<strong>现代计算机系统CPU和内存之间其实是有一个cache的层级结构的</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763049699-fec78581-27d2-40e8-85e1-4e5443db50f9.png#averageHue=%23f3f3f2&clientId=u7c376b92-d600-4&from=paste&height=464&id=ub457cee0&originHeight=464&originWidth=816&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=298438&status=done&style=none&taskId=u3142e242-fc87-459c-806c-4e9798cf06e&title=&width=816" alt="image.png"><br>越往上，存储介质速度越快，造价越高容量也越小；越往下，存储介质速度越慢，造价越低但容量也越大。<br>现代操作系统巧妙的利用cache，以最小的代价获得了最大的性能。<br>但是，注意这里的但是，<strong>要想获得极致性能是有前提的，那就是程序员写的程序必须具有良好的局部性，充分利用缓存</strong>。<br>高性能程序在充分利用缓存这一环节可谓绞尽脑汁煞费苦心。<br>鉴于cache的重要性，现在增大cache已经成为提升CPU性能的重要因素，因此你去看当今的CPU布局，其很大一部分面积都用在了cache上。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763112466-35788528-ccea-4815-a8db-150cdae04ef1.png#averageHue=%23457e64&clientId=u7c376b92-d600-4&from=paste&height=388&id=u54354db1&originHeight=388&originWidth=453&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=488733&status=done&style=none&taskId=u2e33d9b4-7e15-4e67-b035-1941b6d1046&title=&width=453" alt="image.png"><br>你以为这就完了吗？<br>哈哈，哪有这么容易的，否则也不会是终面题目了。<br>那么当CPU读写内存时除了面临上述问题外还需要处理哪些问题呢？</p>
<h2 id="多核，多问题"><a href="#多核，多问题" class="headerlink" title="多核，多问题"></a>多核，多问题</h2><p>当摩尔定律渐渐失效后鸡贼的人类换了另一种提高CPU性能的方法，既然单个CPU性能不好提升了，我们还可以堆数量啊，这样，CPU进入多核时代，程序员开始进入苦逼时代。<br>拥有一堆核心的CPU其实是没什么用的，<strong>关键需要有配套的多线程程序才能真正发挥多核的威力</strong>，但写过多线程程序的程序员都知道，能写出来不容易，能写出来并且能正确运行更不容易，关于多线程与多线程编程的详细阐述请参见《深入理解操作系统》第5、6两章(关注公众号“码农的荒岛求生”并回复“操作系统”)。<br>CPU开始拥有多个核心后不但苦逼了软件工程师，硬件工程师也不能幸免。<br>前文提到过，为提高CPU 访存性能，CPU和内存之间会有一个层cache，但当CPU有多个核心后新的问题来了：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763191090-55d918d0-07dc-4f16-a19b-56668939842d.png#averageHue=%23fdfefc&clientId=u7c376b92-d600-4&from=paste&height=684&id=u26f23bd8&originHeight=684&originWidth=894&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=198876&status=done&style=none&taskId=uf632849f-8695-4275-9a0e-5947977edaa&title=&width=894" alt="image.png"><br>现在假设内存中有一变量X，初始值为2。<br>系统中有两个CPU核心C1和C2，现在C1和C2要分别读取内存中X的值，根据cache的工作原理，首次读取X不能命中cache，因此从内存中读取到X后更新相应的cache，现在C1 cache和C2 cache中都有变量X了，其值都是2。<br>接下来C1需要对X执行+2操作，同样根据cache的工作原理，C1从cache中拿到X的值+2后更新cache，在然后更新内存，此时C1 cache和内存中的X值都变为了4。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763453626-54d31d16-e925-463b-9c36-fa1766c735e3.png#averageHue=%23fefefc&clientId=u7c376b92-d600-4&from=paste&height=708&id=udc74179a&originHeight=708&originWidth=960&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=201276&status=done&style=none&taskId=ubffd4286-11e3-4f64-8e43-b291a8ae2f5&title=&width=960" alt="image.png"><br>然后C2也许需要对X执行加法操作，假设需要+4，同样根据cache的工作原理，C2从cache中拿到X的值+4后更新cache，此时cache中的值变为了6（2+4），再更新内存，此时C2 cache和内存中的X值都变为了6。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763484025-3397bde6-5829-49ab-9c52-3fa3643d5566.png#averageHue=%23fbfefc&clientId=u7c376b92-d600-4&from=paste&height=681&id=u4ceecf2d&originHeight=681&originWidth=902&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=180160&status=done&style=none&taskId=u9988a3b3-25a8-453c-9e0c-a5bbad14dac&title=&width=902" alt="image.png"><br>看出问题在哪里了吗？<br>一个初始值为2的变量，在分别+2和+4后正确的结果应该是2+2+4 &#x3D; 8，但从上图可以看出<strong>内存中X的值却为6</strong>，问题出在哪了呢？</p>
<h2 id="多核cache一致性"><a href="#多核cache一致性" class="headerlink" title="多核cache一致性"></a>多核cache一致性</h2><p>有的同学可能已经发现了，问题出在了内存中一个X变量在C1和C2的cache中有共计两个副本，当C1<strong>更新cache时没有同步修改C2 cache中X的值</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763537381-a3fec1f0-1fc2-4add-a46f-44abdb9e162f.png#averageHue=%23f7fcfc&clientId=u7c376b92-d600-4&from=paste&height=678&id=u59784661&originHeight=678&originWidth=1034&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=224942&status=done&style=none&taskId=ue2afc2e0-2adf-444c-bae3-fd125b7ece2&title=&width=1034" alt="image.png"><br>解决方法是什么呢？<br>显然，如果一个cache中待更新的变量同样存在于其它核心的cache，那么你需要一并将其它cache也更新好。<br>现在你应该看到，CPU更新变量时不再简单的只关心自己的cache和内存，<strong>你还需要知道这个变量是不是同样存在于其它核心中的cache</strong>，如果存在需要一并更新。<br>当然，这还只是简单的读，写就更加复杂了，实际上，现代CPU中有一套协议来专门维护缓存的一致性，比较经典的包括MESI协议等。<br>为什么程序员需要关心这个问题呢？原因很简单，<strong>你最好写出对cache一致性协议友好的程序</strong>，<strong>因为cache频繁维护一致性也是有性能代价的</strong>。<br>同样的，限于篇幅，这个话题不再详细阐述，该主题同样值得单独成篇，敬请期待。<br><strong>够复杂了吧！ **<br>怎么样？到目前为止，是不是CPU读写内存没有看上去那么简单？<br>现代计算机中CPU和内存之间有多级cache，</strong>CPU读写内存时不但要维护cache和内存的一致性，同样需要维护多核间cache的一致性<strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763591251-55b06ad3-e822-4a18-afd0-62460356d613.png#averageHue=%236b6146&clientId=u7c376b92-d600-4&from=paste&height=810&id=u52760169&originHeight=810&originWidth=1080&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=2489986&status=done&style=none&taskId=u6346ffdf-74f2-4e89-89f0-bad64103197&title=&width=1080" alt="image.png"><br>你以为这就完了，NONO，最大的谜团其实是接下来要讲的。<br><strong>你以为的不是你以为的 **<br>现代程序员写程序基本上不需要关心</strong>内存是不是足够这个问题</strong>，但这个问题在远古时代绝对是困扰程序员的一大难题。<br>如果你去想一想，其实现代计算机内存也没有足够大的让我们随便申请的地步，<strong>但是你在写程序时是不是基本上没有考虑过内存不足该怎么办？ **<br>为什么我们在内存资源依然处于匮乏的现代可以做到申请内存时却进入内存极大丰富的共产主义理想社会了呢？<br>原来这背后的功臣是我们熟悉的</strong>操作系统<strong>。<br>操作系统对每个进程都维护一个假象，即，每个进程独占系统内存资源；同时给程序员一个承诺，让程序员可以认为在写程序时有一大块连续的内存可以使用。<br>这当然是不可能不现实的，因此操作系统给进程的地址空间必然不是真的，但我们又不好将其称之为“</strong>假的地址空间<strong>”，这会让人误以为计算机科学界里骗子横行，因此就换了一个好听的名字，</strong>虚拟内存<strong>，一个“</strong>假的地址空间**”更高级的叫法。<br><strong>进程其实一直活在操作系统精心维护的幻觉当中</strong>，就像《盗梦空间》一样，关于虚拟内存的详尽阐述请参见《深入理解操作系统》第七章(关注公众号“码农的荒岛求生”并回复“操作系统”)。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763699289-c4eb630b-b4af-448e-b7b2-ce97dd97d3d5.png#averageHue=%234a5f65&clientId=u7c376b92-d600-4&from=paste&height=608&id=ub3a0ef2f&originHeight=608&originWidth=1080&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=1196635&status=done&style=none&taskId=u727a2a9d-5532-400d-bf46-9f1250c4895&title=&width=1080" alt="image.png"><br>从这个角度看，其实最擅长包装的是计算机科学界，哦，对了，他们不但擅长包装还擅长抽象。</p>
<h2 id="天真的CPU"><a href="#天真的CPU" class="headerlink" title="天真的CPU"></a>天真的CPU</h2><p>CPU真的是很傻很天真的存在。<br>上一节讲的操作系统施加的障眼法把CPU也蒙在鼓里。<br>CPU执行机器指令时，指令指示CPU从内存地址A中取出数据，然后CPU执行机器指令时下发命令：“给我从地址A中取出数据”，尽管真的能从地址A中取出数据，但这个地址A不是真的，不是真的，不是真的。<br>因为这个地址A属于虚拟内存，也就是那个“假的地址空间”，现代CPU内部有一个叫做MMU的模块将这假的地址A转换为真的地址B，将地址A转换为真实的地址B之后才是本文之前讲述的关于cache的那一部分。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696763834852-4959134c-c46e-4202-9f99-f6198b69bae8.png#averageHue=%23fafefd&clientId=u7c376b92-d600-4&from=paste&height=690&id=ua87640da&originHeight=690&originWidth=1080&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=155815&status=done&style=none&taskId=uf1f7e466-bd63-46a8-92dc-81df316bc82&title=&width=1080" alt="image.png"><br>你以为这终于应该讲完了吧！<br>NONO！<br>CPU给出内存地址，此后该地址被转为真正的物理内存地址，接下来查L1 cache，L1 cache不命中查L2 cache，L2 cache不命中查L3 cache，L3 cache不能命中查内存。<br>各单位注意，各单位注意，到查内存时还不算完，现在有了虚拟内存，<strong>内存其实也是一层cache，是磁盘的cache，也就是说查内存也有可能不会命中</strong>，因为内存中的数据可能被虚拟内存系统放到磁盘中了，<strong>如果内存也不能命中就要查磁盘</strong>。<br>So crazy，限于篇幅这个过程不再展开，《深入理解操作系统》第七章有完整的讲述。<br>至此，CPU读写内存时完整的过程阐述完毕。</p>
<h2 id="总结-9"><a href="#总结-9" class="headerlink" title="总结"></a>总结</h2><p>现在你还认为CPU读写内存非常简单吗？<br>这一过程涉及到的硬件以及硬件逻辑包括：L1 cache、L2 cache、L3 cache、多核缓存一致性协议、MMU、内存、磁盘；软件主要包括操作系统。<br><strong>这一看似简单的操作涉及几乎所有计算机系统中的核心组件，需要软件以及硬件密切配合才能完成</strong>。<br>这个过程给程序员的启示是：1)，现代计算机系统是非常复杂的；2),<strong>你需要写出对cache友好的程序</strong></p>
<h1 id="十二、CPU与分支预测"><a href="#十二、CPU与分支预测" class="headerlink" title="十二、CPU与分支预测"></a><strong>十二、CPU与分支预测</strong></h1><p>18世纪流水线的诞生带来了制造技术的变革，人类当今拥有琳琅满目物美价廉的商品和流水线技术的发明密不可分，<strong>因此当你喝着可乐、吹着空调、坐在特斯拉里拿着智能手机刷这篇文章时需要感谢流水线技术</strong>。 </p>
<h2 id="一段有趣的代码"><a href="#一段有趣的代码" class="headerlink" title="一段有趣的代码"></a>一段有趣的代码</h2><p>有这样一段代码：</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; <span class="number">10000</span>; k++)&#123; </span><br><span class="line">    <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; arr.size(); i++) &#123; </span><br><span class="line">        <span class="keyword">if</span>(arr[i] &gt; <span class="number">256</span>) </span><br><span class="line">            sum += arr[i]; </span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这段代码非常简单，给定一个数组，计算所有大于256 的元素之和，重复计算 10000 遍。<br>这段代码本身平淡无奇，但有趣的是：<strong>如果这个数组是有序的，那么这段代码的运行速度会比处理无序数组快将近10 倍</strong>(不同的机器、CPU架构可能会稍有差异)。<br>可这是为什么呢？这和制造业使用的流水线又有什么关系呢？且听我慢慢道来。</p>
<h2 id="流水线技术的诞生"><a href="#流水线技术的诞生" class="headerlink" title="流水线技术的诞生"></a>流水线技术的诞生</h2><p>1769年，英国人乔赛亚·韦奇伍德开办了一家陶瓷工厂，这家工厂生产的陶瓷乏善可陈，但其内部的管理方式极具创新性，传统的方法都是由制陶工专人来完成，但韦奇伍德研究后将整个制陶工艺流程分成了<strong>几十道工序</strong>，每一道工序都交给专人完成，这样传统的制陶人不复存在，这便是工业流水线最早的雏形。</p>
<h2 id="发扬光大"><a href="#发扬光大" class="headerlink" title="发扬光大"></a>发扬光大</h2><p>虽然流水线技术可以说是英国人发明的，但发扬光大的却是美国人，这便是福特与T型车。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696764895653-1b507822-d708-4342-b151-e91e017cdc9f.png#averageHue=%23d2cbbd&clientId=u7c376b92-d600-4&from=paste&height=695&id=udad15451&originHeight=695&originWidth=900&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=799038&status=done&style=none&taskId=u3a680484-c18f-4ff3-bb47-f6015db6f63&title=&width=900" alt="image.png"><br>20世纪初，福特将流水线技术应用到汽车的批量生产，效率得到千倍提高，<strong>使得汽车这种奢侈品开始能够为大众消费</strong>，深刻影响了现代社会的方方面面，注意上图中一辆车的价格。。。<br>100 年后又一个美国人携带他的时尚电动车再一次席卷全球，这就是特斯拉。<br>接下来我们仔细看一下流水线技术。</p>
<h2 id="特斯拉与流水线"><a href="#特斯拉与流水线" class="headerlink" title="特斯拉与流水线"></a>特斯拉与流水线</h2><p>假设组装一辆特斯拉需要经过：组装车架、安装引擎、安装电池、检验四道工序，同时假设每个步骤需要 20 分钟，因此如果所有工序都由一个组装站点来完成，那么组装一辆特斯拉需要80分钟。<br>但如果每个步骤都交给一个特定站点来组装的话就不一样了，此时生产一辆车的时间依然是80分钟，但这只是第一辆车所需要的时间，此后工厂可以每20分钟就交付一辆特斯拉。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696764952333-2f16e028-16ab-48f6-bd97-c47809aab7ea.png#averageHue=%23d8e9ea&clientId=u7c376b92-d600-4&from=paste&height=833&id=ucfc379e4&originHeight=833&originWidth=895&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=324470&status=done&style=none&taskId=udf2c966f-26e0-4bdf-b8f7-10c0ba9f651&title=&width=895" alt="image.png"><br>注意，流水线并没有减少组装一辆车的时间，只是增加了工厂的吞吐能力。<br><strong>流水线技术的使用极大增加了工厂交付车辆的效率。</strong></p>
<h2 id="CPU-与超级工厂"><a href="#CPU-与超级工厂" class="headerlink" title="CPU 与超级工厂"></a>CPU 与超级工厂</h2><p>其实 CPU 本身也是一座超级工厂。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696764974335-ecc21efa-8ffa-476f-b365-4b64424da0c3.png#averageHue=%235b8296&clientId=u7c376b92-d600-4&from=paste&height=291&id=u5d4c833f&originHeight=291&originWidth=1080&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=780134&status=done&style=none&taskId=u8e4a8e82-339d-4e63-8dd1-51763ef8127&title=&width=1080" alt="image.png"><br>只不过CPU这座工厂生产的不是特斯拉，而是机器指令。<br>工厂内部有流水线极大提高了生产效率，CPU 没有理由不拥有。<br>你可以想象一下，<strong>不管你现在看这篇文章用的是PC还是智能手机，其内部的 CPU 都有一条复杂度不亚于特斯拉超级工厂的流水生产线</strong>。<br>如果我们把CPU处理的一条机器指令当做一辆特斯拉的话，那么对于现代CPU这座超级工厂来说，<strong>一秒钟的时间内可以交付数十亿量特斯拉</strong>，效率完爆任何当今制造界的工业流水线，<strong>CPU 才是一座名副其实的超级工厂</strong>。<br>如果特斯拉超级工厂也如 CPU 一般高效的话，特斯拉可能比现在的自行车都要便宜，地球人民人手一辆特斯拉不成问题，算上外星人也不成问题。</p>
<h2 id="机器指令与流水线"><a href="#机器指令与流水线" class="headerlink" title="机器指令与流水线"></a>机器指令与流水线</h2><p>实际上说 CPU 生产机器指令是不正确的，<strong>CPU 其实不是在生产机器指令而是在处理机器指令，生产机器指令的是编译器</strong>，CPU需要处理机器指令以此来指挥整个计算机系统工作。<br>同生产一辆特斯拉需要四道工序一样，处理一条机器指令大体上也可以分为四个步骤：取指、译码、执行、回写，这几个阶段分别由特定的硬件来完成 (注意，真实 CPU 内部可能会将执行一条指令分解为数十个阶段)。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696765060202-9d2d3d80-dcaf-4496-9474-e703b8451360.png#averageHue=%23fafefe&clientId=u7c376b92-d600-4&from=paste&height=779&id=u33f93137&originHeight=779&originWidth=897&originalType=binary&ratio=0.6666666865348816&rotation=0&showTitle=false&size=326573&status=done&style=none&taskId=u663c5e2e-7477-44a3-9ada-50eb3fe0b55&title=&width=897" alt="image.png"><br>怎么样，是不是和超级工厂生产特斯拉没什么区别，<strong>当今CPU用每秒处理数十亿机器指令的能力驱动着智能手机好让你流畅的刷公众号、短视频、刷微博、刷知乎</strong>，这里，流水线技术功不可没。</p>
<h2 id="当-if-遇到流水线"><a href="#当-if-遇到流水线" class="headerlink" title="当 if 遇到流水线"></a>当 if 遇到流水线</h2><p>实际上 CPU 内部的流水线和现实中的并不完全一样。<br>程序员在代码中编写的 if 语句一般会被编译器翻译成一条跳转指令，<br>if 语句其实起到一种<strong>分支</strong>的作用，如果条件成立则需要执行if内部的逻辑，否则不执行；因此<strong>跳转指令会依赖自身的执行结果来决定到底要不要跳转</strong>，这会对流水线产生影响。<br>有的同学可能不明白，这能产生什么影响呢？<br>现在，让我们仔细观察一下特斯拉流水线，你会发现<strong>当前一辆车还没有完全制造完成时后一辆车就已经进入到流水线了</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696777514287-448f9c17-5d18-4111-a515-e2f418c8a8fa.png#averageHue=%23d9eceb&clientId=ubc5fcece-554d-4&from=paste&height=748&id=u435fdaae&originHeight=835&originWidth=897&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=399696&status=done&style=none&taskId=u6011d884-464b-449e-af6d-6c64436de92&title=&width=804.0335962624944" alt="image.png"></p>
<p>对于CPU来说道理是一样的，当一条跳转指令还没有完成时后面的指令就需要进入到流水线，因此问题来了：<br><strong>跳转指令需要依赖自身的执行结果来决定到底要不要跳转，那么在跳转指令没有执行完的情况下 CPU 怎么知道后面哪个分支的指令能进入到流水线呢</strong>？<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696777659092-2626d99b-a801-48ce-99a5-ef4b3f636491.png#averageHue=%23fbfefb&clientId=ubc5fcece-554d-4&from=paste&height=704&id=ub88a0b52&originHeight=785&originWidth=1005&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=417570&status=done&style=none&taskId=uda0757f3-4b8e-414c-8766-2b2c729b27f&title=&width=900.8403168827277" alt="image.png"><br>CPU 能预测未来吗？</p>
<h2 id="预测未来"><a href="#预测未来" class="headerlink" title="预测未来"></a>预测未来</h2><p>对此 CPU 当然是不知道的。<br>那么该怎么办呢？<br>很简单，一个字，<strong>猜</strong>。<br>你没有看错，CPU 会猜一下 if 语句可能会走哪个分支，如果猜对了流水线照常继续，如果猜错了，对不起，<strong>流水线上已经执行的后续指令全部作废</strong>，因此我们可以看到如果CPU猜错了会有性能损耗。<br>现代 CPU 将“猜”的这个过程称为<strong>分支预测</strong>。<br>当然，CPU 中的分支预测并不是简单的抛硬币式的随机瞎猜，而且有特定策略，比如可能会基于执行跳转指令的历史去进行预测等等。<br>知道了分支预测就可以解释文章开头的问题了。</p>
<h2 id="程序员的心思你别猜"><a href="#程序员的心思你别猜" class="headerlink" title="程序员的心思你别猜"></a>程序员的心思你别猜</h2><p>现在我们知道，程序员编写的 if 语句对应的是跳转指令：</p>
<figure class="highlight r"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> <span class="punctuation">(</span>arr<span class="punctuation">[</span>i<span class="punctuation">]</span> <span class="operator">&gt;=</span> <span class="number">256</span><span class="punctuation">)</span> <span class="punctuation">&#123;</span><span class="built_in">sum</span> <span class="operator">+</span><span class="operator">=</span> arr<span class="punctuation">[</span>i<span class="punctuation">]</span>;<span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure>
<p>CPU 在执行完跳转指令之前必须决定后续哪个分支的指令会进入到流水线，猜对了流水线照常进行，猜错了有性能损耗。<br>那么如果一个数组是有序的：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696777932313-cbec4c5e-8ba1-4feb-9679-b8b17a0d141e.png#averageHue=%23fafefb&clientId=ubc5fcece-554d-4&from=paste&height=224&id=u4faeb469&originHeight=250&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=235179&status=done&style=none&taskId=u1f6b83ce-8245-48c9-8f41-76cb57df2ad&title=&width=968.0672062023343" alt="image.png"><br>而如果一个数组是无序的：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696777943369-c706f84b-a622-44af-9e0d-3503f952f9de.png#averageHue=%236597e0&clientId=ubc5fcece-554d-4&from=paste&height=211&id=u2341773e&originHeight=235&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=210654&status=done&style=none&taskId=u1dc0e3c8-107a-42e8-8cac-2fd6b1d12e1&title=&width=968.0672062023343" alt="image.png"><br>你觉得哪种更好猜一些？<br>如果你给CPU一个无序数组，那么 Arr[i] 是否大于256 基本上就是随机的，<strong>对于随机事件，不要说CPU的分支预测，任何其它预测手段都将无效，否则这就不是随机事件了</strong>。<br>如果 CPU 猜的不对，那么流水线上的后续指令将作废，这就解释了为什么处理有序数组要比处理无序数组性能好了，因为在数组有序的情况下，CPU 的分支预测几乎不会猜错，流水线上的指令不会被频繁作废。<br>这对程序员的启示就是：如果你编写了 if 语句，那么<strong>你最好让 CPU 大概率能猜对</strong>。<br>有的同学看到这里，可能会觉得每一条 if 语句都性能低下，恨不得从此不再写if else，真的是这样吗？</p>
<h2 id="编写-If-else时需要注意什么"><a href="#编写-If-else时需要注意什么" class="headerlink" title="编写 If else时需要注意什么"></a>编写 If else时需要注意什么</h2><p>实际上如果你编写的if语句没有位于对性能要求很高的核心代码部分，那么分支预测失败这种问题无需关心。<br>实际上现代 CPU 的分支预测是很聪明的，对于非核心部分的if 语句分支预测失败带来的性能损失可以忽略不计。<br>但是对于文章开头提到的代码，程序的大部分时间都用在了 for 循环中，这时你就要注意了，<strong>当然前提还是这段代码对时间要求非常严苛</strong>，否则你也没必要为了这点性能去优化。<br>好奇的同学可能会问，如果给定的数组是无序的，那么上面提到的这段该怎么优化呢？</p>
<h2 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h2><p>实际上非常简单，只需要移除 if 语句就可以，该怎么移除呢？<br>没有 if 语句的话，<strong>那么 sum 每次都必须加上一个数</strong>，如果arr[i]比256大，那么 sum 加上差值，否则sum 加 0即可，这样就消除了if 判断。<br>我们计算arr[i] - 256的值，并将其向右移动31位:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">(arr[i] - <span class="number">256</span>) &gt;&gt; <span class="number">31</span></span><br></pre></td></tr></table></figure>
<p>这样得到的数不是0 (0x00000000)，就是 -1 (0xffffffff)，然后我们对其取反，再次与上 arr[i] 即可:</p>
<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum += ~((arr[i] - <span class="number">256</span>) &gt;&gt; <span class="number">31</span>) &amp; arr[i];</span><br></pre></td></tr></table></figure>
<p>也就是说如果arr[i] - 256 大于0的话那么差值会与上 0xffffffff，其结果就是保持不变，否则会与上0，其结果就是sum会加上0，这样就不需要 if 判断了。<br>利用位运算，即使数组是无序的也不会有性能问题，<strong>代价就是代码可读性会降低很多</strong>，这里，我们再一次看到<strong>天下没有免费的午餐</strong>。</p>
<h2 id="总结-10"><a href="#总结-10" class="headerlink" title="总结"></a>总结</h2><p>虽然 CPU 体积很小，只有指甲那么大，但 CPU 可能是人类有史以来建造过的最复杂的东西，在这里实现了很多有趣的功能，程序员只有彻底理解 CPU 才能更好的利用这些功能编写性能优异的程序。</p>
<h1 id="十三、CPU进化论：复杂指令集的诞生"><a href="#十三、CPU进化论：复杂指令集的诞生" class="headerlink" title="十三、CPU进化论：复杂指令集的诞生"></a>十三、CPU进化论：复杂指令集的诞生</h1><p>英国生物学家达尔文于 1859 年出版了震动整个学术界和宗教界的《物种起源》，达尔文在这本书里提出了生物进化论学说，认为生命在不断演变进化，物竞天择适者生存。<br>**没有历史的计算机 **<br>生命是这样，实际上计算机技术也是如此。<br>计算机技术也和生命体一样在不断演变进化，在讨论一项技术时，如果不了解其演变过程而仅仅着眼于当下就会让人疑惑，不巧的是这正是当前计算机教育的现状——没有历史。<br>因此，在这里我将尝试从历史的角度来讲讲 CPU，以及 CPU 的发展历程。<br>本篇主要关注CPU与复杂指令集CISC。<br>首先来看下什么是CPU。</p>
<h2 id="什么是CPU？"><a href="#什么是CPU？" class="headerlink" title="什么是CPU？"></a>什么是CPU？</h2><p>我们都是程序员，那么从程序员的角度来看，CPU的工作其实是很简单的。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696778421484-1cab7661-7472-4f4b-99c2-164567f9ae0a.png#averageHue=%23566065&clientId=ubc5fcece-554d-4&from=paste&height=562&id=u5c4a7129&originHeight=627&originWidth=940&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=1158430&status=done&style=none&taskId=uffd089a6-a585-450c-b335-d33c06666c6&title=&width=842.5770128057354" alt="image.png"><br>我们编写的所有程序，不管是简单的Hello World，还是复杂的比如PhotoShop之类大型App，最终都会被编译器转为一条条简单的机器指令，因此在CPU看来所有程序是没有什么本质区别的，无非就是一个包含的指令多，一个包含的指令少，这些指令就保存在可执行文件中，程序运行时被加载到内存开始被CPU执行。<br>管你是简单程序还是复杂程序，CPU才不关心这些，它只需要简单一条一条的执行就可以了，因此，在程序员眼里 CPU 是一个很简单的家伙。<br>有很多同学可能会好奇CPU是怎么构造出来，你可以参考《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485736&idx=1&sn=a70558b5200e840ef251e19a2eef099b&source=41#wechat_redirect">链接</a>你管这破玩意叫CPU》。<br>接下来我们的视角就可以进一步聚焦了，CPU执行的是什么机器指令呢？</p>
<h2 id="CPU的能力圈：指令集"><a href="#CPU的能力圈：指令集" class="headerlink" title="CPU的能力圈：指令集"></a>CPU的能力圈：指令集</h2><p>我们该怎样描述一个人的能力呢？写过简历的同学肯定都知道，就像这样：</p>
<blockquote>
<p>会写代码<br>会炒菜<br>会唱歌<br>会跳舞<br>会炒股<br>。。。</p>
</blockquote>
<p>巴菲特有一个词用的很好，这叫能力圈，如果一个人会“写代码”，那么你命令这个人“写代码”，他就能写出代码来(现实情况下你让他写代码他可能会过来打你)。<br>CPU也是同样的道理，每种类型的CPU都要自己的能力圈，只不过CPU的能力圈有一个特殊的名字，叫做 Instruction Set Architecture ，ISA，也就是<strong>指令集</strong>，指令集中包含各种各样的指令：</p>
<blockquote>
<p>会加法<br>会从内存把数据搬运到寄存器<br>会跳转<br>会比较大小<br>。。。</p>
</blockquote>
<p>指令集告诉我们一个CPU可以干嘛。<br>你从ISA中找一条指令发给CPU，CPU就是完成这条指令所代表的任务。<br>ISA有什么用呢，当然是程序员用来编程啦！<br>没错，最初的程序都是面向CPU直接用汇编来写程序，这一时期也非常的朴实无华，没有那么多花哨的概念，什么面向对象啦，什么设计模式啦，统统没有，总之这个时期的程序员写代码只需要看看ISA就可以了。<br>这就是指令集的概念，注意，指令集是CPU告诉程序员该怎么让自己工作的。<br><strong>不同的CPU会有不同类型的指令集</strong>，<strong>指令集的类型除了影响程序员写汇编程序之外还会影响CPU的硬件设计</strong>，到底CPU该采用什么类型的指令集，CPU该如何设计，这一论战持续至今，并且愈发精彩。<br>接下来我们看一下第一种也是最先诞生的指令集类型：复杂指令集，Complex Instruction Set Computer，简称CISC。当今普遍存在于桌面PC以及服务器端的x86架构就是基于复杂指令集CISC，生产x86处理器的厂商就是我们熟悉的“等，等等等等”英特尔以及AMD。</p>
<h2 id="抽象：少就是多"><a href="#抽象：少就是多" class="headerlink" title="抽象：少就是多"></a>抽象：少就是多</h2><p>直到1970s年代，这一时期编译器还非常菜，不像现在这么智能，没多少人信得过编译器，<strong>大部分程序还是用汇编语言纯手工编写</strong> (这一点极为重要，对于接下来理解复杂指令集非常关键)，这对现代程序员来说是无法想象的，不要说手写汇编语言，就是看懂汇编语言的程序员都不会很多。<br>当然，现代编译器已经足够强大足够智能，编译器生成的汇编语言已经足够优秀，因此当今程序员，除了编写操作系统以及部分驱动的那帮家伙，剩下的几乎已经意识不到汇编语言的存在了，不要觉得可惜，这是生产力进步的表现，用高级语言编写程序的效率可是汇编语言望尘莫及的。<br>题外话说的有点多，总之，这一时期的大部分程序都是直接通过汇编语言编写的，因此<strong>大家普遍认为指令集应该更加丰富一些、指令本身功能更强大一些</strong>，程序员常用的操作最好都有对应的特定指令，毕竟大家都在直接用汇编语言来写程序，如果指令集很少或者指令本身功能单一，那么程序员用汇编指令写起程序会会非常繁琐，很不方便，<strong>如果你在这个时期用汇编写程序你也会这样想</strong>。<br>这就是这个时期一些计算机科学家所谓的抹平差异，semantic gap，抹平什么差异呢？<br>大家认为高级语言中的一些概念比如函数调用、循环控制、复杂的寻址模式、数据结构和数组的访问等都应该直接有对应的机器指令，这些就是现代大家认为的复杂指令集CISC非常鲜明的特点。<br>除了更方便的使用汇编语言写程序，另一点需要考虑就是存储。</p>
<h2 id="物种起源"><a href="#物种起源" class="headerlink" title="物种起源"></a>物种起源</h2><p>当今的计算机都遵从冯诺依曼架构，该架构的核心思想之一是“<strong>程序应该和数据一样都作为比特保存在计算机存储设备中</strong>”，下面这张图是所有计算设备的鼻祖，你现在看这篇文章用计算设备，不管是智能手机或者iPad、PC，亦或是存放这篇文章的微信数据中心服务器，其本质都是下面这张简单的图，<strong>这张图是一切计算设备的起源</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696779380083-70d93d97-8839-4640-98ce-05163ec2031c.png#averageHue=%23eeeeec&clientId=ubc5fcece-554d-4&from=paste&height=584&id=uce24ffc9&originHeight=651&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=139866&status=done&style=none&taskId=u765fbd80-649c-4eac-9707-736b053b120&title=&width=968.0672062023343" alt="image.png"><br><strong>代码也是要占存储空间的 **<br>从冯诺依曼结构中我们就能知道为什么当今可执行程序中，比如Windows下的EXE或者Linux下的ELF文件，即包含机器指令也包含数据，对于程序员来说我们可以简单的认为可执行程序中有两部分内容：数据段以及代码段：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696779424569-94bee102-97b3-4a0c-b775-bc5153bbeb6e.png#averageHue=%234d82d4&clientId=ubc5fcece-554d-4&from=paste&height=415&id=uf3367a6f&originHeight=463&originWidth=343&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=87961&status=done&style=none&taskId=u4d1ca75b-7982-4a49-8672-b8c6b981916&title=&width=307.4509738216673" alt="image.png"><br>由此可见，程序员写的代码是要占据存储空间的，要知道在1970s年代，内存大小仅仅数KB到数十KB，这是当今程序员不可想象的，因为现在(2021年)的智能手机内存都已经数GB。如图所示是1974年发布的Intel 1103内存芯片：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696779461096-27d60c95-eed5-432a-b5c3-4b6b102118ea.png#averageHue=%23aca89c&clientId=ubc5fcece-554d-4&from=paste&height=463&id=uc9e9130c&originHeight=517&originWidth=780&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=697764&status=done&style=none&taskId=u6726125e-d778-4a58-acd8-ce48677ad27&title=&width=699.1596489239081" alt="image.png"><br>大小只有 1KB 的英特尔1103存储芯片的于1974年发布，这标志着计算机工业界开始进入动态随机存储DRAM时代，DRAM也就是我们熟知的内存。<br>大家可以思考一下，几KB的内存，可谓寸土寸金，</strong>这么小的内存要想装入更多的程序就必须仔细的设计机器指令以节省程序占据的空间**，这就要求： </p>
<ol>
<li>一条机器指令尽可能完成更多的任务，这很容易理解，就像在《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485731&idx=1&sn=9f8dbed55312c6c10527496cf8e7a982&source=41#wechat_redirect">你管这破玩意叫编程语言</a>》这篇中的例子一样，你更希望有一条“给我端杯水”的指令，而不是自己去写“迈出左脚；停住；迈出右脚；直到饮水机；伸出右手；拿起水杯；接水。。。”等等这样的汇编代码 </li>
<li>机器指令长度不固定，也就是变长机器指令，简单的指令占据更少的空间 </li>
<li>机器指令高度编码(encoded)，提高代码密度，节省空间</li>
</ol>
<h2 id="复杂指令集诞生的必然"><a href="#复杂指令集诞生的必然" class="headerlink" title="复杂指令集诞生的必然"></a>复杂指令集诞生的必然</h2><p>基于对程序员方便编写汇编语言以及节省代码存储空间的需要，直接促成了复杂指令集的设计，因此我们可以看到复杂指令集是这一时期必然的选择，该指令集就这样诞生了并开始成为主流。<br>就这样经过一段时间后，人们发现了新的问题，由于单条指令比较复杂，设计解码机器指令的硬件(CPU的一部分)成了一件非常麻烦的事情，该怎样解决这一问题呢？</p>
<h2 id="CPU真的在直接执行机器指令吗？"><a href="#CPU真的在直接执行机器指令吗？" class="headerlink" title="CPU真的在直接执行机器指令吗？"></a>CPU真的在直接执行机器指令吗？</h2><p>作为程序员，我们知道，对于重复使用的代码其实是没有必要一遍遍编写的，你可以把这些代码封装到函数中，这样每次使用时只需要调用这个函数就好了，这个思路可以解决上述问题。<br>对于指令集中的每一条机器指令都有一小段对应的程序，这些程序存储在CPU中，<strong>这些程序都是由更简单的指令组成</strong>，这些指令就是所谓的微代码，Microcode。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696779835740-760a9f0b-dcd1-48cd-9077-c52e0024f32b.png#averageHue=%23a6b5c8&clientId=ubc5fcece-554d-4&from=paste&height=306&id=ucbc4149a&originHeight=341&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=195648&status=done&style=none&taskId=uaac2f5e7-7b93-4312-b01d-e621f5611ee&title=&width=968.0672062023343" alt="image.png"><br>就这样CPU的指令集可以添加更多的指令，代价仅仅是再多一些简单的微代码而已，是不是很天才的设计。<br>在这里也可以看到，一般我们认为CPU直接执行机器指令，严格来说这是不正确的，对于含有微代码设计的CPU来说，CPU直接执行的并不是机器指令，而是微代码，微代码是CPU以及机器指令的中间层，<strong>机器指令相对于微代码来说是“更高级的语言”，机器指令对程序员来说可见，但微代码对程序员来说不可见，程序员无法直接使用微代码来控制CPU</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696779853093-a787ba6e-8fcc-4833-9df9-008ab2915a34.png#averageHue=%237ca0d8&clientId=ubc5fcece-554d-4&from=paste&height=302&id=uc219842d&originHeight=337&originWidth=617&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=84012&status=done&style=none&taskId=u4ca86866-5d8d-4abd-9fbc-b6dc770ffc5&title=&width=553.0532094692966" alt="image.png"><br>而在这一时期，这些微代码普遍存放在ROM中，Read-Only Memory，而ROM普遍要比内存便宜，因此依靠存储在ROM中的微代码来设计更多复杂指令进而减少程序本身对内存的占用是非常划算的。</p>
<h2 id="新的问题"><a href="#新的问题" class="headerlink" title="新的问题"></a>新的问题</h2><p>一切看上去都很好，有了复杂指令集，程序员可以更方便的编写汇编程序，这些程序也不需要占用很多存储空间，代价就是CPU中需要有微代码来简化CPU设计。<br>然而这一设计随着时间的推移又出现了新的问题。<br>作为程序员我们知道代码难免会有bug，微代码也不会有例外。但修复微代码的bug要比修复普通程序的bug困难的多，你无法像普通程序那样来测试、调试微代码，这一切都太复杂了。<br>而且微代码设计非常消耗晶体管，1979年代的Motorola 68000 处理器就采用该设计，其中三分之一的晶体管都用在了微代码上。<br>同年，计算机科学家Dave Patterson被委以重任来改善微代码设计，为此他还专门发表了论文，但他后来又推翻了自己想法，<strong>认为微代码设计的复杂性问题很难解决，有问题的是微代码这种设计本身</strong>。。<br>因此，有人开始反思，是不是还会有更好的设计。。。<br>预知后事如何请听下回分解。</p>
<h2 id="总结-11"><a href="#总结-11" class="headerlink" title="总结"></a>总结</h2><p>CPU是整个计算机系统的核心，CPU指令集ISA更是核心中的核心。<br>本文从历史的角度讲述了复杂指令集出现的必然，复杂指令集对于那些直接使用汇编语言进行编程的程序员来说是很方便的，同时复杂指令集的指令密度更高，相同的存储空间可以存储更多程序，这一切都推动了复杂指令集的发展。<br>然而任何事物都有其必然性以及局限性，复杂指令集也不例外，随着时间的推移采用复杂指令集的CPU设计出现各种各样的问题，面对这些问题一部分人开始重新思考指令集到底该如何设计，我们将在下篇文章中继续讲述这一话题。 </p>
<h1 id="十四、CPU进化论：复杂指令集的诞生"><a href="#十四、CPU进化论：复杂指令集的诞生" class="headerlink" title="十四、CPU进化论：复杂指令集的诞生"></a>十四、CPU进化论：复杂指令集的诞生</h1><p>在上一篇文章《CPU进化论：复杂指令集》中我们从历史的角度讲述了复杂指令集出现的必然，随着时间的推移，采用复杂指令集架构的CPU出现各种各样的问题，面对这些问题一部分人开始重新思考指令集到底该如何设计。<br>在这一时期，两个趋势的出现促成一种新的指令集设计思想。</p>
<h2 id="内存与编译器"><a href="#内存与编译器" class="headerlink" title="内存与编译器"></a>内存与编译器</h2><p>时间来到了1980s年代，此时容量“高达”64K的内存开始出现，内存容量上终于不再捉襟见肘，价格也开始急速下降，在1977年，1MB内存的价格高达**$5000<strong>，要知道这可是1977年的5000刀，但到了1994年，1MB内存价格就急速下降到大概只有$6，这是第一个趋势。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696780157513-4fd17a3c-a6c9-4310-bd96-f04956e91136.png#averageHue=%23bcb792&clientId=ubc5fcece-554d-4&from=paste&height=412&id=u5e86ba36&originHeight=460&originWidth=715&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=409664&status=done&style=none&taskId=ufd2a0691-1ced-464e-997d-3844fa5d037&title=&width=640.8963448469158" alt="image.png"><br>此外在这一时期随着编译技术的进步，编译器越来越成熟，</strong>渐渐的程序员们开始依靠编译器来生成汇编指令而不再自己手工编写**。<br>这两个趋势的出现让人们有了更多思考。</p>
<h2 id="化繁为简"><a href="#化繁为简" class="headerlink" title="化繁为简"></a>化繁为简</h2><p>19世纪末20世纪初意大利经济学家Pareto发现，在任何一组东西中，最重要的只占其中一小部分，约20%，其余80%尽管是多数，却是次要的，这就是著名的二八定律，机器指令的执行频率也有类似的规律。<br>大概80%的时间CPU都在执行那20%的机器指令，同时CISC中一部分比较复杂的指令并不怎么被经常用到，而且那些<strong>设计编译器的程序员也更倾向于组合一些简单的指令来完成特定任务。 **<br>与此同时我们在上文提到过的一位计算机科学家，被派去改善微代码设计，但后来这老哥发现有问题的是微代码本身，因此开始转过头来去思考微代码这种设计的问题在哪里。<br>他的早期工作提出一个关键点，复杂指令集中那些被认为可以提高性能的指令其实在内部被微代码拖后腿了，如果移除掉微代码，程序反而可以运行的更快，并且可以节省构造CPU消耗的晶体管数量。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696780243103-1378bac5-ed22-4a3a-8213-2fb1ddb1eaee.png#averageHue=%23515889&clientId=ubc5fcece-554d-4&from=paste&height=589&id=uc6f0e21c&originHeight=657&originWidth=1030&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=1829976&status=done&style=none&taskId=u9c7289f8-eb70-4b50-8e42-4ff0e7db059&title=&width=923.2492799892633" alt="image.png"><br>由于微代码的设计思想是将复杂机器指令</strong>在CPU内部<strong>转为相对简单的机器指令，这一过程对编译器不可见，也就是说你没有办法通过编译器去影响CPU内部的微代码运行行为，因此如果微代码出现bug那么编译器是无能为力的，你没有办法通过编译器生成其它机器指令来修复问题而只能去修改微代码本身。<br>此外他还发现，有时一些复杂的机器指令执行起来要比等价的多个简单指令要(作者没写，应该是简单)。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696780284620-56ad6389-ca82-49b5-a6ee-c5a827964757.png#averageHue=%23fefefc&clientId=ubc5fcece-554d-4&from=paste&height=274&id=u504b2de4&originHeight=306&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=102638&status=done&style=none&taskId=u5e2e5425-abc8-435c-b641-24980839f8d&title=&width=968.0672062023343" alt="image.png"><br>这一切都在提示：</strong>为什么不直接用一些简单的指令来替换掉那些复杂的指令呢**？</p>
<h2 id="精简指令集哲学"><a href="#精简指令集哲学" class="headerlink" title="精简指令集哲学"></a>精简指令集哲学</h2><p>基于对复杂指令集的思考，精简指令集哲学诞生了，精简指令集主要体现在以下三个方面： </p>
<h3 id="1，指令本身的复杂度"><a href="#1，指令本身的复杂度" class="headerlink" title="1，指令本身的复杂度"></a>1，指令本身的复杂度</h3><p>精简指令集的思想其实很简单，干嘛要去死磕复杂的指令，去掉复杂指令代之以一些简单的指令。有了简单指令CPU内部的微代码也不需要了，没有了微代码这层中间抽象，编译器生成的机器指令对CPU的控制力大大增强，有什么问题让写编译器的那帮家伙修复就好了，显然调试编译器这种软件要比调试CPU这种硬件要简单很多。<br>注意，<strong>精简指令集思想不是说指令集中指令的数量变少，而是说一条指令背后代表的动作更简单了</strong>。举个简单的例子，复杂指令集中的一条指令背后代表的含义是“吃饭”的全部过程，而精简指令集中的一条指令仅仅表示“咀嚼一下”的其中一个小步骤。<br>博主在《你管这破玩意叫编程语言》一文中举得例子其实更形象一些，复杂指令集下一条指令可以表示“给我端杯水”，而在精简指令集下你需要这样表示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696780396586-172db98d-12e4-4305-b4c8-ca19868ac23f.png#averageHue=%23fbfcfa&clientId=ubc5fcece-554d-4&from=paste&height=637&id=ua10d9520&originHeight=711&originWidth=1078&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=190525&status=done&style=none&taskId=ueaa56239-3363-4b1b-89fd-1c61c2f2550&title=&width=966.2744891538115" alt="image.png"></p>
<h3 id="2，编译器"><a href="#2，编译器" class="headerlink" title="2，编译器"></a>2，编译器</h3><p>精简指令集的另一个特点就是编译器对CPU的控制力更强。<br>在复杂指令集下，CPU会对编译器隐藏机器指令的执行细节，就像微代码一样，编译器对此无能为力。<br>而在精简指令集下CPU内部的操作细节暴露给编译器，编译器可以对其进行控制，也因此，精简指令集RISC还有一个有趣的称呼：“<strong>R</strong>elegate <strong>I</strong>nteresting <strong>S</strong>tuff to <strong>C</strong>ompiler”，把一些有趣的玩意儿让编译器来完成。</p>
<h3 id="3，load-store-architecture"><a href="#3，load-store-architecture" class="headerlink" title="3，load&#x2F;store architecture"></a>3，load&#x2F;store architecture</h3><p>在复杂指令集下，一条机器指令可能涉及到从<strong>内存</strong>中取出数据、执行一些操作比如加和、然后再把执行结果写回到内存中，注意这是在一条机器指令下完成的。<br>但在精简指令集下，这绝对是大写的禁忌，<strong>精简指令集下的指令只能操作寄存器中的数据</strong>，不可以直接操作内存中的数据，也就是说这些指令比如加法指令不会去访问内存。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696780478777-b1730677-b4b1-4e93-881d-10e535f486a6.png#averageHue=%23f7fcfc&clientId=ubc5fcece-554d-4&from=paste&height=365&id=u1085f7bc&originHeight=407&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=153961&status=done&style=none&taskId=uc1258ac1-a9fb-4fa3-b6be-fd9afd274ca&title=&width=968.0672062023343" alt="image.png"><br>毕竟数据还是存放在内存中的，那么谁来读写内存呢？<br><strong>原来在精简指令集下有专用的 load 和 store 两条机器指令来负责内存的读写</strong>，其它指令只能操作CPU内部的寄存器，这是和复杂指令集一个很鲜明的区别。<br>你可能会好奇，用两条专用的指令来读写内存有什么好处吗？别着急，在本文后半部分我们还会回到load&#x2F;store指令。<br>以上就是三点就是精简指令集的设计哲学。<br>接下来我们用一个例子来看下RISC和CISC的区别。</p>
<h2 id="两数相乘"><a href="#两数相乘" class="headerlink" title="两数相乘"></a>两数相乘</h2><p>如图所示就是最经典的计算模型，最右边是内存，存放机器指令和数据，最左侧是CPU，CPU内部是寄存器和计算单元ALU，进一步了解CPU请参考《你管这破玩意叫CPU？》<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696780560805-b24a6a52-df6b-4788-9fae-917d5c55cdc3.png#averageHue=%23f5f9f9&clientId=ubc5fcece-554d-4&from=paste&height=303&id=u50878c6a&originHeight=338&originWidth=429&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=89910&status=done&style=none&taskId=u6b0adf47-80d1-4e32-88a0-ca8ee0c5e0a&title=&width=384.5378069081495" alt="image.png"><br>内存中的地址A和地址B分别存放了两个数，假设我们想计算这两个数字之和，然后再把计算结果写回内存地址A。<br>我们分别来看下在CISC和在RISC下的会怎样实现。</p>
<h3 id="1，CISC"><a href="#1，CISC" class="headerlink" title="1，CISC"></a>1，CISC</h3><p>复杂指令集的一个主要目的就是让尽可能少的机器指令来完成尽可能多的任务，在这种思想下CPU需要在从内存中拿到一条机器指令后“<strong>自己去完成一系列的操作</strong>”，这部分操作对外不可见。<br>在这种方法下，CISC中可能会存在一条叫做MULT的机器指令，MULT是乘法<strong>mult</strong>iplication的简写。<br>当CPU执行MULT这条机器指令时需要： </p>
<ol>
<li>从内存中加载地址A上的数，存放在寄存器中 </li>
<li>从内存中夹杂地址B上的数，存放在寄存器中 </li>
<li>ALU根据寄存器中的值进行乘积 </li>
<li>将乘积写回内存<br>以上这几部统统都可以用这样一条指令来完成：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">MULT A B</span><br></pre></td></tr></table></figure>
MULT就是所谓的复杂指令了，从这里我们也可以看出，**复杂指令并不是说“MULT A B”这一行指令本身有多复杂，而是其背后所代表的任务复杂。 **<br>这条机器指令直接从内存中加载数据，程序员(写汇编语言或者写编译器的程序员)根本就不要自己显示的从内存中加载数据，实际上这条机器指令已经非常类似高级语言了，我们假设内存地址A中的值为变量a，地址B中的值为变量b，那么这条机器指令基本等价于高级语言中这样一句：<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">a = a * b;</span><br></pre></td></tr></table></figure>
这就是我们在上一篇《CPU进化论：复杂指令集》中提到的所谓抹平差异，semantic gap，抹平高级语言和机器指令之间的差异，让程序员或者编译器使用最少的代码就能完成任务，因为这会节省程序本身占用的内存空间，要知道在在1977年，1MB内存的价格大概需要$5000，<strong>省下来的就是钱</strong>。<br>因为一条机器指令背后的操作很多，而程序员仅仅就写了一行“MULT A B”，这行指令背后的复杂操作就必须由CPU直接通过硬件来实现，这加重了CPU 硬件本身的复杂度，需要的晶体管数量也更多。<br>接下来我们看RISC方法。</li>
</ol>
<h3 id="2，RISC"><a href="#2，RISC" class="headerlink" title="2，RISC"></a>2，RISC</h3><p>相比之下RISC更倾向于使用一系列简单的指令来完成一项任务，我们来看下一条MULT指令需要完成的操作： </p>
<ol>
<li>从内存中加载地址A上的数，存放在寄存器中 </li>
<li>从内存中加载地址B上的数，存放在寄存器中 </li>
<li>ALU根据寄存器中的值进行乘积 </li>
<li>将乘积写回内存<br>这几步需要a)从内存中读数据；b)乘积；c) 向内存中写数据，因此在RISC下会有对应的LOAD、PROD、STORE指令来分别完成这几个操作。<br>Load指令会将数据从内存搬到寄存器；PROD指令会计算两个寄存器中数字的乘积；Store指令把寄存器中的数据写回内存，因此如果一个程序员想完成上述任务就需要写这些汇编指令：<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">LOAD RA, A</span><br><span class="line">LOAD RB, B</span><br><span class="line">PROD RA, RB</span><br><span class="line">STORE A, RA</span><br></pre></td></tr></table></figure>
现在你应该看到了，同样一项任务，在CISC下只需要一条机器指令，而在RISC下需要四条机器指令，显然RISC下的程序本身所占据的空间要比CISC大，而且这对直接用汇编语言来写程序的程序员来说是很不友好的，因为更繁琐嘛！再来看看这样图感受一下：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696781310579-9643e851-af8e-4884-95b5-1fe0b347a50d.png#averageHue=%23fbfcfa&clientId=ubc5fcece-554d-4&from=paste&height=637&id=u408cc831&originHeight=711&originWidth=1078&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=190525&status=done&style=none&taskId=u1e9d8380-cf86-464d-bdfd-7d6b22432a3&title=&width=966.2744891538115" alt="image.png"><br>但RISC设计的初衷也<strong>不是让程序员直接使用汇编语言来写程序</strong>，而是把这项任务交给编译器，让编译器来生成机器指令。</li>
</ol>
<h2 id="标准从来都是一个好东西"><a href="#标准从来都是一个好东西" class="headerlink" title="标准从来都是一个好东西"></a>标准从来都是一个好东西</h2><p>让我们再来仔细的看一下RISC下生成的几条指令：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOAD RA, ALOAD RB, BPROD RA, RBSTORE A, RA</span><br></pre></td></tr></table></figure>
<p>这些指令都非常简单，CPU内部不需要复杂的硬件逻辑来进行解码，因此更节省晶体管，这些节省下来的晶体管可用于其它功能上。<br>最关键的是，注意，由于每一条指令都很简单，执行的时间都差不多，因此这使得一种能高效处理机器指令的方法成为可能，这项技术是什么呢？<br>我们在《CPU遇上特斯拉，程序员的心思你别猜》这篇文章中提到过，这就是有名的<strong>流水线技术</strong>。</p>
<h2 id="指令流水线"><a href="#指令流水线" class="headerlink" title="指令流水线"></a>指令流水线</h2><p>流水线技术是初期精简指令集的杀手锏。<br>在这里我们还是以生产汽车(新能源)为例来介绍一下。<br>假设组装一辆汽车需要经过四个步骤：组装车架、安装引擎、安装电池、检验。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696781389631-106767f1-7e8d-4942-a921-b96c73263789.png#averageHue=%23d8e9ea&clientId=ubc5fcece-554d-4&from=paste&height=535&id=ub2d0a1e3&originHeight=833&originWidth=895&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=324470&status=done&style=none&taskId=u4dbbf920-2c37-48ee-b940-7551e7dc0cb&title=&width=575.2044677734375" alt="image.png"><br>假设这每个步骤需要10分钟，如果没有流水线技术，那么生产一辆汽车的时间是40分钟，只有第一辆汽车完整的经过这四个步骤后下一辆车才能进入生产车间。<br>这就是最初复杂指令集CPU的工作场景。<br>显然这是相当低效的，因为当前一辆车在进行最后一个步骤时，前三个步骤：组装车架、安装引擎、安装电池，这三个步骤的工人是空闲。<br>CPU的道理也是一样的，低效的原因在于没有充分利用资源，在这种方法下有人会偷懒。<br>但引入流水线技术就不一样了，当第一辆车还在安装引擎时后一辆车就可以进入流水线来组装车架了，采用流水线技术，四个步骤可以同时进行，<strong>最大可能的充分利用资源</strong>。<br>原来40分钟才能生产一辆车，现在有了流水线技术可以10分钟就生产出一辆车。<br>注意，这里的假设是每个步骤都需要10分钟，<strong>如果流水线每个阶段的耗时不同，将显著影响流水线的处理能力</strong>。<br>假如其中一个步骤，安装电池，需要20分钟，那么安装电池的前一个和后一个步骤就会有10分钟的空闲，这显然不能充分利用资源。<br>精简指令集的设计者们当然也明白这个道理，因此<strong>他们尝试让每条指令执行的时间都差不多一样</strong>，尽可能让流水线更高效的处理机器指令，而这也是为什么在精简指令集中存在Load和Store两条访问内存指令的原因。<br>由于复杂指令集指令与指令之间差异较大，执行时间参差不齐，没办法很好的以流水线的方式高效处理机器指令(后续我们会看到复杂指令集会改善这一点)。<br>第一代RISC处理器即为全流水线设计，典型的就是五级流水线，大概1到2个时钟周期就能执行一条指令，而这一时期的CISC大概5到10个时钟周期才能执行一条指令，尽管RISC架构下编译出的程序需要更多指令，但RISC精简的设计使得RISC架构下的CPU更紧凑，消耗更少的晶体管(无需微代码)，因此带来更高的主频，这使得RISC架构下的CPU完成相同的任务速度优于CISC。<br>有流水线技术的加持，采用精简指令集设计的CPU在性能上开始横扫其复杂指令集对手。</p>
<h2 id="名扬天下"><a href="#名扬天下" class="headerlink" title="名扬天下"></a>名扬天下</h2><p>到了1980年代中期，采用精简指令集的商业CPU开始出现，到1980年代后期，采用精简指令集设计的CPU就在性能上轻松碾压所有传统设计。<br>到了1987年采用RISC设计的MIPS R2000处理器在性能上是采用CISC架构(x86)的Intel i386DX两到三倍。<br>所有其它CPU生成厂商都开始跟进RISC，积极采纳精简指令集设计思想，甚至操作系统MINIX（就是那个Linus上大学时使用的操作系统）的作者Andrew Tanenbaum在90年代初预言：“5年后x86将无人问津”，x86正是基于CISC。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696781545345-5861316c-b892-499e-b54e-f9ed66fb6bb2.png#averageHue=%23fafdfb&clientId=ubc5fcece-554d-4&from=paste&height=163&id=u36b8534f&originHeight=182&originWidth=276&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=46671&status=done&style=none&taskId=u48226490-df3d-4bdb-a8e0-80cbe042e17&title=&width=247.3949526961521" alt="image.png"><br><strong>CISC迎来至暗时刻</strong>。<br>接下来CISC该如何绝地反击，要知道Inter以及AMD (x86处理器两大知名生产商) 的硬件工程师们绝非等闲之辈。<br>预知后事如何，请听下回分解。</p>
<h2 id="总结-12"><a href="#总结-12" class="headerlink" title="总结"></a>总结</h2><p>CISC中微代码设计的复杂性让人们重新思考CPU到底该如何设计，基于对执行指令的重新审视RISC设计哲学应运而生。<br>RISC中每条指令更加简单，执行时间比较标准，因此可以很高效的利用流水线技术，这一切都让采用RISC架构的CPU获得了很好性能。<br>面对RISC，CISC阵营也开始全面反思应如何应对挑战。后续文章将继续这一话题。</p>
<h1 id="十五：CPU核数与线程数有什么关系？"><a href="#十五：CPU核数与线程数有什么关系？" class="headerlink" title="十五：CPU核数与线程数有什么关系？"></a><strong>十五：CPU核数与线程数有什么关系？</strong></h1><p>作为一名美食资浅爱好者，尽管小风哥我厨艺拙计，但依然阻挡不了我对烹饪的热爱。<br>那小风哥我通常是怎么做菜的呢？</p>
<h2 id="大厨与菜谱"><a href="#大厨与菜谱" class="headerlink" title="大厨与菜谱"></a>大厨与菜谱</h2><p>你没猜错，做菜之前先去下一份菜谱，照着菜谱一步步来：起锅烧油、葱姜蒜末下锅爆香、倒入切好的食材、大火翻炒、加入适量酱油、加入适量盐、继续翻炒、出锅喽！<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696782382299-498b1a76-8abd-41ce-8193-c24aabd8d625.png#averageHue=%23627360&clientId=ubc5fcece-554d-4&from=paste&height=645&id=u150cc86f&originHeight=720&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=1703838&status=done&style=none&taskId=u8dfc81c8-388c-4b42-8348-c8500167afa&title=&width=968.0672062023343" alt="image.png"><br>这样一道色香味俱佳的小炒大功告成，装盘端出来拿起筷子一尝，难吃死了。 火候有点过，酱油加的有点少，盐加多了，中餐里的“火候”以及“适量”是最为神秘的存在，可以意会不可言传。因此相对肯德基麦当劳之类的标准工业品，中餐更像是艺术。每个人炒出来的菜味道都不一样，显然嘛，每个人对火候以及适量的理解是不一样的。<br>对不起，跑题了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696782389524-51c8f635-6a8e-46ca-bc1b-d64b99412c42.png#averageHue=%2395732a&clientId=ubc5fcece-554d-4&from=paste&height=57&id=ufed33753&originHeight=64&originWidth=64&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=8883&status=done&style=none&taskId=u2e75c732-0665-4aa5-a822-164ef05cb08&title=&width=57.366945552730925" alt="image.png"><br>虽然小风哥我厨艺不怎么样，但输厨艺不能输气场，有时我会几样一起来，这边炒着A菜，那边炒着B菜。<br>也就是说，我可以同时按照两份菜谱去做饭，如果小风哥足够快，那么我可以同时炒 N 样菜。</p>
<h2 id="炒菜与线程"><a href="#炒菜与线程" class="headerlink" title="炒菜与线程"></a>炒菜与线程</h2><p>实际上CPU和厨师一样，都是按照菜谱(机器指令)去执行某个动作，<strong>从操作系统的角度讲当CPU切换回用户态后，CPU执行的一段指令就是线程，或者说属于某个线程</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696782748919-d47291d9-e072-49fa-bed3-c45f8c6068aa.png#averageHue=%23fdfefb&clientId=ubc5fcece-554d-4&from=paste&height=411&id=ue7a5940d&originHeight=509&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=183924&status=done&style=none&taskId=u69b36e3c-1536-4149-ae10-4b149b9307e&title=&width=871.2604762723113" alt="image.png"><br>这和炒菜一样，我可以按照菜谱抄鱼香肉丝，那么炒菜时这就是鱼香肉丝线程；我可以按照菜谱抄宫保鸡丁，那么炒菜时这就是宫保鸡丁线程。<br>厨师个数就好比CPU核心数，炒菜的样数就好比线程数，这时我问你，你觉得厨师的个数和可以同时抄几样菜有关系吗？<br>答案当然是没有。<br><strong>CPU的核心数和线程个数没有什么必然的关系</strong>。<br>单个核心上可以跑任意多个线程，只要你的内存够就行；计算机系统内也可以有任意多核数，只要你有钱就行。<br>看到这个答案你是不是觉得有点疑惑、有点疑问、有点不明所以，这好像和其它人说的不一样啊！<br>别着急，我们慢慢讲。</p>
<h2 id="傻傻的CPU"><a href="#傻傻的CPU" class="headerlink" title="傻傻的CPU"></a>傻傻的CPU</h2><p>CPU根本不理解自己执行的指令属于哪个线程，CPU也不需要理解这些，<strong>CPU需要做的事情就是根据PC寄存器中的地址从内存中取出后执行，其它没了</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696782892974-d98484ff-2d37-4df7-9c2e-f39702549d1f.png#averageHue=%23fefefb&clientId=ubc5fcece-554d-4&from=paste&height=480&id=uc8e7b26f&originHeight=595&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=229870&status=done&style=none&taskId=u58490408-9d1f-45ae-a91d-21821e05d4c&title=&width=871.2604762723113" alt="image.png"><br>你看CPU才不管你系统内有多少线程。<br>有多少线程是谁需要来关心的呢？是操作系统。<br>线程是操作系统的把戏。</p>
<h2 id="操作系统与多任务"><a href="#操作系统与多任务" class="headerlink" title="操作系统与多任务"></a>操作系统与多任务</h2><p>很久很久以前，计算机一次只能执行一个任务，你不能像现在这样在计算机上一边看电影一边在下小电影，哦，不对，一边写代码，一边下载资料。<br>要么你先写代码，写完代码后再去下资料，要么你先下资料然后再写代码，总之，<strong>这两个任务不能同时进行</strong>。<br>这显然很不方便，就这样，多任务——Multi-Tasking，诞生了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696783022089-3cf57c50-ddc7-4471-a55e-69ef5eee3b49.png#averageHue=%23221e15&clientId=ubc5fcece-554d-4&from=paste&height=461&id=u6267a9e0&originHeight=571&originWidth=600&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=236965&status=done&style=none&taskId=u421c27cd-cc78-42a4-b224-eeaed1e84a3&title=&width=484.03359792906184" alt="image.png"><br><strong>你CPU不是只知道执行机器指令吗？很好，那我操作系统就通过修改你的PC寄存器，让你CPU执行A任务的机器指令一段时间，然后下一段时间再去执行B任务的机器指令，再然后下一个时间段去执行C任务的机器指令</strong>，由于每一段时间非常少，通常在毫秒级别，那么在人类看来A、B、C三个任务在“同时”运行。<br>这就是多任务的本质。</p>
<h2 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h2><p>CPU不知道执行的某一段机器指令属于A任务还是B任务，只有操作系统知道，同时操作系统还能知道任务A和B任务是否属于同一个<strong>地址空间</strong>。<br>如果属于同一个地址空间，那么任务A和任务B就是我们熟悉的“多线程”；如果不属于同一个地址空间，那么任务A和任务B就是我们熟悉的“多进程”，现在你应该明白这两个概念了吧。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696783067245-3a056583-ecd7-487e-b324-fee0399354e7.png#averageHue=%23a9bad2&clientId=ubc5fcece-554d-4&from=paste&height=510&id=u433d3a0d&originHeight=632&originWidth=638&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=277818&status=done&style=none&taskId=uee2d8abd-9d43-47f6-b939-6eb28c6e773&title=&width=514.6890591312357" alt="image.png"><br>这里出现了一个有点拗口的名词，地址空间，Address Space，关于地址空间的概念以及进程线程这一部分更加详细的讲解，请参考《深入理解操作系统》第7章。<br>值得注意的是，计算机系统还在单核时代就已经有多线程的概念了，我们之前说过，即使是单核也可以执行多个线程，那么有的同学可能会有疑问，在单核的系统中开启多个线程有什么意义吗？</p>
<h2 id="单核与多线程"><a href="#单核与多线程" class="headerlink" title="单核与多线程"></a>单核与多线程</h2><p>假设现在有两个任务，任务A和任务B，每个任务需要的计算时间都是5分钟，那么无论是任务A和任务B串行执行还是放到两个线程中并行执行，在单核环境下执行完这两个任务总需要10分钟，因此有的同学觉得单核下多线程没什么用。实际上，<strong>线程这个概念为程序员提供了一种编程抽象</strong>，我们可以把一项任务进行划分，然后把每一个子任务放到一个个线程中去运行。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696783156753-0d04fd8c-fd3e-41a3-bcfd-58286e28dd02.png#averageHue=%237faff4&clientId=ubc5fcece-554d-4&from=paste&height=343&id=uc3907ccc&originHeight=598&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=287313&status=done&style=none&taskId=u6e7fdbac-9d2b-46e1-b8ff-0188d4ab8e5&title=&width=619.38232421875" alt="image.png"><br>假如你的程序带有图形界面，某个UI元素背后需要的大量运算，这时为了防止执行该运算时UI产生卡顿，那么可以把这个运算任务放到一个单独的线程中去。<br>因此如果你的目的是防止当前线程因执行某项操作而不得不等待，那么在这样的应用场景下，你根本就不需要关心系统内是单核还是多核以及有多少个核。</p>
<h2 id="阻塞式I-O"><a href="#阻塞式I-O" class="headerlink" title="阻塞式I&#x2F;O"></a>阻塞式I&#x2F;O</h2><p>这也是使用线程的经典场景。<br>如果没有线程，那么执行阻塞式I&#x2F;O时整个进程会被操作系统暂停，但如果你开启两个线程，其中一个线程被阻塞时另一个线程依然可以继续向前推进。<br>这样的话你就不需要去使用反人类的异步IO了。<br>当然，<strong>这一切的前提是你的场景不涉及高性能以及高并发</strong>，如果涉及的话那这就是另一个话题了，如果你想了解这一话题，关注公众号“码农的荒岛求生”并回复“高并发”即可。<br>在这种简单的场景下，你创建线程时也不需要关心系统中是单核还是多核。</p>
<h2 id="多核时代"><a href="#多核时代" class="headerlink" title="多核时代"></a>多核时代</h2><p>实际上，线程这个概念是从2003年左右才开始流行的，为什么？因为这一时期，多核时代到来了。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696783242212-2ba4d7f0-e56f-4cb6-be0a-c40f14e96958.png#averageHue=%234a8672&clientId=ubc5fcece-554d-4&from=paste&height=675&id=uf86ce968&originHeight=837&originWidth=939&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=2096175&status=done&style=none&taskId=uc5f9337c-8298-4c77-aeac-a5f0fd41f70&title=&width=757.5125807589818" alt="image.png"><br>之所以产生多核，是因为单核的性能提升越来越困难了。<br>尽管采用多进程也可以充分利用多核，但毕竟多进程编程是很繁琐的，这涉及复杂的进程间通信机制、进程间切换的较高性能损耗、进程间内存相互隔离带来的对内存消耗等。<br>线程这个概念很好的解决了上述问题，开始成为多核时代的主角，要想充分利用多核资源，线程是程序员的首选工具。</p>
<h2 id="真正的并行"><a href="#真正的并行" class="headerlink" title="真正的并行"></a>真正的并行</h2><p>有了多核后，运行在两个线程中的任务A和任务B实现了真正的并行。<br>此前这样一句话广为引用，这句话是这么说的：</p>
<blockquote>
<p>threads are for people who can’t program state machines </p>
</blockquote>
<p>“线程是为那些不懂状态机的人准备的”，这句话在单核时代有它的道理，因为在单核时代，所有的任务都不是在同时向前推进，而是“交错”前进，A前进一点，然后B前进一点，线程并不是实现这种“伪并行”唯一的方法，状态机也可以。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696783388646-d41f8a0b-cca8-47d4-a4ac-45cca64db761.png#averageHue=%23d6e5d5&clientId=ubc5fcece-554d-4&from=paste&height=513&id=ue369ed2e&originHeight=636&originWidth=962&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=134054&status=done&style=none&taskId=u1b2f0c3c-4d84-4d55-a3ef-4b800513f45&title=&width=776.0672020129291" alt="image.png"><br>但在多核时代，这句话就不再适用了，对于大多数程序员来说多进程多线程几乎是充分利用多核资源的唯一方法。<br>如果你的场景是想充分利用多核，那么这时你的确需要知道系统内有多少核数，**一般来说你创建的线程数需要与核数保持线性关系。 **<br>也就是说，如果你的核数翻倍，那么创建的线程数也要翻倍。</p>
<h2 id="需要多少线程？"><a href="#需要多少线程？" class="headerlink" title="需要多少线程？"></a>需要多少线程？</h2><p>值得注意的是，线程不是越多越好。<br>如果你的线程是不涉及任何I&#x2F;O、没有任何同步互斥之类的纯计算类型，那么每个核心一个线程通常是最佳选择。但通常来说，线程都需要一定的I&#x2F;O，可能需要一定的同步互斥，那么这时<strong>适当</strong>增加线程可能会提高性能，但当线程数量到达一个临界值后性能开始下降，这时线程间切换的开销将显著增加。<br>这里之所以用适当这个词，是因为这很难去量化，<strong>只能用你实际的程序根据真正的场景进行测试才能得到这个值</strong>。</p>
<h2 id="总结-13"><a href="#总结-13" class="headerlink" title="总结"></a>总结</h2><p>线程数和CPU核心数可以没有任何关联，如果在使用线程时仅仅针对上述提到的几个简单场景，那么你根本不需要关心CPU是单核还是多核。<br>但当你需要利用线程充分发挥多核威力时，通常情况下你创建的线程数与核数要保持一种线性关系，最佳系数通常需要测试才能得到。</p>
<h1 id="十六：彻底理解IO多路复用"><a href="#十六：彻底理解IO多路复用" class="headerlink" title="十六：彻底理解IO多路复用"></a><strong>十六：彻底理解IO多路复用</strong></h1><p>在讲解该技术之前，我们需要预习一下文件以及文件描述符。</p>
<h2 id="什么是文件"><a href="#什么是文件" class="headerlink" title="什么是文件"></a>什么是文件</h2><p>程序员使用I&#x2F;O最终都逃不过文件这个概念。<br>在Linux世界中文件是一个很简单的概念，作为程序员我们只需要将其理解为一个N byte的<strong>序列</strong>就可<br>以了：<br><strong>_b1, b2, b3, b4, ……. bN _</strong><br>实际上所有的I&#x2F;O设备都被抽象为了文件这个概念，一切皆文件，Everything is File，磁盘、网络数<br>据、终端，甚至进程间通信工具管道pipe等都被当做文件对待。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696783591571-8d31a36a-a062-4622-8993-8dd102ac5d83.png#averageHue=%23353b3d&clientId=ubc5fcece-554d-4&from=paste&height=278&id=ubd223ce9&originHeight=344&originWidth=719&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=220849&status=done&style=none&taskId=ufc9d82ee-f258-4768-a3e6-b6f00137e80&title=&width=580.0335948516591" alt="image.png"><br>所有的I&#x2F;O操作也都可以通过文件读写来实现，<strong>这一非常优雅的抽象可以让程序员使用一套接口就能对所有外设I&#x2F;O操作</strong>。<br>常用的I&#x2F;O操作接口一般有以下几类：<br>打开文件，open<br>改变读写位置，seek<br>文件读写，read、write<br>关闭文件，close<br>程序员通过这几个接口几乎可以实现所有I&#x2F;O操作，这就是文件这个概念的强大之处。</p>
<h2 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h2><p>在上一篇《<a target="_blank" rel="noopener" href="https://mp.weixin.qq.com/s?__biz=Mzg4OTYzODM4Mw==&mid=2247485706&idx=1&sn=bc5d6e4bf9ee5dccef520e5b2051d943&source=41#wechat_redirect">读取文件时，程序经历了什么</a>》（一定要看）中我们讲到，要想进行I&#x2F;O读操作，像磁盘数据，我们需要指定一个buff用来装入数据，一般都是这样写的：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">read(buff);</span><br></pre></td></tr></table></figure>
<p>但是这里我们忽略了一个关键问题，那就是虽然我们指定了往哪里写数据，但是我们该从哪里读数据呢？<br>从上一节中我们知道，通过文件这个概念我们能实现几乎所有I&#x2F;O操作，<strong>因此这里少的一个主角就是文件</strong>。<br>那么我们一般都怎样使用文件呢？<br>如果周末你去比较火的餐厅吃饭应该会有体会，一般周末人气高的餐厅都会排队，然后服务员会给你一个排队序号，通过这个序号服务员就能找到你，这里的好处就是服务员无需记住你是谁、你的名字是什么、来自哪里、喜好是什么、是不是保护环境爱护小动物等等，这里的关键点就是<strong>服务员对你一无所知，但依然可以通过一个号码就能找到你</strong>。<br>同样的，在Linux世界要想使用文件，我们也需要借助一个号码，根据“弄不懂原则”，这个号码就被称为了文件描述符，<strong>file descriptors</strong>，在Linux世界中鼎鼎大名，其道理和上面那个排队号码一样。<br>因此，文件描述仅仅就是一个数字而已，但是通过这个数字我们可以操作一个打开的文件，这一点要记住。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696784324423-29978d49-eba4-44b4-b4a1-2e02244c38bf.png#averageHue=%2395b7ec&clientId=ubc5fcece-554d-4&from=paste&height=551&id=uf82f187a&originHeight=683&originWidth=587&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=157738&status=done&style=none&taskId=u71091a08-a724-4afe-ae31-2f253739ee2&title=&width=473.5462033072655" alt="image.png"><br><strong>有了文件描述符，进程可以对文件一无所知</strong>，比如文件在磁盘的什么位置、加载到内存中又是怎样管理的等等，这些信息统统交由操作系统打理，进程无需关心，操作系统只需要给进程一个文件描述符就足够了。<br>因此我们来完善上述程序：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">int fd = open(file_name); // 获取文件描述符</span><br><span class="line">read(fd, buff);</span><br></pre></td></tr></table></figure>
<p>怎么样，是不是非常简单。 </p>
<h2 id="文件描述符太多了怎么办"><a href="#文件描述符太多了怎么办" class="headerlink" title="文件描述符太多了怎么办"></a>文件描述符太多了怎么办</h2><p>经过了这么多的铺垫，终于要到高性能、高并发这一主题了。<br>从前几节我们知道，所有I&#x2F;O操作都可以通过文件样的概念来进行，这当然包括网络通信。<br>如果你有一个web服务器，当三次握手成功以后，我们会调用accept来获取一个链接，调用该函数我们同样会得到一个文件描述符，通过这个文件描述符就可以处理客户端发送的请求并且把处理结果发送回去。也就是说通过这个描述符我们就可以和客户端进行通信了。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">// 通过accept获取客户端的文件描述符</span><br><span class="line">int conn_fd = accept(...);</span><br></pre></td></tr></table></figure>
<p>server的处理逻辑通常是读取客户端请求数据，然后执行某些特定逻辑：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">if(read(conn_fd, request_buff) &gt; 0) &#123;</span><br><span class="line"> do_something(request_buff);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>是不是非常简单，然而世界终归是复杂的，当然也不是这么简单的。<br>接下来就是比较复杂的了。<br>既然我们的主题是高并发，那么<strong>server就不可能只和一个客户端通信</strong>，而是可能会同时和成千上万个客户端进行通信。<strong>这时你需要处理不再是一个描述符这么简单，而是有可能要处理成千上万个描述符</strong>。<br>为了不让问题一上来就过于复杂，我们先简单化，假设只同时处理两个客户端的请求。<br>有的同学可能会说，这还不简单，这样写不就行了：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">if(read(socket_fd1, buff) &gt; 0) &#123; </span><br><span class="line"> // 处理第一个</span><br><span class="line"> do_something();</span><br><span class="line">&#125;</span><br><span class="line">if(read(socket_fd2, buff) &gt; 0) &#123;</span><br><span class="line"> // 处理第二个</span><br><span class="line"> do_something();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在上一篇《读取文件时，程序都经历了什么》中我们讨论过这是非常典型的阻塞式I&#x2F;O，如果此时没有数据可读那么进程会被阻塞而暂停运行，这时我们就无法处理第二个请求了，即使第二个请求的数据已经就位，这也就意味着处理某一个客户端时由于进程被阻塞导致剩下的所有其它客户端必须<strong>等待</strong>，在同时处理几万客户端的server上，这显然是不能容忍的。<br>聪明的你一定会想到使用多线程，为每个客户端请求开启一个线程，这样一个客户端被阻塞就不会影响到处理其它客户端的线程了，注意，既然是高并发，那么我们要为成千上万个请求开启成千上万个线程吗？大量创建销毁线程会严重影响系统性能。<br>那么这个问题该怎么解决呢？<br><strong>这里的关键点在于，我们事先并不知道一个文件描述对应的I&#x2F;O设备是否是可读的、是否是可写的</strong>，<br>在外设的不可读或不可写的状态下进行I&#x2F;O只会导致进程阻塞被暂停运行。<br>因此要优雅的解决这个问题，就要从其它角度来思考这个问题了。</p>
<h2 id="不要打电话给我，有需要我会打给你"><a href="#不要打电话给我，有需要我会打给你" class="headerlink" title="不要打电话给我，有需要我会打给你"></a>不要打电话给我，有需要我会打给你</h2><p>大家生活中肯定会接到过推销电话，而且不止一个，一天下来接上十个八个推销电话你的身体会被掏空的。<br>这个场景的关键点在于打电话的人并不知道你是不是要买东西，只能来一遍遍问你，因此一种更好的策略是不要让他们打电话给你，记下他们的电话，有需要的话打给他们，这样推销员就不会一遍一遍的来烦你了(虽然现实生活中这并不可能)。<br>在这个例子中，你，就好比内核，推销者就好比应用程序，电话号码就好比文件描述符，和你用电话沟通就好比I&#x2F;O。<br>现在你应该明白了吧，处理多个文件描述符的更好方法其实就存在于推销电话中。<br>因此相比上一节中我们通过I&#x2F;O接口<strong>主动</strong>问内核这些文件描述符对应的外设是不是已经就绪了，一种更好的方法是，我们把这些感兴趣的文件描述符一股脑扔给内核，并霸气的告诉内核：“<strong>我这里有1万个文件描述符，你替我监视着它们，有可以读写的文件描述符时你就告诉我，我好处理</strong>”。而不是弱弱的问内核：“第一个文件描述可以读写了吗？第二个文件描述符可以读写吗？第三个文件描述符可以读吗？。。。”<br>这样应用程序就<strong>从“繁忙”的主动变为了清闲的被动</strong>，<strong>反正文件描述可读可写了内核会通知我</strong>，能偷懒我才不要那么勤奋。<br>这是一种更加高效的I&#x2F;O处理机制，<strong>现在我们可以一次处理多路I&#x2F;O了</strong>，为这种机制起一个名字吧，再次祭出“弄不懂原则”，就叫I&#x2F;O多路复用吧，这就是 I&#x2F;O multiplexing。</p>
<h2 id="I-O多路复用，I-O-multiplexing"><a href="#I-O多路复用，I-O-multiplexing" class="headerlink" title="I&#x2F;O多路复用，I&#x2F;O multiplexing"></a>I&#x2F;O多路复用，I&#x2F;O multiplexing</h2><p>multiplexing一词其实多用于通信领域，为了充分利用通信线路，希望在一个信道中传输多路信号，要想在一个信道中传输多路信号就需要把这多路信号结合为一路，将多路信号组合成一个信号的设备被称为multiplexer，显然接收方接收到这一路组合后的信号后要恢复原先的多路信号，这个设备被称为demultiplexer，如图所示：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696784685455-571ecb3b-d0a2-4c12-8bcd-0dfc16976f6a.png#averageHue=%23f9faf6&clientId=ubc5fcece-554d-4&from=paste&height=259&id=uc97d4d6d&originHeight=321&originWidth=851&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=147754&status=done&style=none&taskId=ue4cc0fbf-423e-4bd0-9527-db6355ef217&title=&width=686.5209863960526" alt="image.png"><br>回到我们的主题。<br>所谓I&#x2F;O多路复用指的是这样一个过程： </p>
<ol>
<li>我们拿到了一堆文件描述符(不管是网络相关的、还是磁盘文件相关等等，任何文件描述符都可以) </li>
<li>通过调用<strong>某个函数</strong>告诉内核：“<strong>这个函数你先不要返回，你替我监视着这些描述符，当这堆文件描述符中有可以进行I&#x2F;O读写操作的时候你再返回</strong>” </li>
<li>当调用的这个函数返回后我们就能知道哪些文件描述符可以进行I&#x2F;O操作了。<br>也就是说<strong>通过I&#x2F;O多路复用我们可以同时处理多路I&#x2F;O</strong>。那么有哪些函数可以用来进行I&#x2F;O多路复用呢？<br>在Linux世界中有这样三种机制可以用来进行I&#x2F;O多路复用：<br>select<br>poll<br>epoll<br>接下来我们就来介绍一下牛掰的I&#x2F;O多路复用三剑客。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696784730303-6cc960b2-c1be-462b-a4c2-ea937a706e79.png#averageHue=%23787c74&clientId=ubc5fcece-554d-4&from=paste&height=105&id=u49719db6&originHeight=130&originWidth=303&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=44783&status=done&style=none&taskId=u06eaa750-e640-4bee-8293-65a0a821a4e&title=&width=244.43696695417623" alt="image.png"></li>
</ol>
<h2 id="I-O多路复用三剑客"><a href="#I-O多路复用三剑客" class="headerlink" title="I&#x2F;O多路复用三剑客"></a>I&#x2F;O多路复用三剑客</h2><p>本质上select、poll、epoll都是阻塞式I&#x2F;O，也就是我们常说的同步I&#x2F;O，原因在于调用这些I&#x2F;O多路复用函数时如果任何一个需要监视的文件描述符都不可读或者可写那么进程会被阻塞暂停执行，直到有文件描述符可读或者可写才继续运行。</p>
<h3 id="1，select：初出茅庐"><a href="#1，select：初出茅庐" class="headerlink" title="1，select：初出茅庐"></a>1，select：初出茅庐</h3><p>在select这种I&#x2F;O多路复用机制下，我们需要把想监控的文件描述集合通过函数参数的形式告诉select，然后select会将这些文件描述符集合<strong>拷贝</strong>到内核中，我们知道数据拷贝是有性能损耗的，因此为了减少这种数据拷贝带来的性能损耗，Linux内核对集合的大小做了限制，并规定用户监控的文件描述集合不能超过1024个，同时当select返回后<strong>我们仅仅能知道有些文件描述符可以读写了，但是我们不知道是哪一个</strong>，因此程序员必须再遍历一边找到具体是哪个文件描述符可以读写了。<br>因此，总结下来select有这样几个特点：<br>我能照看的文件描述符数量有限，不能超过1024个<br>用户给我的文件描述符需要拷贝的内核中<br>我只能告诉你有文件描述符满足要求了，但是我不知道是哪个，你自己一个一个去找吧(遍历)<br>因此我们可以看到，select机制的这些特性在高并发网络服务器动辄几万几十万并发链接的场景下无疑是低效的。</p>
<h3 id="2，poll：小有所成"><a href="#2，poll：小有所成" class="headerlink" title="2，poll：小有所成"></a>2，poll：小有所成</h3><p>poll和select是非常相似的，poll相对于select的优化仅仅在于解决了文件描述符不能超过1024个的限制，select和poll都会随着监控的文件描述数量增加而性能下降，因此不适合高并发场景。 </p>
<h3 id="3，epoll：独步天下"><a href="#3，epoll：独步天下" class="headerlink" title="3，epoll：独步天下"></a>3，epoll：独步天下</h3><p>在select面临的三个问题中，文件描述数量限制已经在poll中解决了，剩下的两个问题呢？<br>针对拷贝问题，epoll使用的策略是<strong>各个击破</strong>与<strong>共享内存</strong>。<br>实际上文件描述符集合的变化频率比较低，select和poll频繁的拷贝整个集合，内核都快被烦死了，<br>epoll通过引入epoll_ctl很体贴的做到了只操作那些有变化的文件描述符，同时epoll和内核还成为了好朋友，共享了同一块内存，这块内存中保存的就是那些已经可读或者可写的的文件描述符集合，这样就减少了内核和程序的拷贝开销。<br>针对需要遍历文件描述符才能知道哪个可读可写这一问题，epoll使用的策略是“当小弟”。在select和poll机制下，<strong>进程要亲自下场去各个文件描述符上等待</strong>，任何一个文件描述可读或者可写就唤醒进程，但是进程被唤醒后也是一脸懵逼并不知道到底是哪个文件描述符可读或可写，还要再从头到尾检查一遍。<br>但epoll就懂事多了，主动找到进程要当小弟替大哥出头。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696784871200-c3f4eab3-08a1-4229-b921-7313fbd341e5.png#averageHue=%23332213&clientId=ubc5fcece-554d-4&from=paste&height=199&id=u086f25b3&originHeight=247&originWidth=500&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=117241&status=done&style=none&taskId=u3a74b3f1-f18d-45f5-82b9-1f33c560033&title=&width=403.3613316075515" alt="image.png"><br>在这种机制下，进程不需要亲自下场了，进程只要等待在epoll上，epoll代替进程去各个文件描述符上等待，当哪个文件描述符可读或者可写的时候就告诉epoll，epoll用小本本认真记录下来然后唤醒大哥：“进程大哥，快醒醒，你要处理的文件描述符我都记下来了”，这样进程被唤醒后就无需自己从头到尾检查一遍，因为epoll小弟都已经记下来了。<br>因此我们可以看到，在epoll这种机制下，实际上利用的就是“不要打电话给我，有需要我会打给你”这种策略，进程不需要一遍一遍麻烦的问各个文件描述符，而是翻身做主人了，“你们这些文件描述符有哪个可读或者可写了主动报上来”，这种机制实际上就是大名鼎鼎的事件驱动，Event-driven，这也是我们下一篇的主题。<br>实际上在Linux平台，<strong>epoll基本上就是高并发的代名词</strong>。 </p>
<h2 id="总结-14"><a href="#总结-14" class="headerlink" title="总结"></a>总结</h2><p>基于一切皆文件的设计哲学，I&#x2F;O也可以通过文件的形式实现，高并发场景下要与多个文件交互，这就离不开高效的I&#x2F;O多路复用技术，本文我们详细讲解了什么是I&#x2F;O多路复用以及使用方法，这其中以epoll为代表的I&#x2F;O多路复用(基于事件驱动)技术使用非常广泛，实际上你会发现但凡涉及到高并发、高性能的场景基本上都能见到事件驱动的编程方法，当然这也是下一篇我们要重点讲解的主题，敬请期待。 </p>
<h1 id="十七、你管这破玩意叫mmap？"><a href="#十七、你管这破玩意叫mmap？" class="headerlink" title="十七、你管这破玩意叫mmap？"></a>十七、你管这破玩意叫mmap？</h1><h1 id="十八、彻底理解零拷贝"><a href="#十八、彻底理解零拷贝" class="headerlink" title="十八、彻底理解零拷贝"></a>十八、彻底理解零拷贝</h1><h1 id="十九、操作系统与内核有什么区别？"><a href="#十九、操作系统与内核有什么区别？" class="headerlink" title="十九、操作系统与内核有什么区别？"></a>十九、操作系统与内核有什么区别？</h1><p><strong>通用底盘技术 **<br>Canoo公司有一项核心技术专利，这就是它们的通用电动底盘技术，长得是这个样子，非常像一个滑板：<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696784972954-bf74f1b8-c0b7-4c0f-8b53-ded08a33ecfc.png#averageHue=%237a6856&clientId=ubc5fcece-554d-4&from=paste&height=282&id=u23647a10&originHeight=350&originWidth=700&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=106011&status=done&style=none&taskId=u26694384-347d-44ab-9890-7aaea781102&title=&width=564.7058642505722" alt="image.png"><br>这个带轮子、有电池、能动的滑板已经包含了一辆车</strong>最核心**的组件，差的就是一个外壳。<br>这个看起来像滑板的东西就是所谓的电池系统和底盘一体化技术，Canoo公司在它们的通用底盘上加装不同的外壳就能制造出不同的车型。 </p>
<h2 id="什么是内核？"><a href="#什么是内核？" class="headerlink" title="什么是内核？"></a>什么是内核？</h2><p>在上面这个示例中，<strong>包含轮子以及电池系统的底盘就好比内核，而套上外壳加上椅子以及内饰后的整体成品就好比操作系统</strong>。<br>内核仅仅是操作系统的一部分，是真正与硬件交互的那部分软件，与硬件交互包括读写硬盘、读写网盘、读写内存以及任何连接到系统中的硬件。<br>除了与硬件交互外，内核还负责分配资源，分配什么资源呢？所谓资源就是硬件，比如CPU时间、内存、IO等等，这些都是资源。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696785062335-0fca643f-36fc-456d-a22f-2e7f91d95ca3.png#averageHue=%23517e5a&clientId=ubc5fcece-554d-4&from=paste&height=523&id=u751570cb&originHeight=648&originWidth=914&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=173679&status=done&style=none&taskId=ub3583d3d-46b0-4e30-9258-297c99b433c&title=&width=737.3445141786042" alt="image.png"><br>现在我们知道了内核负责分配资源，那么问题来了，要怎么分配这些资源呢？答案就是以<strong>进程</strong>的形式来分配资源。<br>怎么分配呢？<br>一句话：<strong>虚拟大法好</strong>。<br>每个进程都认为自己在独占CPU，这通过CPU时间片来实现，内核让CPU在各个进程之间快速切换，这样程序员写好程序员后直接运行即可，即使在单核系统中运行成百上千个进程都没有问题。<br>每个进程都认为自己在独占内存，这通过虚拟内存来实现。<br>有的同学可能会问，为什么都要虚拟化呢？<br>答案显而易见，因为计算机系统内的资源是有限的，<strong>我们只有几个CPU核心、几个G的内存，但却要同时运行几百几千个进程</strong>，除此之外我们别无它法。<br>如果你还知道有其它更高效的方法那么赶紧放下手机，马上将你的思想写成论文发表出来，下一届的图灵奖非你莫属。<br>因此，内核的职责就是以进程的形式来分配CPU时间，以虚拟内存的形式来分配物理内存，以文件的形式来管理IO设备。 </p>
<h2 id="什么是操作系统？"><a href="#什么是操作系统？" class="headerlink" title="什么是操作系统？"></a>什么是操作系统？</h2><p>然而只有一个内核实际上是做不了什么真正有用的事情，就像上面示例中那个通用底盘一样，这个底盘确实能跑起来，但你没办法开着这样一个底盘出去浪，因为这个底盘很难用。<br>因此，你不得不加装上方向盘、座椅以及车身外壳等，同样的道理，内核是给人用的，为了与内核交互，发明了命令行以及图形界面GUI。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696785293617-d63b23e4-ff86-41bb-81f7-4da167f585e9.png#averageHue=%236aadd5&clientId=ubc5fcece-554d-4&from=paste&height=425&id=u385a958b&originHeight=527&originWidth=940&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=652944&status=done&style=none&taskId=u3c707a2a-9622-42bb-874d-afe87d330ee&title=&width=758.3193034221969" alt="image.png"><br><strong>除了给普通用户提供使用的接口之外，操作系统还需要给程序员提供编写程序的接口</strong>，当我们写的程序依赖内核提供的服务时是该怎么办呢？<br>有的同学说我们需要依赖内核提供的服务吗？<br>想一想，进行网络编程时你有没有自己编写过处理TCP&#x2F;IP协议栈数据的代码？你有没有自己写代码从网卡上收发数据？都没有，实际上你需要做的仅仅是简单的调用一些socket接口就可以了。<br>网络编程仅仅是其中的一项，其它还包括文件IO、创建进程、创建线程等等等等，这些是内核提供的，那么我们该怎么使用呢？<br>答案就是通过所谓的系统调用，system call。<br>通过系统调用，我们可以像使用普通函数那样向操作系统请求服务，当然，直接使用系统调用是非常繁琐的，<strong>因此通常会在这之上提供一层封装</strong>。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696785335577-c3ef9d93-7680-4c9f-be63-ce0737fa469c.png#averageHue=%23fbfefe&clientId=ubc5fcece-554d-4&from=paste&height=451&id=ud0c2c727&originHeight=709&originWidth=690&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=185488&status=done&style=none&taskId=u9fb67dd4-4040-4ef9-bc0b-0ca960de798&title=&width=438.63861083984375" alt="image.png"><br>在Windows平台就是给程序员提供编程接口的是Windows API，这层API包罗万象，不但包括上文提到对系统调用的封装，还包括其它功能，像创建带有图形界面的应用程序等等。<br><strong>但在Linux世界你找不到一种类似Windows API的东西</strong>，毕竟Windows是微软自家产品，什么都可以打包起来，Linux只是一个开源的内核，如果一定要找一个类似的东西话那就是libc，也就是C标准库，这里同样包括了对系统调用的封装以及一些库函数，但libc不包含创建带有图形界面应用程序的功能。<br>现在我们知道了，操作系统需要提供两种接口：<br>给用户提供操作接口。<br>给程序员提供编程接口。<br>这些就是好比汽车的外壳，我们(用户和程序员)看得见摸得着，外壳加上底盘——也就是内核，才是功能完善的操作系统。<br><img src="https://cdn.nlark.com/yuque/0/2023/png/1205446/1696785398693-2855d67c-d32a-4180-9a92-b5258e11c009.png#averageHue=%2371736f&clientId=ubc5fcece-554d-4&from=paste&height=529&id=u75967252&originHeight=656&originWidth=1080&originalType=binary&ratio=1.115625023841858&rotation=0&showTitle=false&size=395261&status=done&style=none&taskId=u939aefdc-aa25-4751-a242-8461a80b7c7&title=&width=871.2604762723113" alt="image.png"></p>
<h2 id="各种各样的操作系统"><a href="#各种各样的操作系统" class="headerlink" title="各种各样的操作系统"></a>各种各样的操作系统</h2><p>实际上我们熟悉的Linux只是内核而不能称得上是操作系统，Ubuntu则可以认为是操作系统，其内核是Linux；RedHat也是操作系统，其内核同样是Linux；我们可以看到，尽管Ubuntu和RedHat是不同的操作系统，但其内核可以是相同的。<br>这就好比它们可以基于同样的底盘打造出不同的车型。<br>而我们熟悉的Windows也是操作系统，其内核是Windows NT内核。 </p>
<h2 id="总结-15"><a href="#总结-15" class="headerlink" title="总结"></a>总结</h2><p>内核就像本文开头提到的电动底盘，包含了一个汽车的最核心元素；但这样一个底盘并没有什么实际用处，当搭配上外壳以及座椅后才是一辆真正有用的车，这就好比操作系统。值得注意的是，不同的操作系统可以有相同的内核。<br>当我们在使用方便的智能手机以及个人PC时不应忘记，正是操作系统在背后的默默工作让一堆硬件电路变得这么好用。 </p>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>YHM</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://example.com/2023/10/09/%E5%9B%BE%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/">http://example.com/2023/10/09/%E5%9B%BE%E8%A7%A3%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>你相信光吗?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%EF%BC%8C%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%B3%BB%E7%BB%9F/"># 计算机，计算机系统</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2023/10/16/%E5%81%A5%E8%BA%AB%E8%AE%A1%E5%88%92/">健身计划</a>
            
            
            <a class="next" rel="next" href="/2023/10/09/hello-world/">Hello World</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© YHM | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>